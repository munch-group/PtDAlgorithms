---
title: "Phase-Type Distributions"
format: html
---

# Introduction to Phase-Type Distributions

Phase-type distributions are a powerful class of probability distributions that model the time until absorption in continuous or discrete-time Markov chains on a finite state space. They find diverse applications in statistical modeling, including physics, telecommunications, queuing theory, and recently, population genetics.

This page provides an introduction to phase-type distributions, their mathematical formulation, and the correspondence between traditional matrix representations and the graph-based approach implemented in PtDAlgorithms.

## What is a Phase-Type Distribution?

A **phase-type distribution** represents the time until a Markov process reaches an absorbing state. The process moves through various "phases" (transient states) before eventually being absorbed.

### Continuous Phase-Type Distributions

In a continuous phase-type distribution, the underlying process is a continuous-time Markov jump process.

**Example**: Consider a system with 3 transient states and 1 absorbing state. The system starts in state 1, transitions between states at exponential rates, and eventually reaches the absorbing state. The time until absorption follows a phase-type distribution.

**Key characteristics:**
- Transient states: temporary states the process can visit
- Absorbing state: terminal state from which the process cannot escape
- Transition rates: exponential rates governing state transitions
- Time until absorption: the random variable of interest

### Discrete Phase-Type Distributions

A **discrete phase-type distribution** models the number of jumps in a discrete-time Markov chain until reaching the absorbing state.

**Example**: Number of steps in a random walk before hitting a boundary.

## Mathematical Formulation

### Continuous Phase-Type Distributions

Let $\tau$ be a phase-type distributed random variable with $p$ transient states. We write $\tau \sim PH_p(\boldsymbol{\alpha}, \mathbf{S})$ where:

- **$\boldsymbol{\alpha} = (\alpha_1, \ldots, \alpha_p)$**: Initial probability vector
  - $\alpha_i$ is the probability of starting in state $i$
  - Potential defect: $\alpha_0 = 1 - \sum_{i=1}^p \alpha_i$ (probability of starting in absorbing state)

- **$\mathbf{S}$**: Sub-intensity matrix (rate matrix excluding absorbing states)
  - Entry $s_{ij}$ is the rate of transition from state $i$ to state $j$
  - Diagonal entries are negative: $s_{ii} = -\sum_{j \neq i} s_{ij}$

- **$\mathbf{U} = (-\mathbf{S})^{-1}$**: Green matrix
  - Entry $u_{ij}$ is the expected total time spent in state $j$ when starting in state $i$

#### Cumulative Distribution Function (CDF)

The probability that absorption occurs by time $t$:

$$
F(t) = 1 - \boldsymbol{\alpha} e^{\mathbf{S}t} \mathbf{e}, \quad t \geq 0
$$

where $e^{\mathbf{S}t}$ is the matrix exponential and $\mathbf{e}$ is a vector of ones.

#### Probability Density Function (PDF)

The density function is:

$$
f(t) = \boldsymbol{\alpha} e^{\mathbf{S}t} (-\mathbf{S}) \mathbf{e}, \quad t \geq 0
$$

#### Moments

The expectation (first moment):

$$
\mathbb{E}[\tau] = \boldsymbol{\alpha} \mathbf{U} \mathbf{e}
$$

Higher-order moments:

$$
\mathbb{E}[\tau^k] = k! \boldsymbol{\alpha} \mathbf{U}^k \mathbf{e}
$$

The variance:

$$
\text{Var}(\tau) = 2\boldsymbol{\alpha} \mathbf{U}^2 \mathbf{e} - (\boldsymbol{\alpha} \mathbf{U} \mathbf{e})^2
$$

### Discrete Phase-Type Distributions

For discrete phase-type distributions with sub-transition matrix $\mathbf{T}$ and initial distribution $\boldsymbol{\pi}$:

#### Green Matrix

$$
\mathbf{U} = -(\mathbf{T} - \mathbf{I})^{-1}
$$

#### CDF (Probability Mass Function)

The probability of absorption at exactly jump $t$:

$$
F(t) = 1 - \boldsymbol{\pi} \mathbf{T}^t \mathbf{e}
$$

#### Moments

The expectation:

$$
\mathbb{E}[\tau] = \boldsymbol{\pi} \mathbf{U} \mathbf{e}
$$

### Reward-Transformed Distributions

Phase-type distributions can be **reward-transformed** by assigning rewards $r_i > 0$ to each state $i$. Instead of measuring time until absorption, the distribution represents accumulated reward until absorption.

#### Mathematical Interpretation

**Intuition**: Rewards scale the "waiting time" in each state. If state $i$ has reward $r_i = 2$, then spending time $t$ in that state accumulates reward $2t$. This is like earning interest at different rates in different states.

Given rewards $\mathbf{r} = (r_1, \ldots, r_p)$, the reward-transformed variable is:

$$
Y = \int_0^\tau r(X_t) dt
$$

where $\{X_t\}$ is the underlying Markov process and $\tau$ is the time until absorption.

**Example**: Consider a system where:
- State 1 has reward $r_1 = 1$ (baseline accumulation rate)
- State 2 has reward $r_2 = 5$ (accumulates 5× faster)
- The process spends time $t_1$ in state 1 and $t_2$ in state 2

Then the total accumulated reward is $Y = 1 \cdot t_1 + 5 \cdot t_2$.

The $k$-th moment of the reward-transformed distribution:

$$
\mathbb{E}[Y^k] = k! \boldsymbol{\alpha} (\mathbf{U} \boldsymbol{\Delta}(\mathbf{r}))^k \mathbf{e}
$$

where $\boldsymbol{\Delta}(\mathbf{r})$ is a diagonal matrix with rewards on the diagonal.

#### Graph Interpretation

In the graph representation, **rewards are vertex scalars** that modify what we measure:

- **Without rewards**: Measure time until absorption (standard phase-type distribution)
- **With rewards**: Each vertex $v$ has an associated reward $r_v$ (a positive scalar)
- **Accumulation**: While the process resides in vertex $v$, reward accumulates at rate $r_v$ per unit time
- **Edge weights unchanged**: Transition rates (edge weights) remain the same; only the "value" of time in each state changes

Think of rewards as **time multipliers** at each vertex: spending time $\Delta t$ in vertex $v$ contributes $r_v \cdot \Delta t$ to the total accumulated reward.

**Key insight**: Rewards don't change the transition structure of the graph—they only change what we're measuring. The same stochastic process gives different distributions depending on the rewards.

**Practical uses**:
- **Population genetics**: Counting mutations (reward = mutation rate per lineage)
- **Queuing theory**: Accumulated cost (reward = cost per unit time in each state)
- **Physics**: Energy or distance (reward = rate of energy/distance change in each state)

**Example**: In a population genetics model:
- Each state represents a configuration of genealogical lineages
- State with $k$ lineages has reward $r_k = \binom{k}{2}$ (number of pairs that could coalesce)
- The reward-transformed distribution represents total branch length, not just time

### Multivariate Phase-Type Distributions

**Multivariate phase-type distributions** assign a vector of rewards to each state, resulting in a vector-valued outcome:

$$
\mathbf{Y} \sim MPH^*(\boldsymbol{\alpha}, \mathbf{S}, \mathbf{R})
$$

where $\mathbf{R}$ is a matrix of rewards (each row corresponds to a state, each column to a reward dimension).

**Applications**: Modeling multiple correlated quantities accumulated along the same stochastic process.

**Marginal moments**: Computed independently for each dimension.

**Joint moments**: The covariance between dimensions $i$ and $j$:

$$
\text{Cov}(Y_i, Y_j) = \boldsymbol{\alpha}\mathbf{U}(\mathbf{R}_{\cdot i})\mathbf{U}(\mathbf{R}_{\cdot j})\mathbf{e} + \boldsymbol{\alpha}\mathbf{U}(\mathbf{R}_{\cdot j})\mathbf{U}(\mathbf{R}_{\cdot i})\mathbf{e} - \boldsymbol{\alpha}\mathbf{U}(\mathbf{R}_{\cdot i})\mathbf{e} \cdot \boldsymbol{\alpha}\mathbf{U}(\mathbf{R}_{\cdot j})\mathbf{e}
$$

## Graph-Based Representation

Traditional matrix-based formulations become computationally infeasible for systems with thousands of states. However, many real-world systems have **sparse state spaces** where each state connects to only a few others. This sparseness makes a **graph-based representation** more natural and efficient.

### Graph Representation

A phase-type distribution can be represented as a **weighted directed graph** $G = (V, E)$ where:

- **Vertices ($V$)**: Represent states in the Markov chain
  - Special **starting vertex** $S$: initial state
  - **Transient vertices**: states the process can visit
  - **Absorbing vertices**: terminal states (no outgoing edges)

- **Edges ($E$)**: Represent transitions between states
  - An edge $(v \to z)$ connects vertex $v$ to vertex $z$
  - Each edge has a **weight** $w(v \to z)$ representing the transition rate

- **Edge weights**:
  - For continuous distributions: transition rates (positive real numbers)
  - For discrete distributions: transition probabilities (between 0 and 1)

### Correspondence: Matrices ↔ Graphs

The graph representation directly corresponds to the matrix formulation:

| Matrix Concept | Graph Concept |
|----------------|---------------|
| State $i$ | Vertex $v$ |
| Initial probability $\alpha_i$ | Weight $w(S \to v_i)$ from starting vertex |
| Sub-intensity entry $s_{ij}$ | Edge weight $w(v_i \to v_j)$ |
| Absorbing state | Vertex with no outgoing edges |
| Total exit rate from state $i$ | $\lambda_v = \sum_{z \in \text{children}(v)} w(v \to z)$ |

**Example**: The sub-intensity matrix

$$
\mathbf{S} = \begin{pmatrix}
-5 & 1 & 4 \\
1 & -8 & 2 \\
0 & 1 & -3
\end{pmatrix}
$$

corresponds to a graph with:
- Vertex A with edges: (A → B, weight=1), (A → C, weight=4)
- Vertex B with edges: (B → A, weight=1), (B → C, weight=2)
- Vertex C with edges: (C → B, weight=1)
- Total exit rates: $\lambda_A = 5$, $\lambda_B = 8$, $\lambda_C = 3$

### Advantages of Graph Representation

1. **Memory efficiency**: Store only existing transitions (not full $p \times p$ matrix)
   - For sparse systems: $O(|E|)$ vs $O(p^2)$ memory

2. **Computational efficiency**: Operations on edges only
   - Many algorithms: $O(|V|^2)$ vs $O(p^3)$ for matrix operations

3. **Iterative construction**: Build state space incrementally
   - Add vertices and edges as needed
   - Natural for complex phenomena

4. **Intuitive modeling**: Specify transitions from each state independently
   - Markov property: next state depends only on current state
   - Easy to encode complex models

5. **Numerical stability**: Avoid matrix inversions and exponentials

### Example: Rabbit Island Model

Consider rabbits jumping between two islands at rate 1. Islands flood at rates 2 and 4, drowning all rabbits on that island. The absorbing state is when all rabbits have drowned.

**State representation**: Vector $(n_1, n_2)$ where $n_i$ is the number of rabbits on island $i$.

**Graph construction**:
- Start with state $(2, 0)$: 2 rabbits on island 1
- From state $(i, j)$:
  - If $i > 0$: transition to $(i-1, j+1)$ at rate $i$ (rabbit jumps left to right)
  - If $j > 0$: transition to $(i+1, j-1)$ at rate $j$ (rabbit jumps right to left)
  - If $i > 0$: transition to $(0, j)$ at rate 2 (island 1 floods)
  - If $j > 0$: transition to $(i, 0)$ at rate 4 (island 2 floods)
  - Absorbing state: $(0, 0)$

This naturally sparse structure makes graphs ideal for representation.

## Computational Algorithms

PtDAlgorithms implements efficient graph-based algorithms for:

1. **State space construction**: Iterative building of the graph
2. **Reward transformation**: Modifying distributions by assigning rewards
3. **Moment computation**: Computing expectations, variances, higher moments
4. **Distribution functions**: Computing PMF/PDF and CDF
5. **Multivariate distributions**: Joint and marginal moments

### Key Algorithmic Innovations

From Røikjer, Hobolth, and Munch (2022):

- **Acyclic graph transformation**: Convert cyclic graphs to acyclic form for recursive computation
- **Cached operations**: Compute moments in $O(|V|^2)$ time after initial $O(|V|^3)$ setup
- **Discrete approximation**: Approximate continuous distributions with arbitrary precision
- **Parallel computation**: Natural parallelization over graph structure

**Performance**: Orders of magnitude faster than matrix-based methods for sparse systems.

## Practical Example

Let's compute properties of an Erlang distribution (sum of exponential random variables):

```python
from ptdalgorithms import Graph

# Build Erlang(3) distribution: sum of 3 exponentials with rate 1
g = Graph(1)
start = g.starting_vertex()

# Create chain: S -> v1 -> v2 -> v3 -> absorbing
v1 = g.find_or_create_vertex([1])
v2 = g.find_or_create_vertex([2])
v3 = g.find_or_create_vertex([3])

start.add_edge(v1, 1.0)  # Start in state 1 with probability 1
v1.add_edge(v2, 1.0)     # Transition rate 1
v2.add_edge(v3, 1.0)     # Transition rate 1
v3.add_edge(g.find_or_create_vertex([4]), 1.0)  # To absorbing state

# Compute properties
print(f"Expectation: {g.expectation()}")      # Should be 3.0
print(f"Variance: {g.variance()}")            # Should be 3.0
print(f"PDF at t=2.0: {g.pdf(2.0)}")
print(f"CDF at t=2.0: {g.cdf(2.0)}")
```

## When to Use Phase-Type Distributions

Phase-type distributions are particularly useful when:

1. **Modeling absorption times**: Time until system reaches terminal state
2. **Sparse state spaces**: Many states but few transitions per state
3. **Complex phenomena**: Iterative construction from simple rules
4. **Multiple quantities**: Multivariate distributions with correlated outcomes
5. **Large state spaces**: Thousands to millions of states

**Applications**:
- Queuing theory (service times)
- Reliability theory (time to failure)
- Population genetics (coalescent times)
- Telecommunications (packet delays)
- Survival analysis (time to event)

## Further Reading

For detailed algorithms and proofs, see:

**Røikjer, T., Hobolth, A., & Munch, K. (2022).** *Graph-based algorithms for phase-type distributions.* Statistics and Computing, 32:103. [https://doi.org/10.1007/s11222-022-10174-3](https://doi.org/10.1007/s11222-022-10174-3)

The paper provides:
- Complete algorithmic details
- Complexity analysis
- Proofs of correctness
- Empirical performance comparisons
- Applications to population genetics

## Related Documentation

- **[State Space Construction](state_space.ipynb)** - Building phase-type models
- **[Moments](moments.ipynb)** - Computing expectations and variances
- **[Distributions](distributions.ipynb)** - PMF, PDF, and CDF computation
- **[Graph Construction](../api/Graph.html)** - API reference

## References

**Key references:**

- Neuts, M.F. (1981). *Matrix-Geometric Solutions in Stochastic Models.* Johns Hopkins University Press.
- Bladt, M., & Nielsen, B.F. (2017). *Matrix-Exponential Distributions in Applied Probability.* Springer.
- Hobolth, A., Siri-Jegousse, A., & Bladt, M. (2019). Phase-type distributions in population genetics. *Theoretical Population Biology*, 127:16-32.

**Graph algorithms:**

- Duff, I.S., Erisman, A.M., & Reid, J.K. (2017). *Direct Methods for Sparse Matrices.* Oxford University Press.
- Bobbio, A., Horváth, A., & Telek, M. (2004). The scale factor: a new degree of freedom in phase-type approximation. *Performance Evaluation*, 56(1-4):121-144.

---

*This documentation is based on the graph-based algorithms implemented in PtDAlgorithms and described in Røikjer et al. (2022).*
