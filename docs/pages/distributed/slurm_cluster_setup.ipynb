{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: SLURM Cluster Setup and Configuration\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This guide shows how to configure and manage cluster resources for distributed computing with phasic.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The configuration system provides:\n",
    "\n",
    "- **YAML-based configs** - Separate configuration from code\n",
    "- **Predefined profiles** - Quick start with standard configurations\n",
    "- **Script generation** - Automatic SLURM script creation\n",
    "- **Flexible customization** - Adapt to any cluster setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration Management\n",
    "\n",
    "### Loading Predefined Profiles\n",
    "\n",
    "phasic includes several predefined profiles for common scenarios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phasic.cluster_configs import get_default_config\n",
    "\n",
    "# Load a predefined profile\n",
    "config = get_default_config(\"medium\")\n",
    "\n",
    "print(\"Medium Cluster Configuration\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Name: {config.name}\")\n",
    "print(f\"Nodes: {config.nodes}\")\n",
    "print(f\"CPUs per node: {config.cpus_per_node}\")\n",
    "print(f\"Memory per CPU: {config.memory_per_cpu}\")\n",
    "print(f\"Time limit: {config.time_limit}\")\n",
    "print(f\"Partition: {config.partition}\")\n",
    "print(f\"Total devices: {config.total_devices}\")\n",
    "print(f\"Platform: {config.platform}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Available Profiles\n",
    "\n",
    "Let's examine all available profiles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List all profiles\n",
    "profiles = [\"debug\", \"small\", \"medium\", \"large\", \"production\"]\n",
    "\n",
    "# Create comparison table\n",
    "data = []\n",
    "for profile in profiles:\n",
    "    cfg = get_default_config(profile)\n",
    "    data.append({\n",
    "        'Profile': profile,\n",
    "        'Nodes': cfg.nodes,\n",
    "        'CPUs/node': cfg.cpus_per_node,\n",
    "        'Total Devices': cfg.total_devices,\n",
    "        'Memory/CPU': cfg.memory_per_cpu,\n",
    "        'Time Limit': cfg.time_limit,\n",
    "        'Use Case': {\n",
    "            'debug': 'Quick testing',\n",
    "            'small': 'Development',\n",
    "            'medium': 'Standard jobs',\n",
    "            'large': 'Large-scale inference',\n",
    "            'production': 'Maximum scale'\n",
    "        }[profile]\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(\"\\nAvailable Cluster Profiles:\")\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Custom Configurations\n",
    "\n",
    "For cluster-specific settings, create a YAML configuration file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Create a custom configuration\n",
    "custom_config_yaml = \"\"\"\n",
    "name: my_cluster\n",
    "nodes: 6\n",
    "cpus_per_node: 24\n",
    "memory_per_cpu: \"8G\"\n",
    "time_limit: \"04:00:00\"\n",
    "partition: \"gpu-partition\"\n",
    "qos: \"high-priority\"\n",
    "coordinator_port: 12345\n",
    "platform: \"gpu\"\n",
    "gpus_per_node: 4\n",
    "\n",
    "# Network configuration\n",
    "network_interface: \"ib0\"  # InfiniBand interface\n",
    "\n",
    "# Environment variables\n",
    "env_vars:\n",
    "  JAX_ENABLE_X64: \"1\"\n",
    "  XLA_PYTHON_CLIENT_PREALLOCATE: \"false\"\n",
    "  CUDA_VISIBLE_DEVICES: \"0,1,2,3\"\n",
    "\n",
    "# Modules to load\n",
    "modules_to_load:\n",
    "  - \"cuda/11.8\"\n",
    "  - \"python/3.11\"\n",
    "  - \"gcc/11.2.0\"\n",
    "\n",
    "# Additional SBATCH options\n",
    "extra_sbatch_options:\n",
    "  constraint: \"skylake\"\n",
    "  account: \"my_project\"\n",
    "\"\"\"\n",
    "\n",
    "# Save to file\n",
    "import os\n",
    "os.makedirs(\"slurm_configs\", exist_ok=True)\n",
    "\n",
    "with open(\"slurm_configs/my_cluster.yaml\", \"w\") as f:\n",
    "    f.write(custom_config_yaml)\n",
    "\n",
    "print(\"Created custom configuration: slurm_configs/my_cluster.yaml\")\n",
    "print(\"\\nConfiguration content:\")\n",
    "print(custom_config_yaml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Custom Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phasic.cluster_configs import load_config\n",
    "\n",
    "# Load the custom configuration\n",
    "custom_config = load_config(\"slurm_configs/my_cluster.yaml\")\n",
    "\n",
    "print(\"Loaded Custom Configuration:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Name: {custom_config.name}\")\n",
    "print(f\"Platform: {custom_config.platform}\")\n",
    "print(f\"Nodes: {custom_config.nodes}\")\n",
    "print(f\"GPUs per node: {custom_config.gpus_per_node}\")\n",
    "print(f\"Total devices: {custom_config.total_devices}\")\n",
    "print(f\"Network: {custom_config.network_interface}\")\n",
    "print(f\"\\nEnvironment variables:\")\n",
    "for key, val in custom_config.env_vars.items():\n",
    "    print(f\"  {key}: {val}\")\n",
    "print(f\"\\nModules to load:\")\n",
    "for mod in custom_config.modules_to_load:\n",
    "    print(f\"  - {mod}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SLURM Script Generation\n",
    "\n",
    "The `generate_slurm_script.py` tool creates complete SLURM submission scripts from configurations.\n",
    "\n",
    "### Basic Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate script from profile\n",
    "!python ../examples/generate_slurm_script.py \\\n",
    "    --profile small \\\n",
    "    --script my_inference.py \\\n",
    "    --output submit_small.sh\n",
    "\n",
    "print(\"\\nGenerated SLURM script: submit_small.sh\")\n",
    "print(\"\\nFirst 30 lines of generated script:\")\n",
    "!head -30 submit_small.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generated Script Structure\n",
    "\n",
    "The generated script includes:\n",
    "\n",
    "1. **SBATCH directives** - Resource requests\n",
    "2. **Module loading** - Environment setup\n",
    "3. **Python environment** - Pixi or Conda activation\n",
    "4. **Coordinator setup** - JAX distributed configuration\n",
    "5. **Execution** - Running your script with srun\n",
    "6. **Status reporting** - Job completion information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced: Custom Config to Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate from custom configuration\n",
    "!python ../examples/generate_slurm_script.py \\\n",
    "    --config slurm_configs/my_cluster.yaml \\\n",
    "    --script my_inference.py \\\n",
    "    --output submit_custom.sh \\\n",
    "    --job-name \"my_gpu_job\"\n",
    "\n",
    "print(\"Generated custom SLURM script: submit_custom.sh\")\n",
    "print(\"\\nSBATCH directives from custom config:\")\n",
    "!grep \"^#SBATCH\" submit_custom.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Workflow Example\n",
    "\n",
    "Here's a complete workflow from development to production:\n",
    "\n",
    "### Step 1: Develop Locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create your inference script\n",
    "inference_script = \"\"\"\n",
    "#!/usr/bin/env python3\n",
    "from phasic import initialize_distributed, Graph, SVGD\n",
    "\n",
    "# Initialize (works locally AND on SLURM)\n",
    "dist_info = initialize_distributed()\n",
    "\n",
    "if dist_info.is_coordinator:\n",
    "    print(f\"Running on {dist_info.global_device_count} devices\")\n",
    "\n",
    "# Your inference code here\n",
    "# ...\n",
    "\"\"\"\n",
    "\n",
    "with open(\"my_inference.py\", \"w\") as f:\n",
    "    f.write(inference_script)\n",
    "\n",
    "print(\"Created my_inference.py\")\n",
    "\n",
    "# Test locally\n",
    "print(\"\\nTesting locally:\")\n",
    "!python my_inference.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Test on Small Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate script for small-scale testing\n",
    "!python ../examples/generate_slurm_script.py \\\n",
    "    --profile debug \\\n",
    "    --script my_inference.py \\\n",
    "    --output submit_test.sh\n",
    "\n",
    "print(\"Generated test submission script\")\n",
    "print(\"\\nTo submit:\")\n",
    "print(\"  sbatch submit_test.sh\")\n",
    "print(\"\\nOr quick submit:\")\n",
    "print(\"  sbatch <(python ../examples/generate_slurm_script.py --profile debug --script my_inference.py)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Scale to Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate production-scale script\n",
    "!python ../examples/generate_slurm_script.py \\\n",
    "    --profile production \\\n",
    "    --script my_inference.py \\\n",
    "    --output submit_production.sh\n",
    "\n",
    "print(\"Generated production submission script\")\n",
    "print(\"\\nProduction configuration:\")\n",
    "prod_config = get_default_config(\"production\")\n",
    "print(f\"  Nodes: {prod_config.nodes}\")\n",
    "print(f\"  Total devices: {prod_config.total_devices}\")\n",
    "print(f\"  Time limit: {prod_config.time_limit}\")\n",
    "print(\"\\nTo submit:\")\n",
    "print(\"  sbatch submit_production.sh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitoring Jobs\n",
    "\n",
    "Once submitted, you can monitor your jobs:\n",
    "\n",
    "### Check Job Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell shows commands - run on cluster\n",
    "monitoring_commands = \"\"\"\n",
    "# Check your jobs\n",
    "squeue -u $USER\n",
    "\n",
    "# Check specific job\n",
    "squeue -j <job_id>\n",
    "\n",
    "# View job details\n",
    "scontrol show job <job_id>\n",
    "\n",
    "# View output in real-time\n",
    "tail -f logs/my_inference_<job_id>.out\n",
    "\n",
    "# View errors\n",
    "tail -f logs/my_inference_<job_id>.err\n",
    "\n",
    "# Cancel job\n",
    "scancel <job_id>\n",
    "\"\"\"\n",
    "\n",
    "print(\"Job Monitoring Commands:\")\n",
    "print(\"=\" * 60)\n",
    "print(monitoring_commands)\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration Best Practices\n",
    "\n",
    "### 1. Start Small\n",
    "\n",
    "Always test with `debug` or `small` profiles before scaling up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Development workflow\n",
    "workflow = \"\"\"\n",
    "1. Test locally:        python my_script.py\n",
    "2. Test on cluster:     sbatch <(python generate_slurm_script.py --profile debug --script my_script.py)\n",
    "3. Small scale:         sbatch <(python generate_slurm_script.py --profile small --script my_script.py)\n",
    "4. Production scale:    sbatch <(python generate_slurm_script.py --profile production --script my_script.py)\n",
    "\"\"\"\n",
    "\n",
    "print(\"Recommended Development Workflow:\")\n",
    "print(workflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Cluster-Specific Configs\n",
    "\n",
    "Create configs for each cluster you use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Different clusters\n",
    "clusters = {\n",
    "    \"local_cluster\": {\n",
    "        \"partition\": \"compute\",\n",
    "        \"modules\": [\"python/3.11\"],\n",
    "        \"network\": \"eth0\"\n",
    "    },\n",
    "    \"hpc_center\": {\n",
    "        \"partition\": \"gpu-nodes\",\n",
    "        \"modules\": [\"cuda/11.8\", \"python/3.11\", \"gcc/11\"],\n",
    "        \"network\": \"ib0\",\n",
    "        \"qos\": \"high-priority\"\n",
    "    },\n",
    "    \"cloud_cluster\": {\n",
    "        \"partition\": \"standard\",\n",
    "        \"modules\": [],  # Using containers\n",
    "        \"network\": \"eth0\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Cluster-Specific Settings:\")\n",
    "print(\"=\" * 60)\n",
    "for cluster, settings in clusters.items():\n",
    "    print(f\"\\n{cluster}:\")\n",
    "    for key, val in settings.items():\n",
    "        print(f\"  {key}: {val}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Resource Estimation\n",
    "\n",
    "Estimate resources needed for your job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_resources(n_particles, n_iterations, model_complexity=\"medium\"):\n",
    "    \"\"\"\n",
    "    Rough resource estimation for SVGD inference.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_particles : int\n",
    "        Number of SVGD particles\n",
    "    n_iterations : int\n",
    "        Number of iterations\n",
    "    model_complexity : str\n",
    "        \"simple\", \"medium\", or \"complex\"\n",
    "    \"\"\"\n",
    "    # Rough estimates (adjust based on your model)\n",
    "    time_per_eval = {\n",
    "        \"simple\": 0.001,   # 1ms per evaluation\n",
    "        \"medium\": 0.01,    # 10ms per evaluation\n",
    "        \"complex\": 0.1     # 100ms per evaluation\n",
    "    }[model_complexity]\n",
    "    \n",
    "    total_evals = n_particles * n_iterations\n",
    "    total_time_seconds = total_evals * time_per_eval\n",
    "    \n",
    "    # Add overhead (30%)\n",
    "    total_time_seconds *= 1.3\n",
    "    \n",
    "    hours = int(total_time_seconds // 3600)\n",
    "    minutes = int((total_time_seconds % 3600) // 60)\n",
    "    \n",
    "    # Memory estimate (very rough)\n",
    "    memory_per_particle_mb = 10  # Adjust for your model\n",
    "    total_memory_gb = (n_particles * memory_per_particle_mb) / 1024\n",
    "    \n",
    "    print(f\"Resource Estimation:\")\n",
    "    print(f\"  Particles: {n_particles:,}\")\n",
    "    print(f\"  Iterations: {n_iterations:,}\")\n",
    "    print(f\"  Total evaluations: {total_evals:,}\")\n",
    "    print(f\"  Estimated time: {hours}h {minutes}m\")\n",
    "    print(f\"  Estimated memory: {total_memory_gb:.1f} GB\")\n",
    "    print(f\"\\nRecommended configuration:\")\n",
    "    \n",
    "    if hours < 1:\n",
    "        print(f\"  Profile: debug or small\")\n",
    "    elif hours < 2:\n",
    "        print(f\"  Profile: small or medium\")\n",
    "    elif hours < 4:\n",
    "        print(f\"  Profile: medium or large\")\n",
    "    else:\n",
    "        print(f\"  Profile: large or production\")\n",
    "\n",
    "# Example estimations\n",
    "print(\"Small job:\")\n",
    "estimate_resources(100, 500, \"medium\")\n",
    "print(\"\\n\" + \"=\" * 60 + \"\\n\")\n",
    "print(\"Large job:\")\n",
    "estimate_resources(1000, 2000, \"complex\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troubleshooting\n",
    "\n",
    "### Common Issues and Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "troubleshooting = {\n",
    "    \"Job stays in queue\": [\n",
    "        \"Check partition availability: sinfo\",\n",
    "        \"Check your priority: sprio -j <job_id>\",\n",
    "        \"Reduce resource requests (nodes, time, memory)\",\n",
    "        \"Use different partition or QoS\"\n",
    "    ],\n",
    "    \"Job fails immediately\": [\n",
    "        \"Check error log: logs/jobname_<id>.err\",\n",
    "        \"Verify modules load correctly\",\n",
    "        \"Check Python environment is activated\",\n",
    "        \"Test script locally first\"\n",
    "    ],\n",
    "    \"Out of memory\": [\n",
    "        \"Increase memory_per_cpu in config\",\n",
    "        \"Reduce particles per device\",\n",
    "        \"Use batch processing\",\n",
    "        \"Check for memory leaks\"\n",
    "    ],\n",
    "    \"Timeout before completion\": [\n",
    "        \"Increase time_limit in config\",\n",
    "        \"Optimize model computation\",\n",
    "        \"Use checkpointing\",\n",
    "        \"Reduce iterations or particles\"\n",
    "    ],\n",
    "    \"Inter-node communication fails\": [\n",
    "        \"Check network_interface setting\",\n",
    "        \"Verify coordinator_port is open\",\n",
    "        \"Check firewall rules\",\n",
    "        \"Test with single node first\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"Troubleshooting Guide:\")\n",
    "print(\"=\" * 60)\n",
    "for issue, solutions in troubleshooting.items():\n",
    "    print(f\"\\n{issue}:\")\n",
    "    for solution in solutions:\n",
    "        print(f\"  • {solution}\")\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Topics\n",
    "\n",
    "### GPU Configuration\n",
    "\n",
    "For GPU clusters, use specialized configs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_config_yaml = \"\"\"\n",
    "name: gpu_cluster\n",
    "nodes: 4\n",
    "cpus_per_node: 16\n",
    "memory_per_cpu: \"8G\"\n",
    "time_limit: \"02:00:00\"\n",
    "partition: \"gpu\"\n",
    "platform: \"gpu\"\n",
    "gpus_per_node: 4\n",
    "\n",
    "env_vars:\n",
    "  JAX_PLATFORMS: \"gpu\"\n",
    "  CUDA_VISIBLE_DEVICES: \"0,1,2,3\"\n",
    "  XLA_PYTHON_CLIENT_MEM_FRACTION: \"0.8\"\n",
    "\n",
    "modules_to_load:\n",
    "  - \"cuda/11.8\"\n",
    "  - \"cudnn/8.6\"\n",
    "\"\"\"\n",
    "\n",
    "with open(\"slurm_configs/gpu_cluster.yaml\", \"w\") as f:\n",
    "    f.write(gpu_config_yaml)\n",
    "\n",
    "print(\"Created GPU cluster configuration\")\n",
    "print(\"\\nKey GPU settings:\")\n",
    "print(\"  • platform: gpu\")\n",
    "print(\"  • gpus_per_node: 4\")\n",
    "print(\"  • JAX_PLATFORMS: gpu\")\n",
    "print(\"  • CUDA modules loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Variables Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_vars_reference = {\n",
    "    \"JAX Configuration\": {\n",
    "        \"JAX_PLATFORMS\": \"Set to 'cpu' or 'gpu'\",\n",
    "        \"JAX_ENABLE_X64\": \"Enable 64-bit precision (1 or 0)\",\n",
    "        \"JAX_COORDINATOR_PORT\": \"Port for distributed coordinator\",\n",
    "    },\n",
    "    \"XLA Configuration\": {\n",
    "        \"XLA_FLAGS\": \"XLA compiler flags\",\n",
    "        \"XLA_PYTHON_CLIENT_PREALLOCATE\": \"Preallocate GPU memory (true/false)\",\n",
    "        \"XLA_PYTHON_CLIENT_MEM_FRACTION\": \"Fraction of GPU memory to use (0-1)\",\n",
    "    },\n",
    "    \"CUDA Configuration\": {\n",
    "        \"CUDA_VISIBLE_DEVICES\": \"Which GPUs to use (e.g., '0,1,2,3')\",\n",
    "        \"NCCL_SOCKET_IFNAME\": \"Network interface for NCCL (e.g., 'ib0')\",\n",
    "    },\n",
    "    \"SLURM Variables\" : {\n",
    "        \"SLURM_COORDINATOR_ADDRESS\": \"Set by script (coordinator hostname)\",\n",
    "        \"SLURM_JOB_ID\": \"Auto-set by SLURM\",\n",
    "        \"SLURM_PROCID\": \"Auto-set by SLURM (process rank)\",\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Environment Variables Reference:\")\n",
    "print(\"=\" * 60)\n",
    "for category, vars in env_vars_reference.items():\n",
    "    print(f\"\\n{category}:\")\n",
    "    for var, desc in vars.items():\n",
    "        print(f\"  {var}\")\n",
    "        print(f\"    {desc}\")\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This guide covered:\n",
    "\n",
    "**Configuration management** - YAML-based cluster configs\n",
    "\n",
    "**Predefined profiles** - Quick start with standard setups\n",
    "\n",
    "**Script generation** - Automatic SLURM script creation\n",
    "\n",
    "**Workflow best practices** - From development to production\n",
    "\n",
    "**Troubleshooting** - Common issues and solutions\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "1. **Start with predefined profiles** for quick testing\n",
    "2. **Create cluster-specific configs** for production\n",
    "3. **Use script generator** to avoid manual SBATCH setup\n",
    "4. **Test incrementally** (local → debug → small → production)\n",
    "5. **Monitor resources** to optimize configuration\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- **[Distributed Computing Basics](distributed_computing_basics.ipynb)** - Learn the fundamentals\n",
    "- **[Distributed SVGD Inference](distributed_svgd_inference.ipynb)** - Apply to inference problems\n",
    "- **[API Reference](../api/index.html)** - Complete API documentation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
