[
  {
    "objectID": "pages/laplace.html",
    "href": "pages/laplace.html",
    "title": "Laplace transform",
    "section": "",
    "text": "These pages are under construction",
    "crumbs": [
      "Basics",
      "Laplace transform"
    ]
  },
  {
    "objectID": "pages/epochs.html",
    "href": "pages/epochs.html",
    "title": "Epochs",
    "section": "",
    "text": "This pages is under construction",
    "crumbs": [
      "Advanced",
      "Epochs"
    ]
  },
  {
    "objectID": "pages/state_space.html",
    "href": "pages/state_space.html",
    "title": "State space",
    "section": "",
    "text": "The state-space is built as a graph using an simple API and take up very little space compared to a matrix representation. It handles millions of vertices (states) and edges (transitions) and is munch faster than the traditional matrix-based computation relying on (sparse) matrix inversion and exponentiation.\nConsider this model: Rabbits jump between two islands at a rate of one. The two islands are flooded at rates 2 and 4 drowning all rabbits on the flooded island. The end (absorbing) is when no more rabbits are left.\nIn ptdalgorithms, each state is represented by a sequence of integers. To represent states in the rabbit model, we only need two such integer to represent the number of rabbits on the left and right islands. Laid out as in the above picture, the states are:\nTo skip some of the boilerplate you can pass a callback function and an initial state to Graph. The callback function must take as the only argument a list of int representing a state, and return: a list of tuples that each represent reachable child state and the associated transition rate. To create a callback function, just think of rules of your model and ask yourself:\nHere is an example for our rabbit model: If the current state is “two rabbits on the left island” ([2, 0]), the reachable states are: “one rabbit on each island” ([1, 1]) if one rabbit jumps and and “no rabbits” ([0, 0]) if the island is flodded. So if the callback function is called like this:\nit should return\nTogether, the callback and initial state fully specifies the model. Here is what they look like for the rabbit model:\nnr_rabbits, flood_left, flood_right = 2, 2, 4\n\ndef rabbit_islands(state):\n    nr_left, nr_right = state\n    reachable = []\n    if state[0] &gt; 0:\n        reachable.append(([nr_left-1, nr_right+1], 1))\n        reachable.append(([0,         nr_right  ], flood_left))\n    if state[1] &gt; 0:   \n        reachable.append(([nr_left+1, nr_right-1], 1))\n        reachable.append(([nr_left,   0         ], flood_right))\n    return reachable\n\ninitial_state = [nr_rabbits, 0]\nTo then build the state space all you need to do is:\nimport ptdalgorithms as ptd\n\ngraph = ptd.Graph(callback=rabbit_islands, initial=initial_state)\nPlot it to make sure it looks as expected. The gray S state is the “starting state” immediately transiting one or more model states where the model is allowed to begin. In the rabbit model, S goes to state 2,0 with probability 1 because the model can only begin there. The end (absorbing) state 0,0 is also colored gray.\ngraph.plot()",
    "crumbs": [
      "Basics",
      "State space"
    ]
  },
  {
    "objectID": "pages/state_space.html#off-to-the-races",
    "href": "pages/state_space.html#off-to-the-races",
    "title": "State space",
    "section": "Off to the races",
    "text": "Off to the races\nNow the world is at your command. To scratch the surfance you can compute the expected time to rabbit extinction:\n\ngraph.expectation()\n\n0.5038265306122448\n\n\nbut there is so much more you can do to explore your rabbit model. For a full exposé of the API using the rabbit example see the full python API example.\n\n\n\n\n\n\nThis pages is under construction",
    "crumbs": [
      "Basics",
      "State space"
    ]
  },
  {
    "objectID": "pages/state_space.html#learning-more",
    "href": "pages/state_space.html#learning-more",
    "title": "State space",
    "section": "Learning more",
    "text": "Learning more\n\nSee Python API walk through for a full example of the Python API.\nSee R API walk through for a full example of the R API.",
    "crumbs": [
      "Basics",
      "State space"
    ]
  },
  {
    "objectID": "pages/state_space.html#citing-ptdalgorithms",
    "href": "pages/state_space.html#citing-ptdalgorithms",
    "title": "State space",
    "section": "Citing ptdalgorithms",
    "text": "Citing ptdalgorithms\nGraph-based algorithms for phase-type distributions, Statistics and Computing (2022)",
    "crumbs": [
      "Basics",
      "State space"
    ]
  },
  {
    "objectID": "pages/coalescent_showcase.html",
    "href": "pages/coalescent_showcase.html",
    "title": "The coalescent",
    "section": "",
    "text": "import ptdalgorithms as ptd\n\nAnother example is the Coalescent, fully specified with only the code below:\n\ndef coalescent(state):\n    transitions = []\n    for i in range(nr_samples):\n        for j in range(i, nr_samples):            \n            same = int(i == j)\n            if same and state[i] &lt; 2:\n                continue\n            if not same and (state[i] &lt; 1 or state[j] &lt; 1):\n                continue \n            new = state[:]\n            new[i] -= 1\n            new[j] -= 1\n            new[i+j+1] += 1\n            transitions.append((new, state[i]*(state[j]-same)/(1+same)))\n    return transitions\n\nnr_samples = 4\ngraph = ptd.Graph(callback=coalescent, initial=[nr_samples]+[0]*nr_samples)\ngraph.plot()\n\n\n\n\n\n\n\n\nComputing the expected TMRCA is then just:\n\ngraph.expectation()\n\nINFO: building reward compute graph...\n\n\n1.5\n\n\nThe graph grows quickly with the number of samples:\n\nnr_samples = 15\ngraph = ptd.Graph(callback=coalescent, initial=[nr_samples]+[0]*nr_samples)\ngraph.plot()\n\n\n\n\n\n\n\n\n\ngraph.expectation()\n\nINFO: building reward compute graph...\n\n\n1.866666666666666\n\n\n\n\n\n\n\n\nThis pages is under construction"
  },
  {
    "objectID": "pages/distributions.html",
    "href": "pages/distributions.html",
    "title": "Distributions",
    "section": "",
    "text": "This pages is under construction",
    "crumbs": [
      "Basics",
      "Distributions"
    ]
  },
  {
    "objectID": "r_api/index.html",
    "href": "r_api/index.html",
    "title": "ptdalgorithms",
    "section": "",
    "text": "These pages are under construction"
  },
  {
    "objectID": "examples/python/two-island-two-locus-arg.html",
    "href": "examples/python/two-island-two-locus-arg.html",
    "title": "ptdalgorithms",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nnp.random.seed(42)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%config InlineBackend.figure_format = 'retina'\nimport ptdalgorithms as ptd\n\n\nmake_discrete &lt;- function(mutation_graph, mutation_rate) {\n    # Takes a graph for a continuous distribution and turns\n    # it into a descrete one (inplace). Returns a matrix of\n    # rewards for computing marginal moments\n\n    # current nr of states in graph\n    vlength &lt;- vertices_length(mutation_graph)\n\n    # number of fields in state vector (assumes all are the same length)\n    state_vector_length &lt;- length(vertex_at(mutation_graph, 1)$state)\n\n    # list state vector fields to reward at each auxiliary node\n    rewarded_state_vector_indexes &lt;- vector(mode = \"list\", length = state_vector_length)\n\n    # loop all but starting node\n    for (i in 2:vlength) {\n        vertex &lt;- vertex_at(mutation_graph,i)\n        if (vertex$rate &gt; 0) { # not absorbing\n            for (j in 1:length(vertex$state)) {\n                val &lt;- vertex$state[j]\n                if (val &gt; 0) { # only ones we may reward\n                    # add auxilliary node\n                    mutation_vertex &lt;- create_vertex(mutation_graph, rep(0, state_vector_length))\n                    add_edge(mutation_vertex, vertex, 1)\n                    add_edge(vertex, mutation_vertex, mutation_rate*val)\n\n                    rewarded_state_vector_indexes[[mutation_vertex$index]] &lt;- c(rewarded_state_vector_indexes[[j]], j)\n                }\n            }\n        }\n    }\n    # normalize graph\n    weights_were_multiplied_with &lt;- normalize_graph(mutation_graph)\n\n    # build reward matrix\n    rewards &lt;- matrix(nrow=vertices_length(mutation_graph),ncol=state_vector_length, 0)\n    for (state in seq_along(rewarded_state_vector_indexes)) {\n        for (i in rewarded_state_vector_indexes[[state]]) {\n            rewards[state, i] &lt;- 1\n        }\n    }\n    rewards = t(rewards)\n    return(rewards)\n}\n# # self-transition rate:\n# mutation_rate &lt;- 0.0001\n\n# # clone graph to get one to modify:\n# mutation_graph &lt;- clone_graph(graph)\n\n# # add auxilliary states, normalize and return reward matrix:\n# rewards &lt;- make_discrete(mutation_graph, mutation_rate)\n\n# # for plotting the new graph\n# gam &lt;- graph_as_matrix(mutation_graph)\n\n# vertices_length(mutation_graph)"
  },
  {
    "objectID": "examples/python/coalescent-jointprob.html",
    "href": "examples/python/coalescent-jointprob.html",
    "title": "Joint probability and FMC embedding",
    "section": "",
    "text": "import sys\nimport pandas as pd\nfrom collections import defaultdict\nimport numpy as np\nnp.random.seed(42)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_context(\"paper\")\nplt.style.use('dark_background')\n\nimport matplotlib as mpl\nscale = 0.8\nd = dict([(k, v*scale) for (k, v) in sns.plotting_context('paper').items()])\nd['figure.figsize'] = [5.4, 3.5]\nd['axes.facecolor'] = '#1F1F1F'\nd['figure.facecolor'] = '#1F1F1F'\nmpl.rcParams.update(d)\n\n%config InlineBackend.figure_format = 'retina'\n\nimport ptdalgorithms as ptd\nptd.plot.set_theme('dark')"
  },
  {
    "objectID": "examples/python/coalescent-jointprob.html#example-model-coalescent",
    "href": "examples/python/coalescent-jointprob.html#example-model-coalescent",
    "title": "Joint probability and FMC embedding",
    "section": "Example model: Coalescent",
    "text": "Example model: Coalescent\n\ndef coalescent(state, nr_samples=None):\n    if not state.size:\n        ipv = [([nr_samples]+[0]*nr_samples, 1)]\n        return ipv\n    else:\n        transitions = []\n        for i in range(nr_samples):\n            for j in range(i, nr_samples):            \n                same = int(i == j)\n                if same and state[i] &lt; 2:\n                    continue\n                if not same and (state[i] &lt; 1 or state[j] &lt; 1):\n                    continue \n                new = state.copy()\n                new[i] -= 1\n                new[j] -= 1\n                new[i+j+1] += 1\n                transitions.append((new, state[i]*(state[j]-same)/(1+same)))\n        return transitions\n\ngraph = ptd.Graph(callback=coalescent, nr_samples=4)\n\ngraph.plot()\n\n\n\n\n\n\n\n\n\ngraph.expectation()\n\nINFO: building reward compute graph...\n\n\n1.4999999999999996\n\n\n\nrewards = graph.states().T\nrewards\n\narray([[0, 4, 2, 0, 1, 0],\n       [0, 0, 1, 2, 0, 0],\n       [0, 0, 0, 0, 1, 0],\n       [0, 0, 0, 0, 0, 1],\n       [0, 0, 0, 0, 0, 0]], dtype=int32)\n\n\n\nsfs = np.apply_along_axis(graph.expectation, 1, rewards)\nsns.barplot(sfs) ;"
  },
  {
    "objectID": "examples/python/coalescent-jointprob.html#make-discrete",
    "href": "examples/python/coalescent-jointprob.html#make-discrete",
    "title": "Joint probability and FMC embedding",
    "section": "Make discrete",
    "text": "Make discrete\nTurn state space for a continuous PTD into one for a discrete.\n\ndef make_discrete(mutation_graph, mutation_rate, skip_states=[], skip_slots=[]):\n    \"\"\"\n    Takes a graph for a continuous distribution and turns\n    it into a descrete one (inplace). Returns a matrix of\n    rewards for computing marginal moments\n    \"\"\"\n\n    mutation_graph = graph.copy()\n\n    # save current nr of states in graph\n    vlength = mutation_graph.vertices_length()\n\n    # number of fields in state vector (assumes all are the same length)\n    state_vector_length = len(mutation_graph.vertex_at(1).state())\n\n    # list state vector fields to reward at each auxiliary node\n    # rewarded_state_vector_indexes = [[] for _ in range(state_vector_length)]\n    rewarded_state_vector_indexes = defaultdict(list)\n\n    # loop all but starting node\n    for i in range(1, vlength):\n        if i in skip_states:\n            continue\n        vertex = mutation_graph.vertex_at(i)\n        if vertex.rate() &gt; 0: # not absorbing\n            for j in range(state_vector_length):\n                if j in skip_slots:\n                    continue\n                val = vertex.state()[j]\n                if val &gt; 0: # only ones we may reward\n                    # add auxilliary node\n                    mutation_vertex = mutation_graph.create_vertex(np.repeat(0, state_vector_length))\n                    mutation_vertex.add_edge(vertex, 1)\n                    vertex.add_edge(mutation_vertex, mutation_rate*val)\n                    # print(mutation_vertex.index(), rewarded_state_vector_indexes[j], j)\n                    # rewarded_state_vector_indexes[mutation_vertex.index()] = rewarded_state_vector_indexes[j] + [j]\n                    rewarded_state_vector_indexes[mutation_vertex.index()].append(j)\n\n    # print(rewarded_state_vector_indexes)\n\n    # normalize graph\n    weights_were_multiplied_with = mutation_graph.normalize()\n\n    # build reward matrix\n    rewards = np.zeros((mutation_graph.vertices_length(), state_vector_length))\n    for state in rewarded_state_vector_indexes:\n        for i in rewarded_state_vector_indexes[state]:\n            rewards[state, i] = 1\n\n    rewards = np.transpose(rewards)\n    return mutation_graph, rewards\n\n\n\ngraph = ptd.Graph(callback=coalescent, nr_samples=3)\n\n# self-transition rate:\n# mutation_rate = 1e-8\nmutation_rate = 0.1\n\n# # clone graph to get one to modify:\n# mutation_graph = graph.copy()\n\n# add auxilliary states, normalize and return reward matrix:\nmutation_graph, rewards = make_discrete(graph, mutation_rate)\n\n# print(mutation_graph.expectation())\n# print([mutation_graph.expectation(r) for r in rewards])\n\n# print(rewards)\nmutation_graph.plot()\n\n\n# from functools import wraps\n\n# def discrete(mutation_rate, skip_states=[], skip_slots=[]):\n#     def decorator(graph_constructor):\n#         @wraps(graph_constructor)\n#         def wrapper(*args, **kwargs):\n#             graph = graph_constructor(*args, **kwargs)\n#             rewards = make_discrete(graph, mutation_rate)\n#             return rewards\n#         return wrapper\n#     return decorator\n    \n# @discrete(mutation_rate=1)\n# def foo():    \n#     return coalescent(4)\n\n\n# rewards = foo()\n# rewards\n\n\n\n\n\n\n\n\n\ndiscrete_graph, discrete_rewards= graph.discretize(reward_rate=0.1)\n\n\nmutation_graph.states()\n\narray([[0, 0, 0, 0],\n       [3, 0, 0, 0],\n       [1, 1, 0, 0],\n       [0, 0, 1, 0],\n       [0, 0, 0, 0],\n       [0, 0, 0, 0],\n       [0, 0, 0, 0]], dtype=int32)\n\n\n\nrewards\n\narray([[0., 0., 0., 0., 1., 1., 0.],\n       [0., 0., 0., 0., 0., 0., 1.],\n       [0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0.]])\n\n\n\ngraph.expectation() * 0.1\n\nINFO: building reward compute graph...\n\n\n0.13333333333333333\n\n\n\ngraph.expectation(np.sum(mutation_graph.states(), axis=0) * 0.1), \n\n(0.13333333333333333,)\n\n\n\nsfs = np.apply_along_axis(mutation_graph.expectation_discrete, 1, rewards)\nsns.barplot(sfs) ;\n\nINFO: building reward compute graph...\n\n\n\n\n\n\n\n\n\n\nsns.barplot(mutation_graph.pdf(np.arange(10)))\nsns.despine()"
  },
  {
    "objectID": "examples/python/coalescent-jointprob.html#discrete-joint-prob",
    "href": "examples/python/coalescent-jointprob.html#discrete-joint-prob",
    "title": "Joint probability and FMC embedding",
    "section": "Discrete joint prob",
    "text": "Discrete joint prob\n\n\ndef discrete_joint_prob(_graph, reward_rates, precision=1e-15, return_fun=False, return_graph=False):\n\n    starting_vertex = graph.starting_vertex()\n    reward_dims = len(reward_rates(starting_vertex.state())) - 1 # a bit of a hack. -1 to not count trash rate...\n\n    orig_state_vector_length = len(graph.vertex_at(1).state())\n    state_vector_length = orig_state_vector_length + reward_dims\n\n    state_indices = np.arange(orig_state_vector_length)\n    reward_indices = np.arange(orig_state_vector_length, state_vector_length)\n\n    new_graph = ptd.Graph(state_vector_length)\n    # new_starting_vertex = new_graph.vertex_at(1)\n    new_starting_vertex = new_graph.starting_vertex()\n\n    null_rewards = np.zeros(reward_dims)\n\n    index = 0\n    # add edges from starting vertex (IPV)\n    for edge in starting_vertex.edges():\n        new_starting_vertex.add_edge(\n          new_graph.find_or_create_vertex(np.append(edge.to().state(), null_rewards).astype(int)), 1)\n\n    index = index + 1\n    \n    trash_rates = {}\n    t_vertex_indices = np.array([], dtype=int)\n    while index &lt; new_graph.vertices_length():\n\n        new_vertex = new_graph.vertex_at(index)\n        new_state = new_vertex.state()\n        state = new_vertex.state()[state_indices]\n        vertex = graph.find_vertex(state)\n\n        # non-mutation transitions (coalescence)\n        for edge in vertex.edges():\n            new_child_state = np.append(edge.to().state(), new_state[reward_indices])\n\n            if np.all(new_state == new_child_state):\n                continue\n                \n            new_child_vertex = new_graph.find_or_create_vertex(new_child_state)\n            # cat(new_child_vertex$state, \"\\n\")\n            new_vertex.add_edge(new_child_vertex, # if I use create_vertex here, I cannot find it again with find_vertex...\n                edge.weight()\n            )\n\n            # if new child was absorbing, record at \"t-states\":\n            if not graph.find_vertex(new_child_state[state_indices]).edges():\n                t_vertex_indices = np.append(t_vertex_indices, new_child_vertex.index()) \n\n        # mutation transitions\n        current_state = new_state[state_indices]\n        current_rewards = new_state[reward_indices]\n        rates = reward_rates(current_state, current_rewards) # list of all allowed mutation transition rates with trash rate appended\n\n        trash_rates[index] = rates[reward_dims]\n        for i in range(reward_dims):\n            rate = rates[i]\n            if rate &gt; 0:\n                new_rewards = current_rewards\n                new_rewards[i] = new_rewards[i] + 1\n                new_child_vertex = new_graph.find_or_create_vertex(np.append(current_state, new_rewards))\n                # stopifnot(sum(new_child_vertex$state) &gt; 4)\n                # cat(new_child_vertex$state, \"\\n\")\n                new_vertex.add_edge(\n                    new_child_vertex, # if I use create_vertex here, I cannot find it again with find_vertex...\n                    rate\n                    )\n                \n                # # if new child was absorbing, record at \"t-states\":                \n                # if (length(edges(find_vertex(graph, new_child_state[state_indices]))) == 0) {\n                #     t_vertex_indices = c(t_vertex_indices, new_child_vertex$index) \n\n        index = index + 1 \n\n        if not index % 10_000:\n            graph_size = new_graph.vertices_length()\n            print(f'index: {index:&gt;6}      vertices: {graph_size:&gt;6}      ratio: {graph_size/index:&gt;4.2}', file=sys.stderr)\n            sys.stderr.flush()\n\n    # trash states\n    trash_vertex = new_graph.find_or_create_vertex(np.repeat(0, state_vector_length))\n    trash_loop_vertex = new_graph.create_vertex(np.repeat(0, state_vector_length))\n    trash_vertex.add_edge(trash_loop_vertex, 1)\n    trash_loop_vertex.add_edge(trash_vertex, 1)\n\n    # add trash edges\n    for i, rate in trash_rates.items():\n        new_graph.vertex_at(i).add_edge(trash_vertex, rate) \n\n    # add edges from t-states to new final absorbing\n    new_absorbing = new_graph.create_vertex(np.repeat(0, state_vector_length))\n\n    t_vertex_indices = np.unique(t_vertex_indices)\n    \n    for i in t_vertex_indices:\n        new_graph.vertex_at(i).add_edge(new_absorbing, 1)\n\n    # normalize graph                            \n    weights_were_multiplied_with = new_graph.normalize()\n\n    if return_graph:                           \n        return(new_graph)                                             \n\n    # time spent in each of the the t-states at time stop or after some appropriately large time (these are the joint probs)\n\n    prev = None\n    for decade in range(1000):\n        accum_time_all = new_graph.accumulated_visiting_time(decade*10)\n        accum_time = np.array(accum_time_all)[t_vertex_indices]\n        if prev is not None and np.all(np.abs(accum_time - prev) &lt; precision):\n            break\n        prev = accum_time\n\n    assert decade &lt; 100\n\n    class Fun():\n\n        def __init__(self, new_graph, t_vertex_indices):\n            self.new_graph = new_graph\n            self.t_vertex_indices = t_vertex_indices\n\n        def __call__(self, tup):\n\n        # def __call__(self, stop):\n        #     accum_time_all = self.new_graph.accumulated_visiting_time(stop)\n        #     accum_time = np.array(accum_time_all)[self.t_vertex_indices]\n\n        #     states = new_graph.states()\n        #     state_reward_matrix = states[self.t_vertex_indices, :][:, reward_indices]\n        #     joint_probs = pd.DataFrame(state_reward_matrix)\n        #     index_cols = joint_probs.columns.values.tolist()\n        #     joint_probs['time'] = stop\n        #     joint_probs['prob'] = accum_time\n        #     joint_probs.set_index(index_cols, inplace=True)\n\n            return joint_probs \n\n    fun = Fun(new_graph, t_vertex_indices)\n\n    if return_fun:\n        return fun\n\n    return fun(decade*10).drop(columns='time')\n\n    # I can test if the graph is acyclic and if so, use accumulated_residence_time instead?\n\n\ngraph = ptd.Graph(callback=coalescent, nr_samples=4)\ngraph.plot()\n\n\n\n\n\n\n\n\n\ngraph.variance()\n\nINFO: building reward compute graph...\n\n\n1.1388888888888893\n\n\n\n# gam = graph.as_matrices()\n# gam\n\n\ngraph.plot()\n\n\n\n\n\n\n\n\n\ngraph.pdf(10)\n\n8.140105759241116e-05\n\n\n\ngraph.plot(\n            nodesep=0.5,\n             subgraphfun=lambda state: 'has singletons' if np.all(state[0] &gt; 0) else 'no singletons',\n               )\n\n\n\n\n\n\n\n\n\ndef reward_callback(state, current_rewards=None, mutation_rate=1, reward_limit=10, tot_reward_limit=np.inf):\n\n    reward_limits = np.append(np.repeat(reward_limit, len(state)-1), 0)\n    \n    reward_dims = len(reward_limits)\n    if current_rewards is None:\n        current_rewards = np.zeros(reward_dims)\n\n    reward_rates = np.zeros(reward_dims)\n    trash_rate = 0\n    \n    for i in range(reward_dims):\n        rate = state[i] * mutation_rate \n        r = np.zeros(reward_dims)\n        r[i] = 1\n        if np.all(current_rewards + r &lt;= reward_limits) and np.sum(current_rewards + r) &lt;= tot_reward_limit:\n            reward_rates[i] = rate\n        else:\n            trash_rate = trash_rate + rate\n\n    return np.append(reward_rates, trash_rate)\n\njoint_probs = discrete_joint_prob(graph, reward_callback)\n\njoint_probs    \n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[21], line 23\n     19             trash_rate = trash_rate + rate\n     21     return np.append(reward_rates, trash_rate)\n---&gt; 23 joint_probs = discrete_joint_prob(graph, reward_callback)\n     25 joint_probs    \n\nCell In[14], line 145, in discrete_joint_prob(_graph, reward_rates, precision, return_fun, return_graph)\n    142 if return_fun:\n    143     return fun\n--&gt; 145 return fun(decade*10).drop(columns='time')\n\nCell In[14], line 138, in discrete_joint_prob.&lt;locals&gt;.Fun.__call__(self, tup)\n    124 def __call__(self, tup):\n    125 \n    126 # def __call__(self, stop):\n   (...)\n    135 #     joint_probs['prob'] = accum_time\n    136 #     joint_probs.set_index(index_cols, inplace=True)\n--&gt; 138     return joint_probs\n\nNameError: name 'joint_probs' is not defined\n\n\n\n\ndef reward_callback(state, current_rewards=None, mutation_rate=1, reward_limit=10, tot_reward_limit=np.inf):\n\n    reward_limits = np.append(np.repeat(reward_limit, len(state)-1), 0)\n    \n    reward_dims = len(reward_limits)\n    if current_rewards is None:\n        current_rewards = np.zeros(reward_dims)\n\n    reward_rates = np.zeros(reward_dims)\n    trash_rate = 0\n    \n    for i in range(reward_dims):\n        rate = state[i] * mutation_rate \n        r = np.zeros(reward_dims)\n        r[i] = 1\n        if np.all(current_rewards + r &lt;= reward_limits) and np.sum(current_rewards + r) &lt;= tot_reward_limit:\n            reward_rates[i] = rate\n        else:\n            trash_rate = trash_rate + rate\n\n    return np.append(reward_rates, trash_rate)\n\n\ndef joint_pmf(graph, rate_fun, reward_limit=10):\n    \"\"\"\n    Returns a joint probability mass function for the graph\n    \"\"\"\n\n    def reward_callback(state, current_rewards=None, mutation_rate=1, reward_limit=10):\n\n        reward_limits = np.append(np.repeat(reward_limit, len(state)-1), 0)\n        \n        reward_dims = len(reward_limits)\n        if current_rewards is None:\n            current_rewards = np.zeros(reward_dims)\n\n        reward_rates = np.zeros(reward_dims)\n        trash_rate = 0\n        \n        for i in range(reward_dims):\n            rate = rate_fun(state[i])\n            r = np.zeros(reward_dims)\n            r[i] = 1\n            if np.all(current_rewards + r &lt;= reward_limits):\n                reward_rates[i] = rate\n            else:\n                trash_rate = trash_rate + rate\n\n        return np.append(reward_rates, trash_rate)\n\n    return discrete_joint_prob(graph, reward_callback, return_fun=True)\n\n\n\nfun = joint_pmf(graph, lambda x: x*1, reward_limit=10)\nfun\n\n\njoint_probs.at[(0, 1, 0, 0, 0), 'prob']\n\n0.0222222222222207\n\n\n\ndef joint_pmf(graph, reward_callback):\n    df = \n    df.loc[(0, 1, 0, 0)]\n\n\noutcomes = np.matrix(list(map(list, joint_probs.index.values)))\nprobs = joint_probs['prob'].values\nwith_deficit = probs @ outcomes\nwith_deficit = with_deficit[:,:nr_samples-1]\nno_deficit = np.matrix([2/x for x in range(1, 4)])\ndeficit = (no_deficit - with_deficit) / no_deficit\ndeficit\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[36], line 4\n      2 probs = joint_probs['prob'].values\n      3 with_deficit = probs @ outcomes\n----&gt; 4 with_deficit = with_deficit[:,:nr_samples-1]\n      5 no_deficit = np.matrix([2/x for x in range(1, 4)])\n      6 deficit = (no_deficit - with_deficit) / no_deficit\n\nNameError: name 'nr_samples' is not defined\n\n\n\n\njoint_prob_at_time = discrete_joint_prob(graph, reward_rates, return_fun=True)\njoint_prob_at_time\n\n&lt;__main__.discrete_joint_prob.&lt;locals&gt;.Fun at 0x10900b390&gt;\n\n\n\ndf = pd.concat([joint_prob_at_time(t) for t in np.arange(1, 10, 1)])\ndf.head(20)\n\n\n\n\n\n\n\n\n\n\n\n\ntime\nprob\n\n\n0\n1\n2\n3\n4\n\n\n\n\n\n\n0\n0\n0\n0\n0\n1\n0.001899\n\n\n1\n0\n0\n0\n1\n0.000081\n\n\n1\n0\n0\n0\n0\n1\n0.000349\n\n\n1\n0\n0\n1\n0.000095\n\n\n1\n0\n0\n0\n1\n0.000078\n\n\n1\n0\n0\n1\n0.000002\n\n\n0\n0\n0\n0\n0\n2\n0.014296\n\n\n1\n0\n0\n0\n2\n0.001170\n\n\n1\n0\n0\n0\n0\n2\n0.005031\n\n\n1\n0\n0\n2\n0.001562\n\n\n1\n0\n0\n0\n2\n0.001349\n\n\n1\n0\n0\n2\n0.000074\n\n\n0\n0\n0\n0\n0\n3\n0.035299\n\n\n1\n0\n0\n0\n3\n0.004107\n\n\n1\n0\n0\n0\n0\n3\n0.017660\n\n\n1\n0\n0\n3\n0.006096\n\n\n1\n0\n0\n0\n3\n0.005474\n\n\n1\n0\n0\n3\n0.000402\n\n\n0\n0\n0\n0\n0\n4\n0.056682\n\n\n1\n0\n0\n0\n4\n0.008252\n\n\n\n\n\n\n\n\ndf.pivot(columns='time')\n\n\n\n\n\n\n\n\n\n\n\n\nprob\n\n\n\n\n\n\ntime\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n0\n1\n2\n3\n4\n\n\n\n\n\n\n\n\n\n\n\n\n\n0\n0\n0\n0\n0\n0.001899\n0.014296\n0.035299\n0.056682\n0.073525\n0.084901\n0.091839\n0.095772\n0.097883\n\n\n1\n0\n0\n0\n0.000081\n0.001170\n0.004107\n0.008252\n0.012439\n0.015893\n0.018383\n0.020012\n0.021003\n\n\n1\n0\n0\n0\n0\n0.000349\n0.005031\n0.017660\n0.035485\n0.053489\n0.068342\n0.079047\n0.086051\n0.090314\n\n\n1\n0\n0\n0.000095\n0.001562\n0.006096\n0.013347\n0.021546\n0.029038\n0.034965\n0.039188\n0.041969\n\n\n1\n0\n0\n0\n0.000078\n0.001349\n0.005474\n0.012319\n0.020287\n0.027735\n0.033737\n0.038080\n0.040977\n\n\n1\n0\n0\n0.000002\n0.000074\n0.000402\n0.001097\n0.002069\n0.003124\n0.004086\n0.004862\n0.005431\n\n\n\n\n\n\n\n\nnew_graph = discrete_joint_prob(graph, reward_rates, return_graph=True)\n\n\nnew_graph.plot(size=(8, 8), ranksep=0.6, nodesep=0.3, rainbow=True)\n\n\n\n\n\n\n\n\n\n\nnew_graph.plot(size=(8, 8), ranksep=3, nodesep=0.3, rainbow=True,\n    subgraphfun=lambda state: ','.join(map(str, state[:nr_samples])),\n    splines='line',\n)"
  },
  {
    "objectID": "examples/python/coalescent-jointprob.html#finite-markov-chains-fmc",
    "href": "examples/python/coalescent-jointprob.html#finite-markov-chains-fmc",
    "title": "Joint probability and FMC embedding",
    "section": "Finite Markov Chains (FMC)",
    "text": "Finite Markov Chains (FMC)\n\nDistribution of steps spent in a state\n\ndef loop():\n\n    def callback(state):\n        if not state.size:\n            return [([1, 0], 0.5), ([0, 1], 0.5)]\n\n        transitions = []\n\n        if state.sum() &gt; 1:\n            return transitions\n\n        if state[0] == 0:\n            new_state = state.copy()\n            new_state[0] += 1\n            new_state[1] -= 1            \n            transitions.append((new_state, 1))\n        else:\n            new_state = state.copy()\n            new_state[0] -= 1\n            new_state[1] += 1\n            transitions.append((new_state, 1))\n\n        new_state = state.copy()\n        new_state[0] = 9\n        new_state[1] = 9\n        transitions.append((new_state, 1))\n\n        return transitions\n\n    graph = ptd.Graph(callback=callback)\n    return graph\n        \ngraph = loop()\ngraph.plot(rainbow=True)\n\n\n\n\n\n\n\n\n\n\ndef loop_reward_rates(new_state, current_rewards=None, mutation_rate=None, reward_limit=10, tot_reward_limit=5):\n\n    target_state = np.array([0, 1])\n\n    reward_limits = np.append(np.repeat(reward_limit, len(new_state)-1), 0)\n    \n    reward_dims = len(reward_limits)\n    if current_rewards is None:\n        current_rewards = np.zeros(reward_dims)\n\n    result = np.zeros(reward_dims)\n    trash_rate = 0\n    \n    for i in range(reward_dims):\n        rate = new_state[i] * mutation_rate \n        r = np.zeros(reward_dims)\n        r[i] = 1\n        \n        if np.all(new_state == target_state) and np.sum(current_rewards + r) &lt;= tot_reward_limit:\n        # if np.all(current_rewards + r &lt;= reward_limits) and np.sum(current_rewards + r) &lt;= tot_reward_limit:\n            result[i] = rate\n        else:\n            trash_rate = trash_rate + rate\n\n    return np.append(result, trash_rate)\n\n\n# reward_rates = partial(coalescent_reward_rates, mutation_rate=1, reward_limit=1, tot_reward_limit=2)\nreward_rates = partial(loop_reward_rates, mutation_rate=1, reward_limit=2)\n\njoint_probs = discrete_joint_prob(graph, reward_rates)\n\njoint_probs#.head()\n\n\n\n\n\n\n\n\n\nprob\n\n\n0\n1\n\n\n\n\n\n0\n0\n0.500000\n\n\n1\n0.125000\n\n\n2\n0.046875\n\n\n3\n0.017578\n\n\n4\n0.006592\n\n\n5\n0.002472\n\n\n\n\n\n\n\n\ndiscrete_joint_prob(graph, reward_rates, return_graph=True).plot(size=(8, 8), ranksep=1, nodesep=0.5)\n\n\n\n\n\n\n\n\n\n\nNr of runs of a particular state\n\nsample_size = 5\ngraph = coalescent(sample_size)\ngraph.plot(rainbow=True)\n\n\n\n\n\n\n\n\n\n\n\n\nnew_graph = graph.copy()\n\ntarget_vertex = new_graph.vertex_at(5)\n\nnew_vertices = []\nfor vertex in new_graph.vertices():\n    for edge in vertex.edges():\n        if edge.to() == target_vertex:\n            # create new vertex\n            new_vertex = new_graph.find_or_create_vertex(np.repeat(-vertex.index(), vertex.state().size))\n\n            # make edge point that instead\n            edge.update_to(new_vertex)\n\n            # add edge from new_vertex to target_vertex with weight 1\n            new_vertex.add_edge(target_vertex, 1)\n\n            # keep index of added vertex\n            new_vertices.append(new_vertex.index())\n\n# rewards = make_discrete(new_graph, mutation_rate, skip=new_vertices)\nrewards = make_discrete(new_graph, 1, skip_states=new_vertices)\n\nprint(rewards)\n\nrev = np.zeros(new_graph.vertices_length())\nfor i in new_vertices:\n    rev[i] = 1\n\nprint(new_graph.expectation(rev))\n# print(new_graph.accumulated_visiting_time(10))\nprint(new_graph.accumulated_visits_discrete(1000))\n\nnew_graph.plot(rainbow=True, size=(10, 10))\n\n[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n0.5\n[0.0, 1.5, 1.6666666666666654, 0.9999999999999998, 0.9999999999999997, 1.5000000000000009, 1.5000000000000009, 0.0, 0.3333333333333333, 0.16666666666666666, 0.49999999999999983, 0.5000000000000001, 0.16666666666666663, 0.16666666666666666, 0.3333333333333333, 0.3333333333333333, 0.16666666666666666, 0.5, 0.5, 0.5, 0.5]\n\n\nINFO: building reward compute graph...\n\n\n\n\n\n\n\n\n\n\ndef loop(state):\n    if not state.size:\n        return [([1], 1)]\n    elif state[0] &lt; 3:\n        return [(state+1, 4)]\n    return []\n\ngraph = ptd.Graph(callback=loop)\ngraph.plot()\n\n\n\n\n\n\n\n\n\ngraph.expectation(), graph.expected_waiting_time()\n\nINFO: building reward compute graph...\n\n\n(0.5, [0.5, 0.5, 0.25, 0.0])\n\n\n\n\ndiscr_graph, discr_rewards = graph.discretize(reward_rate=1)\ndiscr_graph.plot()\n\n\n\n\n\n\n\n\n\n\n\nINFO: building reward compute graph...\n\n\n(0.5, [0.5, 0.5, 0.25, 0.0])\n\n\n\nnp.sum(discr_rewards, axis=0)\n\narray([0, 0, 0, 0, 1, 1])\n\n\n\ndiscr_graph.expected_waiting_time()\n\n[3.4999999999999996,\n 3.4999999999999996,\n 1.9999999999999996,\n 0.0,\n 4.5,\n 2.9999999999999996]\n\n\n\ndiscr_graph.expectation(np.sum(discr_rewards, axis=0))\n\n0.7499999999999999\n\n\n\nnp.sum(discr_rewards, axis=0)\n\narray([0, 0, 0, 0, 1, 1])\n\n\n\ndiscr_graph.expectation(discr_rewards)\n\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[44], line 1\n----&gt; 1 discr_graph.expectation(discr_rewards)\n\nTypeError: expectation(): incompatible function arguments. The following argument types are supported:\n    1. (self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, rewards: list[float] = []) -&gt; float\n\nInvoked with: &lt;Graph (6 vertices)&gt;, array([[0, 0, 0, 0, 1, 1]])\n\n\n\n\ngraph.expectation(np.sum(discr_rewards, axis=1))\n\narray([2])\n\n\n\ndiscr_graph.expectation(rewards = np.sum(discr_rewards, axis=1))\n#graph.expectation(np.sum(discr_rewards, axis=1) * 0.1)\n\n\n\n\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\nCell In[42], line 1\n----&gt; 1 discr_graph.expectation(rewards = np.sum(discr_rewards, axis=1))\n      2 #graph.expectation(np.sum(discr_rewards, axis=1) * 0.1)\n\nRuntimeError: Failed: Rewards must match the number of vertices. Expected 6, got 1\n\n\n\n\ndef loop():\n\n    def callback(state):\n        transitions = []\n        if state[0] == 0:\n            new_state = state[:]\n            new_state[0] += 1\n            new_state[1] -= 1\n            transitions.append((new_state, 1))\n        else:\n            new_state = state[:]\n            new_state[0] -= 1\n            new_state[1] += 1\n            transitions.append((new_state, 1))\n        return transitions\n\n    graph = ptd.Graph(callback=callback, initial=[1, 0])\n    return graph\n        \ngraph = loop()\ngraph.plot(rainbow=True)\n\n\n\n\n\n\n\n\n\n\nI could add an fmc argument that adds a slot to initial and increments that for all states returned by callback\n\ndef loop():\n\n    def callback(state):\n\n        if not state.size:\n            return [([1, 0, 0], 1)]\n\n        if state[2] == 5:\n            return []\n\n        if state[0] == 0:\n            new_state = state[:]\n            new_state[0] += 1\n            new_state[1] -= 1\n            new_state[2] += 1\n            return [(new_state, 1)]\n        else:\n            new_state = state[:]\n            new_state[0] -= 1\n            new_state[1] += 1\n            new_state[2] += 1\n            return [(new_state, 1)]\n\n    graph = ptd.Graph(callback=callback)\n    return graph\n        \ngraph = loop()\ngraph.plot(rainbow=True)\n\n\n\n\n\n\n\n\n\nrewards = make_discrete(graph, 1, skip_slots=[graph.state_length()-1])\ngraph.plot(rainbow=True)\n\n\n\n\n\n\n\n\n\ngraph.states()\n\narray([[0, 0, 0],\n       [1, 0, 0],\n       [0, 1, 1],\n       [1, 0, 2],\n       [0, 1, 3],\n       [1, 0, 4],\n       [0, 1, 5],\n       [0, 0, 0],\n       [0, 0, 0],\n       [0, 0, 0],\n       [0, 0, 0],\n       [0, 0, 0]], dtype=int32)\n\n\n\ngraph.accumulated_visits_discrete(1000)\n\n[0.0,\n 2.0,\n 1.9999999999999998,\n 2.0,\n 1.9999999999999996,\n 2.0,\n 0.0,\n 1.0,\n 0.9999999999999999,\n 1.0,\n 0.9999999999999998,\n 1.0]\n\n\n\n\nLength of longest run of a state in an FMC\n\n# D: A-&gt;A\n# A: A-&gt;B\n# B: B-&gt;A\n# D: B-&gt;B\n\ndef maxlen():\n\n    def callback(state):\n\n        A, B, C, D = 1, 1, 1, 1\n\n        if not state.size:\n            return [([1, 0, 0], 1)]\n\n        x, y, z = state\n        \n        max_y, max_z = 2, 6\n\n        absorb = (0, max_y, max_z)\n        # absorb = (0, 0, 0)\n        if np.all(state == absorb):\n            return []\n\n        trash1, trash2 = (-1, -1, -1), (-2, -2, -2)\n        # trash1, trash2 = (0, 0, 0), (0, 0, 0)\n        if np.all(state == trash1):\n            return [(trash2, 1)]\n        if np.all(state == trash2):\n            return [(trash1, 1)]\n\n        if z+1 == max_z:\n            return [(absorb, 1)]\n        \n        if y == 0:\n            return [((x, y, z+1), C/(B+C)),\n                    ((x, y+1, z+1), A/(A+D))]\n        if y == max_y:\n            return [(trash1, D/(A+D)), # trash\n                    ((y, 0, z+1), B/(B+C))]\n\n        return [((x, y+1, z+1), D/(A+D)),\n                ((y, 0, z+1), B/(B+C))]\n\n    graph = ptd.Graph(callback=callback)\n    return graph\n        \ngraph = maxlen()\ngraph.plot(rainbow=True, ranksep=1, nodesep=0.3, size=(10, 10))\n\n\n\n\n\n\n\n\n\ngraph.states()\n\narray([[0, 0, 0],\n       [1, 0, 0],\n       [1, 0, 1],\n       [1, 1, 1],\n       [1, 0, 2],\n       [1, 1, 2],\n       [1, 2, 2],\n       [0, 0, 0],\n       [0, 0, 1],\n       [0, 1, 1],\n       [0, 0, 2],\n       [0, 1, 2],\n       [0, 2, 2]], dtype=int32)\n\n\n\njoint_probs %&gt;% filter(V1==1, V2==0, V3==1) \n\n\nA data.frame: 1 × 5\n\n\nV1\nV2\nV3\nV4\naccum_time\n\n\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;dbl&gt;\n\n\n\n\n1\n0\n1\n0\n0.03111111\n\n\n\n\n\nWith sample_size &lt;- 4, mutation_rate &lt;- 1, reward_limits &lt;- rep(20, sample_size-1), and tot_reward_limit &lt;- Inf, tothe marginal probabilities match the SFS:\nc(sum(joint_probs$V1 * joint_probs$accum_time), \n  sum(joint_probs$V2 * joint_probs$accum_time), \n  sum(joint_probs$V3 * joint_probs$accum_time))\n1.99981743759578 0.998152771395828 0.666638375487117\nand the joint prob of a singleton and a trippleton is:\n1   0   1   0.03111111\nwhich is exactly what we also get with reward_limits &lt;- rep(1, sample_size-1).\nSetting tot_reward_limit &lt;- 2 also produces 0.03111111.\n\njoint_probs %&gt;% rename_with(gsub, pattern=\"V\", replacement=\"ton\") %&gt;% group_by(ton1, ton2) %&gt;% summarize(prob=sum(accum_time), .groups=\"keep\")\n\n\nA grouped_df: 4 × 3\n\n\nton1\nton2\nprob\n\n\n&lt;int&gt;\n&lt;int&gt;\n&lt;dbl&gt;\n\n\n\n\n0\n0\n0.12222222\n\n\n0\n1\n0.04259259\n\n\n1\n0\n0.12666667\n\n\n1\n1\n0.03777778\n\n\n\n\n\n\nplot_df &lt;- joint_probs %&gt;% \n    rename_with(gsub, pattern=\"V\", replacement=\"ton\") %&gt;% \n    group_by(ton1, ton2) %&gt;% \n    summarize(prob=sum(accum_time), .groups=\"keep\")\n\nfor (colname in colnames(plot_df)) {\n    if (startsWith(colname, 'ton')) {\n        plot_df[[colname]] &lt;- as.factor(plot_df[[colname]])\n    }\n}\n\nggplot(plot_df, aes(x=ton1, y=ton2)) +\n    geom_tile(aes(fill = prob)) + \n    geom_text(aes(label = round(prob, 3))) +\n    scale_fill_viridis() +\n    # scale_fill_distiller(palette = 'PiYG',direction = 1,\n    #                 limit=max(abs(plot_df$prob)) * c(-1, 1)\n    #                 ) +\n    theme_minimal() +\n     theme(panel.grid.major = element_blank(), \n            panel.grid.minor = element_blank(), \n            text=element_text(size=17))\n\n\n\n\n\n\n\n\n\n# map_state &lt;- function(state) {\n#         lumped_state &lt;- c(sum(state[1:sample_size]), head(state, sample_size) * (reward_limits - tail(state, sample_size)))\n#         lumped_state &lt;- as.integer(lumped_state)\n#         return(lumped_state)\n# }\n# label_fun &lt;- function(state, index) {\n#     return(paste(map_state(state), collapse=\"\"))\n# }\n\n# if (vertices_length(graph) &lt; 30) {    \n#     new_graph &lt;- discrete_joint_prob(graph, reward_rates, return_graph=TRUE)\n\n#     plot_graph(graph_as_matrix(new_graph), size=c(10, 10), align=TRUE, #rainbow=TRUE,\n#                    fontsize=26, ranksep=4, nodesep=0.9, rankdir=\"LR\",\n#               subgraphs=TRUE, subgraphfun=label_fun,\n#               # subgraphs=TRUE, subgraphfun=function(state, index) sum(head(state, sample_size)),\n#             splines='line'\n#               )  \n# }           \n\n\ngraph_vec &lt;- c()\nnew_graph_vec &lt;- c()\nsample_sizes &lt;- 4:15\nfor (sample_size in sample_sizes) {\n    graph &lt;- standard_coalescent(sample_size)\n    graph_vec &lt;- c(graph_vec, vertices_length(graph))\n    reward_limits &lt;- c(rep(1, sample_size-1), 0)\n    tot_reward_limit &lt;- Inf\n    new_graph &lt;- discrete_joint_prob(graph, reward_rates, return_graph=TRUE)\n    # new_graph &lt;- discrete_joint_prob(graph, reward_limits, mutation_rate, reward_possible, tot_reward_limit=tot_reward_limit, return_graph=TRUE)\n    new_graph_vec &lt;- c(new_graph_vec, vertices_length(new_graph))\n    # new_graph_vec &lt;- c(new_graph_vec, length(unique(apply(apply(states(new_graph), 1, map_state), 2, paste, collapse=\"\"))))\n}\n\n1000 1311 \n1000 1443 \n2000 2178 \n1000 1579 \n2000 2687 \n3000 3185 \n1000 1656 \n2000 2979 \n3000 3930 \n4000 4451 \n\n\n\ntheme_set(theme_bw() + theme(axis.line = element_line(colour = \"black\"),\n                 text=element_text(size=17),\n                 axis.text = element_text(size=15),\n                 plot.margin = unit(c(0.3,0.1,0.1,0.1), \"inch\")))\npalette &lt;- c(\"#888888\", \"#E69F00\", \"#56B4E9\", \"#009E73\", \"#F0E442\", \"#0072B2\", \"#D55E00\", \"#CC79A7\")\nopt &lt;- options(repr.plot.width=7, repr.plot.height=5,\n               ggplot2.discrete.colour=palette, ggplot2.discrete.fill=palette) ;\ndespine &lt;-  theme(panel.border = element_blank(), \n                 panel.grid.major = element_blank(),\n                 panel.grid.minor = element_blank())\n\nlibrary(gridExtra)\ndf &lt;- data.frame(\n  samples = sample_sizes,\n  graph_states = graph_vec,\n  new_graph_states =new_graph_vec\n)\ndf_long &lt;- pivot_longer(df, c(graph_states, new_graph_states))\np1 &lt;- ggplot(df_long, aes(x=samples, y=value, color=name)) +\n    geom_line(linewidth=1) + geom_point(size=3) + \n    despine +\n    xlim(0, NA) + ylim(0, NA) +\n    labs(x=\"Sample size\", y=\"Vertices\", color=\"Graph\") +\n    scale_color_discrete(labels = c(\"Original\", \"Augmented\"))\np2 &lt;- ggplot(df, aes(x=samples, y=new_graph_vec / graph_vec)) + \n    geom_line(linewidth=1) + geom_point(size=3) + \n    geom_abline(slope=1, intercept=0) +\n    # geom_abline(slope=0.25, intercept=1.5) +\n    despine +\n    xlim(0, NA) + ylim(0, NA) +\n    labs(x=\"Sample size\", y=\"Augmented / original vertices\", color=\"Graph\")\n\nopt &lt;- options(repr.plot.width=12, repr.plot.height=5.5)\ngrid.arrange(p1, p2, nrow = 1, widths = 3:2)\noptions(opt) ;\n\n\n\n\n\n\n\n\n\n# nr_states_vec &lt;- c()\n# nr_lumped_states_vec &lt;- c()\n# sample_sizes &lt;- 4:10\n# for (sample_size in sample_sizes) {\n#     graph &lt;- standard_coalescent(sample_size)\n#     state_length &lt;- length(vertex_at(graph, 1)$state)\n#     # last state index is absorbing where no rewards can be earned\n#     reward_limits &lt;- c(rep(1, state_length-1), 0)    \n#     new_graph &lt;- discrete_joint_prob(graph, reward_rates, return_graph=TRUE)\n#     # new_graph &lt;- discrete_joint_prob(graph, reward_limits, mutation_rate, reward_possible, return_graph=TRUE)\n#     nr_states_vec &lt;- c(nr_states_vec, vertices_length(new_graph))\n#     nr_lumped_states_vec &lt;- c(nr_lumped_states_vec, length(unique(apply(apply(states(new_graph), 1, map_state), 2, paste, collapse=\"\"))))\n# }\n# df &lt;- data.frame(\n#   samples = sample_sizes,\n#   nr_states = nr_states_vec,\n#   nr_lumped_states =nr_lumped_states_vec\n# )\n# df_long &lt;- pivot_longer(df, c(nr_states, nr_lumped_states))\n# ggplot(df_long, aes(x=samples, y=value, hue=name)) + geom_line() + geom_point()"
  },
  {
    "objectID": "examples/python/coalescent-jointprob.html#two-locus-arg",
    "href": "examples/python/coalescent-jointprob.html#two-locus-arg",
    "title": "Joint probability and FMC embedding",
    "section": "Two-locus ARG",
    "text": "Two-locus ARG\n\nRcpp::sourceCpp(\"./cpp/index_prop_mapping.cpp\")\n\ntwo_locus_arg &lt;- function(s, N, R) {\n\n    # state vector length\n    n &lt;- (s+1)**2\n\n    graph &lt;- create_graph(n)\n    index &lt;- 1\n    # first_vertex &lt;- create_vertex(graph, c(rep(0, s+2), s, rep(0, n-s-3))) # assumes that p=2\n    state &lt;- rep(0, n)\n    state[props_to_index_two_locus(s, 1, 1, 1)] &lt;- s\n    first_vertex &lt;- find_or_create_vertex(graph, state) # assumes that p=2\n    add_edge(starting_vertex(graph), first_vertex, 1)\n\n    index &lt;- 2\n    while (index &lt;= vertices_length(graph)) {\n\n      vertex &lt;- vertex_at(graph, index)\n      state &lt;- vertex$state\n\n      count &lt;- 0\n      for (i in 1:n) {\n          count &lt;- count + state[i]\n      }\n      if (count &lt;= 1) {\n          # Only one lineage, stop\n          index &lt;- index + 1\n          next\n      }    \n\n      for (i in 1:n) {\n        if (state[i] == 0) next\n\n        conf_i &lt;- index_to_props_two_locus(s, i)\n\n        # coalescence #########################\n        for (j in i:n) {\n          if (state[j] == 0) next\n            \n          conf_j &lt;- index_to_props_two_locus(s, j)\n\n          if (i == j) {\n            if (state[i] &lt; 2) {\n              next;\n            }\n            rate &lt;- state[i] * (state[i] - 1) / 2 / N\n          } else {\n            if (state[i] &lt; 1 || state[j] &lt; 1) {\n              next;\n            }\n            rate &lt;- state[i] * state[j] / N\n          }\n\n          child_state &lt;- state\n        \n          # lineages with index i and j coalesce:  \n          child_state[i] &lt;- child_state[i] - 1\n          child_state[j] &lt;- child_state[j] - 1\n          stopifnot(conf_i$descendants_l1+conf_j$descendants_l1 &lt;= s)\n          stopifnot(conf_i$descendants_l2+conf_j$descendants_l2 &lt;= s)\n\n          # coalescene into lineage with index k\n          k = props_to_index_two_locus(s, conf_i$descendants_l1+conf_j$descendants_l1, conf_i$descendants_l2+conf_j$descendants_l2)\n          child_state[k] &lt;- child_state[k] + 1\n\n          child_vertex &lt;- find_or_create_vertex(graph, child_state)\n          add_edge(vertex, child_vertex, rate)\n\n        }\n        \n\n        # recombination #######################\n        if (state[i] &gt; 0 && conf_i$descendants_l1 &gt; 0 && conf_i$descendants_l2 &gt; 0) {\n\n          # TODO: make sure this should not be R * state[i]\n          rate &lt;- R #* state[i] \n          child_state &lt;- state\n\n          # a lineage with index i recombines to produce lineages with index k and l\n          k = props_to_index_two_locus(s, conf_i$descendants_l1, 0)\n          l = props_to_index_two_locus(s, 0, conf_i$descendants_l2)\n          child_state[i] &lt;- child_state[i] - 1\n          child_state[k] &lt;- child_state[k] + 1\n          child_state[l] &lt;- child_state[l] + 1\n            \n          child_vertex &lt;- find_or_create_vertex(graph, child_state)\n          add_edge(vertex, child_vertex, rate)\n        }\n\n      }\n\n      index &lt;- index + 1\n\n      # if ((index %% 50) == 0) {\n      #   cat(index, vertices_length(graph), \"\\n\")\n      # }\n\n    }\n    \n    return(graph)\n}\n\n\narg_reward_rates &lt;- function(new_state, current_rewards, mutation_rate, reward_limit, locus_ton_reward_limit)\n{    \n    reward_limits &lt;- c(rep(reward_limit, length(new_state)-1), 0)\n    reward_limits &lt;- c(reward_limits, reward_limits) # duplicate to account for separate mutations at each locus\n\n    reward_dims &lt;- length(reward_limits)\n    if (is.null(current_rewards))\n        current_rewards &lt;- rep(0, reward_dims)\n\n# allowed_l1 &lt;- sapply(1:(reward_dims %/% 2), function(i) index_to_props_two_locus(sample_size, i)$descendants_l1 &gt; 0)\n# allowed_l2 &lt;- sapply((reward_dims %/% 2 + 1):reward_dims, function(i) index_to_props_two_locus(sample_size, i)$descendants_l2 &gt; 0)                   \n# allowed_mask &lt;- as.integer(c(allowed_l1, allowed_l2))\n    \n    result &lt;- rep(0, reward_dims)\n    trash_rate &lt;- 0\n                           \n    for (i in 1:reward_dims) {\n        rate &lt;- new_state[(i-1) %% (reward_dims %/% 2) + 1] * mutation_rate # fancy index to map state index to duplicted reward index\n        r &lt;- rep(0, reward_dims)\n        r[i] &lt;- 1\n        proposed_rewards &lt;- current_rewards + r\n        \n        if ( all(proposed_rewards &lt;= reward_limits) && \n            sum(head(proposed_rewards, reward_dims %/% 2)) &lt;= locus_ton_reward_limit && \n            sum(tail(proposed_rewards, reward_dims %/% 2)) &lt;= locus_ton_reward_limit ) {\n            result[i] &lt;- rate\n        } else {\n            trash_rate &lt;- trash_rate + rate\n        }\n    }     \n    return(c(result, trash_rate))\n}\n\nsample_size &lt;- 4\ngraph &lt;- two_locus_arg(sample_size, 1, 1)\nvertices_length(graph)\n\n110\n\n\n\nreward_rates &lt;- partial(arg_reward_rates, mutation_rate=1, reward_limit=1, locus_ton_reward_limit=1)\n\nstart &lt;- proc.time()[3]\njoint_probs &lt;- discrete_joint_prob(graph, reward_rates)\nproc.time()[3] - start\n\ntail(joint_probs)\n\n1000 3020 \n2000 4887 \n3000 6721 \n4000 8038 \n5000 9302 \n6000 10563 \n7000 11123 \n8000 11872 \n9000 12493 \n10000 13150 \n11000 13551 \n12000 13976 \n13000 14322 \n14000 14526 \n[1]   110.0000 14593.0000   132.6636\n\n\nelapsed: 32.5500000000001\n\n\n\nA data.frame: 6 × 51\n\n\n\nV1\nV2\nV3\nV4\nV5\nV6\nV7\nV8\nV9\nV10\n⋯\nV42\nV43\nV44\nV45\nV46\nV47\nV48\nV49\nV50\naccum_time\n\n\n\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n⋯\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;dbl&gt;\n\n\n\n\n539\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n⋯\n0\n0\n0\n0\n0\n0\n0\n0\n0\n5.350590e-08\n\n\n540\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n⋯\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1.670565e-07\n\n\n541\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n⋯\n0\n0\n0\n0\n0\n0\n0\n0\n0\n5.778167e-09\n\n\n542\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n⋯\n0\n0\n0\n0\n0\n0\n0\n0\n0\n5.778167e-09\n\n\n543\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n⋯\n0\n0\n0\n0\n0\n0\n0\n0\n0\n5.778167e-09\n\n\n544\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n⋯\n0\n0\n0\n0\n0\n0\n1\n0\n0\n5.778167e-09\n\n\n\n\n\n\n\n# sample_size &lt;- 3\n# graph &lt;- two_locus_arg(sample_size, 1, 1)\n\n# # plot_graph(graph_as_matrix(graph), size=c(10, 10), align=TRUE, rainbow=TRUE,\n# #                fontsize=16, ranksep=2, nodesep=0.5,\n# #           subgraphs=TRUE,         \n# #            subgraphfun=function(state, index) paste(state[1:sample_size], collapse=\"\"))  \n\n# state_length &lt;- length(vertex_at(graph, 1)$state)\n# reward_limits &lt;- list()\n# for (i in 1:state_length) {\n#     prop_i &lt;- index_to_props_two_locus(sample_size, i)\n#     if (prop_i$descendants_l1 == sample_size && prop_i$descendants_l2 == sample_size) {\n#         # absorbing state has no reward\n#         next\n#     }\n#     if (prop_i$descendants_l1 &gt; 0 && prop_i$descendants_l2 &gt; 0) {\n#         r &lt;- rep(0, state_length)\n#         r[i] &lt;- 1\n#         # cat(prop_i$descendants_l1, \" \", prop_i$descendants_l2, \" \", r, \"\\n\")\n#         reward_limits &lt;- c(reward_limits,  list(r))\n#         next\n#     }\n#     for (j in i:state_length) {\n#         prop_j &lt;- index_to_props_two_locus(sample_size, j)\n#         if (prop_j$descendants_l1 &gt; 0 && prop_j$descendants_l2 &gt; 0) {\n#             next\n#         }        \n#         r &lt;- rep(0, state_length)\n#         if ((prop_i$descendants_l1 &gt; 0 && prop_j$descendants_l2 &gt; 0) || (prop_j$descendants_l1 &gt; 0 && prop_i$descendants_l2 &gt; 0)) {\n#             r[i] &lt;- 1\n#             r[j] &lt;- 1\n#             reward_limits &lt;- c(reward_limits, list(r))\n#             # cat(prop_i$descendants_l1, \" \", prop_i$descendants_l2, \" \", prop_j$descendants_l1, \" \", prop_j$descendants_l2, \" \", r, \"\\n\")            \n#         }\n#     }\n# }\n\n# tot_reward_limit &lt;- Inf\n\n# mutation_rate &lt;- 1\n\n# reward_possible &lt;- function(state, rewards) {\n#     max_nrs_descendants &lt;- function(state) {\n#        l1 &lt;- 0\n#        l2 &lt;- 0\n#        for (i in 1:length(state)) {\n#            if (state[i] &gt; 0) {\n#                props &lt;- index_to_props_two_locus(sample_size, i) # SAMPLE SIZE SHOULD NOT BE A GLOBAL HERE...\n#                l1 &lt;- max(c(l1, props$descendants_l1))\n#                l2 &lt;- max(c(l2, props$descendants_l2))\n#            }\n#         }\n#        return(c(l1, l2))\n#     }\n#     return (all(max_nrs_descendants(rewards) &lt;= max_nrs_descendants(state)))\n# }\n\n\n# #reward_limits\n# #reward_limits &lt;- reward_limits[[1]]\n# state_length &lt;- length(vertex_at(graph, 1)$state)\n# # last state index is absorbing where no rewards can be earned\n# reward_limits &lt;- c(rep(1, state_length-1), 0)\n\n# start &lt;- proc.time()[3]\n# joint_probs &lt;- discrete_joint_prob(graph, reward_limits, mutation_rate, reward_possible, tot_reward_limit=tot_reward_limit)\n# proc.time()[3] - start\n# tail(joint_probs)                                \n\n\nstate_length &lt;- ncol(joint_probs) - 1\n\nmat &lt;- joint_probs %&gt;% select(starts_with('V')) %&gt;% as.matrix\n\nfun &lt;- function(x, marg_ton, sample_size) {\n     any(sapply((1:state_length)[which(x==1)], function(i) index_to_props_two_locus(sample_size, i)$descendants_l1 == marg_ton))\n}\nfor (marg_ton in 1:sample_size) {               \n    mask &lt;- apply(mat, 1, fun, marg_ton=marg_ton, sample_size=sample_size)\n    print( sum(joint_probs$accum_time[mask]) )\n}\n\n[1] 0.04359551\n[1] 0.018509\n[1] 0.009337695\n[1] 0.00101796\n\n\n\nfun &lt;- function(name, sample_size) {\n     f &lt;- function(name, sample_size) {\n        if (!startsWith(name, \"V\"))\n            return(name)\n        idx &lt;- as.integer(gsub('V', '', name))\n        props &lt;- index_to_props_two_locus(sample_size, idx)\n        # new_name &lt;- paste(c(\"(\", props$descendants_l1, \", \", props$descendants_l2, \")\"), collapse=\"\")\n        new_name &lt;- paste(c(\"ton\", props$descendants_l1, \"x\", props$descendants_l2, \"_\", props$population, props$population), collapse=\"\")\n        return(new_name)\n        }\n    sapply(name, f, sample_size=sample_size)\n}    \n\ndf &lt;- joint_probs %&gt;% \n    # rename_with(gsub, pattern=\"V\", replacement=\"ton\") %&gt;% \n    rename_with(fun, sample_size=sample_size)\n\nhead(df)\n\ntonnames &lt;- df %&gt;% select(!accum_time) %&gt;% names() %&gt;% str_extract(\"^ton[:digit:]x[:digit:]\") %&gt;% unique()\nl &lt;- map(tonnames, function (n) rowSums(select(df, ends_with(n))))\nplot_df &lt;- as.data.frame(do.call(cbind, l))\ncolnames(plot_df) &lt;- tonnames\nplot_df['accum_time'] &lt;- df['accum_time']\nhead(plot_df)         \n\n\nA data.frame: 6 × 51\n\n\n\nton0x0_11\nton1x0_11\nton2x0_11\nton3x0_11\nton4x0_11\nton0x1_11\nton1x1_11\nton2x1_11\nton3x1_11\nton4x1_11\n⋯\nton1x3_22\nton2x3_22\nton3x3_22\nton4x3_22\nton0x4_22\nton1x4_22\nton2x4_22\nton3x4_22\nton4x4_22\naccum_time\n\n\n\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n⋯\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;dbl&gt;\n\n\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n⋯\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0.020014967\n\n\n2\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n⋯\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0.004216329\n\n\n3\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n⋯\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0.004216329\n\n\n4\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n⋯\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0.011198623\n\n\n5\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n⋯\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0.001859383\n\n\n6\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n⋯\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0.011198623\n\n\n\n\n\n\nA data.frame: 6 × 26\n\n\n\nton0x0\nton1x0\nton2x0\nton3x0\nton4x0\nton0x1\nton1x1\nton2x1\nton3x1\nton4x1\n⋯\nton1x3\nton2x3\nton3x3\nton4x3\nton0x4\nton1x4\nton2x4\nton3x4\nton4x4\naccum_time\n\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n⋯\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n⋯\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0.020014967\n\n\n2\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n⋯\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0.004216329\n\n\n3\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n⋯\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0.004216329\n\n\n4\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n⋯\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0.011198623\n\n\n5\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n⋯\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0.001859383\n\n\n6\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n⋯\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0.011198623\n\n\n\n\n\n\n# plot_df &lt;- joint_probs %&gt;% \n#     # rename_with(gsub, pattern=\"V\", replacement=\"ton\") %&gt;% \n#     rename_with(fun, sample_size=sample_size) %&gt;%\n#     group_by(ton0x1, ton1x0) %&gt;% \n#     summarize(prob=sum(accum_time), .groups=\"keep\")\n\n# for (colname in colnames(plot_df)) {\n#     # if (startsWith(colname, 'ton')) {\n#     if (colname != 'prob') {\n#         plot_df[[colname]] &lt;- as.factor(plot_df[[colname]])\n#     }\n# }\n# plot_df\n\n\nggplot(plot_df, aes(x=ton0x1, y=ton1x0)) +\n    geom_tile(aes(fill = accum_time)) + \n    geom_text(aes(label = round(accum_time, 3))) +\n    scale_fill_viridis() +\n    # scale_fill_distiller(palette = 'PiYG',direction = 1,\n    #                 limit=max(abs(plot_df$prob)) * c(-1, 1)\n    #                 ) +\n    theme_minimal() +\n     theme(panel.grid.major = element_blank(), \n            panel.grid.minor = element_blank(), \n            text=element_text(size=17))\n\n\n\n\n\n\n\n\n\nget_exp_mat &lt;- function(graph, rewards, s) \n{\n    exp_mat &lt;- matrix(nrow=s+1,ncol=s+1)\n    for (i in 0:s) {\n      for (j in 0:s) {\n        exp_mat[i+1,j+1] &lt;- expectation(graph, rewards[props_to_index_two_locus(s, i, j), ])\n      }\n    } \n    return(exp_mat)\n}\n                 \nplot_exp_mat &lt;- function(exp_mat, title=\"Expectations\") \n{  \n    df &lt;- as.data.frame(exp_mat) #%&gt;% gather()\n    df &lt;- df %&gt;% rownames_to_column('ton1') %&gt;% gather('ton2', 'value', -c(ton1))\n\n    limit &lt;- max(abs(df$value)) * c(-1, 1)\n    \n    ggplot(df, aes(ton1, ton2)) +\n        geom_tile(aes(fill = value)) + \n        geom_text(aes(label = round(value, 2)), size=5) +\n        ggtitle(title) +\n    scale_x_discrete(labels= seq(0, nrow(exp_mat))) + \n    scale_y_discrete(labels= seq(0, nrow(exp_mat))) + \n    scale_fill_distiller(palette = 'PiYG',direction = 1, limit=limit) +\n    theme_minimal() +\n     theme(panel.grid.major = element_blank(), \n            panel.grid.minor = element_blank(), \n            text=element_text(size=17))\n\n} \n\nexp_mat &lt;- get_exp_mat(graph, reward_matrix, sample_size)\nnew_exp_mat &lt;- get_exp_mat(new_graph, rbind(0, new_reward_matrix, 0), sample_size)\n\noptions(repr.plot.width = 20, repr.plot.height = 5, repr.plot.res = 100)\n\np1 &lt;- plot_exp_mat(exp_mat, \"Original graph\")    \np2 &lt;- plot_exp_mat(new_exp_mat, \"Lumped graph\")    \np3 &lt;- plot_exp_mat(exp_mat - new_exp_mat, \"Absolute difference\")    \nrel_diff &lt;- (exp_mat - new_exp_mat)/exp_mat\nrel_diff[is.na(rel_diff)] &lt;- 0\np4 &lt;- plot_exp_mat(rel_diff, \"Relative difference\")    \ngrid.arrange(p1, p2, p3, p4, nrow = 1)\n\nERROR: Error in eval(expr, envir, enclos): objekt 'reward_matrix' blev ikke fundet\n\nError in eval(expr, envir, enclos): objekt 'reward_matrix' blev ikke fundet\nTraceback:\n\n1. get_exp_mat(graph, reward_matrix, sample_size)\n2. expectation(graph, rewards[props_to_index_two_locus(s, i, j), \n .     ])   # at line 6 of file &lt;text&gt;"
  },
  {
    "objectID": "examples/python/coalescent-jointprob.html#state-space-for-joint-proability-computation",
    "href": "examples/python/coalescent-jointprob.html#state-space-for-joint-proability-computation",
    "title": "Joint probability and FMC embedding",
    "section": "State space for joint proability computation",
    "text": "State space for joint proability computation\nGenerate coalescent state space like normal with the following modifications\n\nChange state space from (4, 0, 0, 0) to (4, 0, 0, 0, t1, t2, t3, t4). The last extra “ton” states keep track of the number accumulated mutations of each kind. We simply double the state vector so we keep track of the counts lineages with descendants, but also the counts of mutations happened on such lineages.\nEach state can mutate to accumulate a “ton” in accordance with its state vector. E.g., a (4, 0, 0, 0, 0, 0, 0, 0) state can only make singletons, a (2, 1, 0, 0, 0, 0, 0, 0) state can only make singletons and doubletons.\nA mutation event is a transition to a siter state E.g., (4, 0, 0, 0, 0, 0, 0, 0) -&gt; (4, 0, 0, 0, 1, 0, 0, 0)\nThe ton counts have a maximum value (base-1). If this value is reached, the mutation transition instead leads to a trash state with an infinite self loop. The transitions to trash represents the part of the deficient PDF not covered because we only run up to a max nr of tons."
  },
  {
    "objectID": "examples/python/coalescent-jointprob.html#reward-transform",
    "href": "examples/python/coalescent-jointprob.html#reward-transform",
    "title": "Joint probability and FMC embedding",
    "section": "Reward transform",
    "text": "Reward transform\n\nConvert the last half of each state (with ton counts) to numbers in some base.\nUse these for reward transformation.\nCompute PDF for t &lt;- 1:sample_size^(base-1)\nConvert each time t back to the corresponding ton vector and associate it with the probability\ngroup by two tons and sum probs in groups to get all pairwise combinations for a joint probability matrix."
  },
  {
    "objectID": "examples/python/coalescent-jointprob.html#figure-out-why-you-get-nas-in-multi_rewards-with-max_tons---1",
    "href": "examples/python/coalescent-jointprob.html#figure-out-why-you-get-nas-in-multi_rewards-with-max_tons---1",
    "title": "Joint probability and FMC embedding",
    "section": "Figure out why you get NAs in multi_rewards with max_tons <- 1",
    "text": "Figure out why you get NAs in multi_rewards with max_tons &lt;- 1\n\n# joint_prob_coalescent &lt;- function(n, mutation_rate, max_tons, total_tons=Inf) {\n    \n#     state_vector_length &lt;- n + n + 1\n#     graph &lt;- create_graph(state_vector_length)\n#     starting_vertex &lt;- vertex_at(graph, 1)\n#     initial_state &lt;- c(rep(0, n), 0)\n#     initial_state[1] &lt;- n\n    \n#     add_edge(\n#       starting_vertex,\n#       create_vertex(graph, initial_state),\n#       1\n#     )\n#     index &lt;- 2\n\n#     while (index &lt;= vertices_length(graph)) {\n#       vertex &lt;- vertex_at(graph, index)\n\n#       # skip if we only have one lineage left or if this is a trash state\n#       if (sum(vertex$state[1:n]) &lt;= 1) {\n#         index &lt;- index + 1\n#         next\n#       }\n\n#       # mutations\n#       trash_rate &lt;- 0 \n#       for (i in 1:n)  {\n#         state &lt;- vertex$state          \n#         rate &lt;- vertex$state[i] * mutation_rate\n#         nr_tons &lt;- state[n+i]\n#         if (rate &gt; 0) {\n#             if (nr_tons &lt; max_tons && sum(vertex$state[(n+1):(2*n)]) &lt; total_tons) {\n#               child_state &lt;- state\n\n#               mutation_vertex &lt;- create_vertex(graph, rep(0, state_vector_length))\n#               add_edge(vertex, mutation_vertex, rate)\n#               child_state[n+i] &lt;- child_state[i+n] + 1\n#               add_edge(mutation_vertex, find_or_create_vertex(graph, child_state), 1)\n                \n#               # child_state[n+i] &lt;- child_state[i+n] + 1\n#               # add_edge(vertex, find_or_create_vertex(graph, child_state), rate)\n#             } else {\n#               trash_rate &lt;- trash_rate + rate\n#             }\n#         }          \n#       }\n#       if (trash_rate &gt; 0) {\n#         add_edge(vertex, find_or_create_vertex(graph, rep(0, state_vector_length)), trash_rate)\n#       }\n\n#       # loop over all classes of lineages\n#       for (i in 1:n) {\n#         for (j in i:n) {\n#           state &lt;- vertex$state\n          \n#           # if same class, there need to be at least two to coalesce\n#           if (i == j) {\n#             if (state[i] &lt; 2) {\n#               next;\n#             }\n#             # coal rate\n#             rate &lt;- state[i] * (state[i] - 1) / 2\n#           } else {\n#             # else at least one in each class to coalesce\n#             if (state[i] &lt; 1 || state[j] &lt; 1) {\n#               next;\n#             }\n#             # number of combinations\n#             rate &lt;- state[i] * state[j]\n#           }\n          \n#           # copy state\n#           child_state &lt;- state\n#           # update child state\n#           child_state[i] &lt;- child_state[i] - 1\n#           child_state[j] &lt;- child_state[j] - 1\n#           child_state[i+j] &lt;- child_state[i+j] + 1\n\n#           add_edge(\n#               vertex,\n#               find_or_create_vertex(graph, child_state),\n#               rate\n#             )\n#         }\n#       }\n\n#       index &lt;- index + 1\n#     }\n#     trash_vertex &lt;- find_or_create_vertex(graph, rep(0, state_vector_length))\n#     trash_loop_vertex &lt;- create_vertex(graph, rep(0, state_vector_length))\n#     add_edge(trash_vertex, trash_loop_vertex, 1)\n#     add_edge(trash_loop_vertex, trash_vertex, 1)\n    \n#     return(graph)\n# }\n# # states &lt;- t(sapply(1:vertices_length(graph), function(index) vertex_at(graph, index)$state ))\n# # ipv &lt;- graph_as_matrix(graph)$IPV\n# # sim &lt;- graph_as_matrix(graph)$SIM\n\n# # sample_size &lt;- 4\n# # # mutation_rate &lt;- 20000 * 31 * 5e-10 # 0.00031\n# # mutation_rate &lt;- 1\n# # max_tons &lt;- 3\n# # base &lt;- max_tons + 1\n# # # graph &lt;- joint_prob_coalescent(sample_size, mutation_rate, max_tons)\n# # # gam &lt;- graph_as_matrix(graph)\n# # # #gam\n\n# # graph &lt;- joint_prob_coalescent(sample_size, mutation_rate, max_tons, total_tons)\n# # gam &lt;- graph_as_matrix(graph)\n# # plot_graph(gam, #subgraphs=TRUE, \n# #            rainbow=TRUE,\n# #            size=c(10, 8), \n# #            align=TRUE,\n# #            fontsize=16, ranksep=1, nodesep=0.25,          \n# #            # subgraphfun=function(state) paste(state[-length(state)], collapse=\"\")\n# #            )\n\n\n\njoint_prob_coalescent &lt;- function(n, mutation_rate, max_tons, total_tons=Inf) {\n\n    stopifnot(total_tons == Inf)\n    \n    state_vector_length &lt;- n + n + 1\n    graph &lt;- create_graph(state_vector_length)\n    starting_vertex &lt;- vertex_at(graph, 1)\n    initial_state &lt;- c(rep(0, n), 0)\n    initial_state[1] &lt;- n\n    \n    add_edge(\n      starting_vertex,\n      create_vertex(graph, initial_state),\n      1\n    )\n    index &lt;- 2\n\n    while (index &lt;= vertices_length(graph)) {\n      vertex &lt;- vertex_at(graph, index)\n\n      # skip if we only have one lineage left or if this is a trash state\n      if (sum(vertex$state[1:n]) &lt;= 1) {\n        index &lt;- index + 1\n        next\n      }\n        \n      # loop over all classes of lineages\n      for (i in 1:n) {\n        for (j in i:n) {\n          state &lt;- vertex$state\n          \n          # if same class, there need to be at least two to coalesce\n          if (i == j) {\n            if (state[i] &lt; 2) {\n              next;\n            }\n            # coal rate\n            rate &lt;- state[i] * (state[i] - 1) / 2\n          } else {\n            # else at least one in each class to coalesce\n            if (state[i] &lt; 1 || state[j] &lt; 1) {\n              next;\n            }\n            # number of combinations\n            rate &lt;- state[i] * state[j]\n          }\n          \n          # copy state\n          child_state &lt;- state\n          # update child state\n          child_state[i] &lt;- child_state[i] - 1\n          child_state[j] &lt;- child_state[j] - 1\n          child_state[i+j] &lt;- child_state[i+j] + 1\n\n          add_edge(\n              vertex,\n              find_or_create_vertex(graph, child_state),\n              rate\n            )\n        }\n      }\n\n      # mutations\n      trash_rate &lt;- 0 \n      for (i in 1:n)  {\n        rate &lt;- vertex$state[i] * mutation_rate\n        nr_tons &lt;- child_state[n+i]\n        if (rate &gt; 0) {\n            if (nr_tons &lt; max_tons && sum(vertex$state[(n+1):(2*n)]) &lt; total_tons) {\n              child_state &lt;- state\n              child_state[n+i] &lt;- child_state[i+n] + 1\n              add_edge(vertex, find_or_create_vertex(graph, child_state), rate)\n            } else {\n              trash_rate &lt;- trash_rate + rate\n            }\n        }\n      }\n      if (trash_rate &gt; 0) {\n        add_edge(vertex, find_or_create_vertex(graph, rep(0, state_vector_length)), trash_rate)\n      }\n\n      index &lt;- index + 1\n    }\n    trash_vertex &lt;- find_or_create_vertex(graph, rep(0, state_vector_length))\n    trash_loop_vertex &lt;- create_vertex(graph, rep(0, state_vector_length))\n    add_edge(trash_vertex, trash_loop_vertex, 1)\n    add_edge(trash_loop_vertex, trash_vertex, 1)\n    \n    return(graph)\n}\n\n\nndigits &lt;- function(x){\n  y &lt;- floor(abs(x))\n  if(y != 0){\n    floor(log10(y)) + 1\n  } else {\n    1\n  }\n}\nrev_number=function(n){\n    m=as.integer(rev(strsplit(as.character(n),\"\")))\n    if (m==rev(m)) print(\"reversed number\")\n}\nforth &lt;- function(vec, base) {\n    # return( as.integer( c(vec %*%  (base ^ rev(seq_along(vec)) / base)) ) )\n    # return( as.integer( c(vec %*%  (base ^ (seq_along(vec)) / base)) ) )\n    # return( c(vec %*%  (base ^ (rev(seq_along(vec))) / base)) ) \n    return( c(vec %*%  (base ^ (seq_along(vec)) / base)) ) \n}\nback &lt;- function(x, base, state_length) {\n    # x &lt;- as.integer(rev(paste(x, collapse='')))\n    # x &lt;- floor(as.numeric(rev(paste(x, collapse=''))))\n    vec &lt;- c()\n\n    for (i in 1:state_length) {\n        # if (x &gt; 0) {\n            vec &lt;- c(x %% (base), vec)\n            x &lt;- x %/% (base)\n        # }\n    }\n\n    # while (x &gt; 0) {\n    #     vec &lt;- c(x %% (base), vec)\n    #     x &lt;- x %/% (base)\n    # }\n    \n    # for (i in 1:ndigits(x)) {\n    #     if (x &gt; 0) {\n    #         vec &lt;- c(x %% (base), vec)\n    #         x &lt;- x %/% (base)\n    #     }\n    # }\n    vec &lt;- as.integer(vec)\n    return( rev(c(rep(0, state_length-length(vec)), vec) ))\n    # return( c(rep(0, state_length-length(vec)), vec) )\n}\n# vec &lt;- c(1, 2, 0)\n# base &lt;- max(vec)+1\n# state_length &lt;- length(vec)\n# print(vec)\n# f &lt;- forth(vec, base)\n# print(f)\n# b &lt;- back(f, base, state_length)\n# print(b)\n# b &lt;- c(rep(0, length(vec)-length(b)), b)\n# print(b)\n\n\ngraph &lt;- standard_coalescent(sample_size)\ngraph_as_matrix(graph)\n\n\n    $states\n        \n\nA matrix: 4 × 4 of type dbl\n\n\n4\n0\n0\n0\n\n\n2\n1\n0\n0\n\n\n0\n2\n0\n0\n\n\n1\n0\n1\n0\n\n\n\n\n\n    $SIM\n        \n\nA matrix: 4 × 4 of type dbl\n\n\n-6\n6\n0\n0\n\n\n0\n-3\n1\n2\n\n\n0\n0\n-1\n0\n\n\n0\n0\n0\n-1\n\n\n\n\n\n    $IPV\n        \n1000\n\n    $indices\n        \n2345\n\n\n\n\n\nplot_graph(graph_as_matrix(graph), size=c(10, 8), align=TRUE, # rainbow=TRUE,\n               fontsize=16, ranksep=1, nodesep=0.25)\n\n\n\n\n\n\n\n\n\nexpectation(graph)\n\n1.5\n\n\n\nrewards &lt;- make_discrete(graph, 1)\ngraph_as_matrix(graph)\n\n\n    $states\n        \n\nA matrix: 10 × 4 of type dbl\n\n\n0\n0\n0\n0\n\n\n4\n0\n0\n0\n\n\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n\n\n2\n1\n0\n0\n\n\n0\n0\n0\n0\n\n\n0\n2\n0\n0\n\n\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n\n\n1\n0\n1\n0\n\n\n\n\n\n    $SIM\n        \n\nA matrix: 10 × 10 of type dbl\n\n\n-1.0\n1\n0.0000000\n0.0000000\n0.0\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n\n\n0.4\n-1\n0.0000000\n0.0000000\n0.6\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n\n\n0.0\n0\n-1.0000000\n0.0000000\n1.0\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n\n\n0.0\n0\n0.0000000\n-1.0000000\n1.0\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n\n\n0.0\n0\n0.1666667\n0.3333333\n-1.0\n0.0000000\n0.1666667\n0.0000000\n0.0000000\n0.3333333\n\n\n0.0\n0\n0.0000000\n0.0000000\n0.0\n-1.0000000\n1.0000000\n0.0000000\n0.0000000\n0.0000000\n\n\n0.0\n0\n0.0000000\n0.0000000\n0.0\n0.6666667\n-1.0000000\n0.0000000\n0.0000000\n0.0000000\n\n\n0.0\n0\n0.0000000\n0.0000000\n0.0\n0.0000000\n0.0000000\n-1.0000000\n0.0000000\n1.0000000\n\n\n0.0\n0\n0.0000000\n0.0000000\n0.0\n0.0000000\n0.0000000\n0.0000000\n-1.0000000\n1.0000000\n\n\n0.0\n0\n0.0000000\n0.0000000\n0.0\n0.0000000\n0.0000000\n0.3333333\n0.3333333\n-1.0000000\n\n\n\n\n\n    $IPV\n        \n0100000000\n\n    $indices\n        \n7298310412115\n\n\n\n\n\nplot_graph(graph_as_matrix(graph), #rainbow=TRUE, \n           size=c(10, 8), #align=TRUE,\n               fontsize=16, ranksep=1, nodesep=0.25,\n             # subgraph=TRUE, subgraphfun=function(state, index) as.character((index+1) %/% 2)\n)\n\n\n\n\n\n\n\n\n\napply(rewards[1:3,], 1, function(x) expectation(graph, x))\n\n\n210.666666666666667\n\n\n\nrev_graph &lt;- reward_transform(graph, rewards[1,])\nplot_graph(graph_as_matrix(rev_graph), #rainbow=TRUE, \n           size=c(10, 8), #align=TRUE,\n               fontsize=16, ranksep=1, nodesep=0.25,\n             # subgraph=TRUE, subgraphfun=function(state, index) as.character((index+1) %/% 2)\n)\n\n\n\n\n\n\n\n\n\npdph(1:10, rev_graph)\n\n\n0.4920.68520.814440.894420.94147560.968198280.9829850280.99100754760.99529405860.997556851764"
  },
  {
    "objectID": "examples/python/coalescent-jointprob.html#compute-joint-prob",
    "href": "examples/python/coalescent-jointprob.html#compute-joint-prob",
    "title": "Joint probability and FMC embedding",
    "section": "Compute joint prob",
    "text": "Compute joint prob\n\nConstraining the total number of mutations does not work\nThe deficit is computed correctly as long as all max rewards so that all r scalar values in the CDF represents a reward combination in the MDF\nJust like we can limit the number of each king of tons in the state space contruction, we might also limit the total number of mutations so that we, for example, can have at most one instance of two different tons (total_tons=2). E.g., a singleton and a tripleton.\nHowever, this gives a a deficit problem I am not sure I can solve with this approach. In principle, the deficit should be taken care of, and I should just discard all joint probs for total numbers of tons larger than total_tons - but that does not seem to be the case…\n\nmaybe I don’t need loops if they are not selff-loops anyway. If aux-&gt;C has rate 1 then A-&gt;aux-&gt;C is the same as A-&gt;C. Below I just changed two things\n\nnormalize the graph\nuse pdph instead of pph\n\nBUT if I normalize I need to represent the residual prob as reward, which means I need to reward transform, which I cannot if I want to do everying in one go with the scalar trick.\n\nsample_size &lt;- 4\n\ngraph &lt;- standard_coalescent(sample_size)\nplot_graph(graph_as_matrix(graph), size=c(10, 8), align=TRUE, rainbow=TRUE,\n               fontsize=16, ranksep=1, nodesep=0.25,\n            subgraphs=TRUE,         \n           subgraphfun=function(state, index) paste(state[1:sample_size], collapse=\"\"))\n\n\n\n\n\n\n\n\n\n# mutation_rate &lt;- 20000 * 31 * 5e-10 # 0.00031\nmutation_rate &lt;- 1\nmax_tons &lt;- 20\ntotal_tons &lt;- Inf\nbase &lt;- max_tons + 1\ngraph &lt;- joint_prob_coalescent(sample_size, mutation_rate, max_tons, total_tons=total_tons)\n\nweights_were_multiplied_with &lt;- normalize_graph(graph)\n\n# gam &lt;- graph_as_matrix(graph)\n#gam\n\n\nif (vertices_length(graph) &lt; 50)\n    plot_graph(graph_as_matrix(graph), size=c(10, 8), align=TRUE, rainbow=TRUE,\n               fontsize=16, ranksep=2, nodesep=0.5,\n             subgraphs=TRUE,         \n           subgraphfun=function(state, index) paste(state[1:sample_size], collapse=\"\"))\n\nGet last halves of states that server as mutation rewards:\n\nrewards &lt;- states(graph)[, (sample_size+1):(2*sample_size)]\n\nTurn reward vectors into scalars (with the appropriate base):\n\nmulti_rewards &lt;- apply(rewards, 1, forth, base=base)\nmulti_rewards\n\n\n00010012120211441122221423214212442441882222323224346242634426323443442883882132322432334242344463436446290348363845638434444443884883132413231764436423442445252445464446546390448464859031344483924504841056841054544544488588413251324176517642205648544652445255626254646545664649054856586904134548492550585106134417859241365504945525105126710512656446445886885132613251766176522062205264685106658645662546266727264746646674659064866687905134648592650686107134517869251366505946526⋯78538294743378747013745465937034617366149133871391548293873478738314745378947033747466137054915387339174831387547893833474737914705374949173875391948333877479138354749379349193877392148353879479338374921387939234837388149233881392549253913487149155829487357874831574547895703474756614705591548734917583148755789483357474791570547495917487549195833487757914835574947935919487749215835487957934837592148794923583748815923488149255925491558735917683158756789583367475791670557496917587559196833587767915835674957936919587759216835587967935837692158795923683758816923588159256925591768756919783368777791683577496793791968776921783568797793683779216879692378376881792368816925792569197877792188357879879378378921787979238837788189237881792589257921887989239837888199238881892599258923988199260925992600\n\n\nLoop over states except starting to find trash vertices and give them a reward so they won’t dissapear in the reward transformation. They will not contribute this reward because they are dead ends:\n\ntrash_states &lt;- c()\nfor (i in 2:vertices_length(graph)) {\n  vertex &lt;- vertex_at(graph, i)\n  if (sum(vertex$state) == 0) {\n    multi_rewards[i] &lt;- 1\n    trash_states &lt;- c(trash_states, i)\n  }\n}\ntrash_states\n\n\n333419428\n\n\n\nmulti_rewards\n\n\n00010012120211441122221423214212442441882222323224346242634426323443442883882132322432334242344463436446290348363845638434444443884883132413231764436423442445252445464446546390448464859031344483924504841056841054544544488588413251324176517642205648544652445255626254646545664649054856586904134548492550585106134417859241365504945525105126710512656446445886885132613251766176522062205264685106658645662546266727264746646674659064866687905134648592650686107134517869251366505946526⋯78538294743378747013745465937034617366149133871391548293873478738314745378947033747466137054915387339174831387547893833474737914705374949173875391948333877479138354749379349193877392148353879479338374921387939234837388149233881392549253913487149155829487357874831574547895703474756614705591548734917583148755789483357474791570547495917487549195833487757914835574947935919487749215835487957934837592148794923583748815923488149255925491558735917683158756789583367475791670557496917587559196833587767915835674957936919587759216835587967935837692158795923683758816923588159256925591768756919783368777791683577496793791968776921783568797793683779216879692378376881792368816925792569197877792188357879879378378921787979238837788189237881792589257921887989239837888199238881892599258923988199260925992601\n\n\nReward transform graph using scalar rewards:\n\nrew_graph &lt;- reward_transform(graph, multi_rewards)\n\n\nif (vertices_length(graph) &lt; 50)\n    plot_graph(graph_as_matrix(rew_graph),\n           rainbow=TRUE,\n           size=c(8, 8), \n           align=TRUE,\n           fontsize=14, ranksep=1, nodesep=0.5, \n           # subgraphs=TRUE, subgraphfun=function(state, index) as.character((index+1) %/% 2)\n           )\n\nCompute CDF assming no mutation count exceeds max_tons:\n\ncdf_df &lt;- data.frame(t=seq(0, base^(sample_size-1) - 1, 1))\ncdf_df['cdf'] &lt;- sapply(cdf_df$t, function (t) pdph(t, rew_graph))\n# cdf_df['cdf'] &lt;- sapply(cdf_df$t, function (t) pph(t, rew_graph))\ntail(cdf_df)\n\n\nA data.frame: 6 × 2\n\n\n\nt\ncdf\n\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n9256\n9255\n0.9796789\n\n\n9257\n9256\n0.9796824\n\n\n9258\n9257\n0.9796860\n\n\n9259\n9258\n0.9796896\n\n\n9260\n9259\n0.9796932\n\n\n9261\n9260\n0.9796968\n\n\n\n\n\nConvert reward scalars back into state vectors representing ton counts:\n\nx &lt;- lapply(cdf_df$t, back, base=base, state_length=sample_size)\nm &lt;- do.call(rbind, x)\n\n\n# is_additional_deficit &lt;- as.integer(rowSums(m) &gt; total_tons)\n# p &lt;- df$cdf\n# pdf_from_cdf &lt;- c(p[1], p[2:length(p)] - p[-length(p)])\n# additional_deficit &lt;- cumsum(pdf_from_cdf * is_additional_deficit)\n# additional_deficit\n\n\ndf &lt;- cbind(cdf_df, data.frame(m))\ntail(df)\n\n\nA data.frame: 6 × 6\n\n\n\nt\ncdf\nX1\nX2\nX3\nX4\n\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n9256\n9255\n0.9796789\n15\n20\n20\n0\n\n\n9257\n9256\n0.9796824\n16\n20\n20\n0\n\n\n9258\n9257\n0.9796860\n17\n20\n20\n0\n\n\n9259\n9258\n0.9796896\n18\n20\n20\n0\n\n\n9260\n9259\n0.9796932\n19\n20\n20\n0\n\n\n9261\n9260\n0.9796968\n20\n20\n20\n0\n\n\n\n\n\nThe deficit is taken care of, so you should discard all joint probs for total numbers of tons larger than total_tons:\n\n# df &lt;- df[!is_additional_deficit, ]\n# df\n\n\ndf %&gt;% ggplot(aes(x=t, y=cdf)) + \n    geom_bar(stat=\"identity\") +\n    labs(x='scaled time', y='probability') + \n    despine + ylim(0, 1)\n\n\n\n\n\n\n\n\nCompute probability of standing in on of the trash states for each time t in our CDF. These represent the deficit of the computed CDF:\n\nMake sure the stop_probability is the discrete version of that is what we are doing\n\n\ntrash_prob &lt;- c()\nfor (t in df$t) {\n    # s &lt;- stop_probability(graph, t)\n    s &lt;- dph_stop_probability(graph, t)\n    trash_prob &lt;- c(trash_prob, sum(s[trash_states]))\n}\ndf['cdf_deficit'] &lt;- trash_prob\nhead(df)\n\n\nA data.frame: 6 × 7\n\n\n\nt\ncdf\nX1\nX2\nX3\nX4\ncdf_deficit\n\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n1\n0\n0.1000000\n0\n0\n0\n0\n0\n\n\n2\n1\n0.1233308\n1\n0\n0\n0\n0\n\n\n3\n2\n0.1614973\n2\n0\n0\n0\n0\n\n\n4\n3\n0.2117425\n3\n0\n0\n0\n0\n\n\n5\n4\n0.2303889\n4\n0\n0\n0\n0\n\n\n6\n5\n0.2476603\n5\n0\n0\n0\n0\n\n\n\n\n\nCDF deficit:\n\ndf %&gt;% ggplot(aes(x=t, y=cdf_deficit)) + \n    geom_bar(stat=\"identity\") +\n    labs(x='scaled time', y='probability') + \n    despine + ylim(0, 1)\n\n\n\n\n\n\n\n\nSanity check: adding CDF and deficit should produce a CDF that goes to 1:\n\ndf['cdf_incl_deficit'] &lt;- df$cdf + df$cdf_deficit\n\n\ndf %&gt;% ggplot(aes(x=t, y=cdf_incl_deficit)) + \n    geom_bar(stat=\"identity\") +\n    labs(x='scaled time', y='probability') + \n    despine + \n    ylim(0, 1) + \n    geom_hline(yintercept=1, linetype=\"dashed\")\n\n\n\n\n\n\n\n\nI.e., and a PDF that sum to one:\n\np &lt;- df$cdf_incl_deficit\ndf['pdf_from_cdf_incl_deficit'] &lt;- c(p[1], p[2:length(p)] - p[-length(p)])\n\n\ndf %&gt;% ggplot(aes(x=t, y=pdf_from_cdf_incl_deficit)) + \n    geom_bar(stat=\"identity\") +\n    labs(x='scaled time', y='probability') + \n    despine\n\n\n\n\n\n\n\n\n\nsum(df$pdf_from_cdf_incl_deficit)\n\n0.979780061019623\n\n\nIt almost does… Maybe a numerical issue\nCompute PDF from the CDF (this is the one we are after):\n\np &lt;- df$cdf\ndf['pdf_from_cdf'] &lt;- c(p[1], p[2:length(p)] - p[-length(p)])\ndf['prob'] = df$pdf_from_cdf\n\n\ndf %&gt;% ggplot(aes(x=t, y=pdf_from_cdf)) + \n    geom_bar(stat=\"identity\") +\n    labs(x='scaled time', y='probability') + \n    despine\n\n\n\n\n\n\n\n\nThe reason we need to go through the CDF to get the PDF is that the PDF function in PtD computes the distribution of times when the absorbing state is reached. It this cannot take the deficit in trash_states into account. The PDF commputed directly looks like this:\n\nMake sure I ues the discrete version here if I also use the dicscrete CDF above\n\n\n# df['pdf'] &lt;- sapply(df$t, function (t) dph(t, rew_graph))\ndf['pdf'] &lt;- sapply(df$t, function (t) ddph(t, rew_graph))\n\n\ndf %&gt;% ggplot(aes(x=t, y=pdf)) + \n    geom_bar(stat=\"identity\") +\n    labs(x='scaled time', y='probability') + \n    despine"
  },
  {
    "objectID": "examples/python/coalescent-jointprob.html#when-we-do-the-discrete-version-we-dont-need-to-go-through-the-cdf-to-get-the-pdf.-we-can-just-use-the-ddph-directly",
    "href": "examples/python/coalescent-jointprob.html#when-we-do-the-discrete-version-we-dont-need-to-go-through-the-cdf-to-get-the-pdf.-we-can-just-use-the-ddph-directly",
    "title": "Joint probability and FMC embedding",
    "section": "When we do the discrete version, we don’t need to go through the CDF to get the PDF. We can just use the ddph directly",
    "text": "When we do the discrete version, we don’t need to go through the CDF to get the PDF. We can just use the ddph directly\n\ndf['diff'] &lt;- df['pdf_from_cdf'] - df['pdf']\ndf %&gt;% ggplot(aes(x=t, y=diff)) + \n    geom_bar(stat=\"identity\") +\n    labs(x='scaled time', y='probability') + \n    despine \n\n\n\n\n\n\n\n\nThe marginal expectations does not match the SFS proportions, because paths that accumulate more than max_tons singletons will end in the trash state and not have the opportunity to also accumulate doubletons etc. That reflects that the the joint prob of a singleton and a doubleton is be a subset of the singleton probability. That way the total marginal singleton prob will be roughly sfs expectation, but the total marginal doubleton prob will be much too small:\n\nsfs &lt;- c(1, 1/2, 1/3)\nsfs / sum(sfs)\n\n\n0.5454545454545460.2727272727272730.181818181818182\n\n\n\ndf[df$X1==1 & df$X2==0 & df$X3==1, ]\n\n\nA data.frame: 1 × 13\n\n\n\nt\ncdf\nX1\nX2\nX3\nX4\ncdf_deficit\ncdf_incl_deficit\npdf_from_cdf_incl_deficit\npdf_from_cdf\nprob\npdf\ndiff\n\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n443\n442\n0.7136648\n1\n0\n1\n0\n8.327853e-05\n0.7137481\n0.0002646858\n0.0002646858\n0.0002646858\n0.0002646858\n-2.238877e-17\n\n\n\n\n\n\ndf\n\n\nA data.frame: 9261 × 13\n\n\nt\ncdf\nX1\nX2\nX3\nX4\ncdf_deficit\ncdf_incl_deficit\npdf_from_cdf_incl_deficit\npdf_from_cdf\nprob\npdf\ndiff\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n0\n0.1000000\n0\n0\n0\n0\n0.000000e+00\n0.1000000\n0.100000000\n0.100000000\n0.100000000\n0.100000000\n0.000000e+00\n\n\n1\n0.1233308\n1\n0\n0\n0\n0.000000e+00\n0.1233308\n0.023330814\n0.023330814\n0.023330814\n0.023330814\n-6.938894e-18\n\n\n2\n0.1614973\n2\n0\n0\n0\n0.000000e+00\n0.1614973\n0.038166529\n0.038166529\n0.038166529\n0.038166529\n-6.938894e-18\n\n\n3\n0.2117425\n3\n0\n0\n0\n0.000000e+00\n0.2117425\n0.050245196\n0.050245196\n0.050245196\n0.050245196\n6.938894e-18\n\n\n4\n0.2303889\n4\n0\n0\n0\n0.000000e+00\n0.2303889\n0.018646386\n0.018646386\n0.018646386\n0.018646386\n-3.469447e-18\n\n\n5\n0.2476603\n5\n0\n0\n0\n0.000000e+00\n0.2476603\n0.017271404\n0.017271404\n0.017271404\n0.017271404\n-1.387779e-17\n\n\n6\n0.2629493\n6\n0\n0\n0\n0.000000e+00\n0.2629493\n0.015288932\n0.015288932\n0.015288932\n0.015288932\n2.428613e-17\n\n\n7\n0.2762541\n7\n0\n0\n0\n0.000000e+00\n0.2762541\n0.013304841\n0.013304841\n0.013304841\n0.013304841\n5.204170e-18\n\n\n8\n0.2878150\n8\n0\n0\n0\n0.000000e+00\n0.2878150\n0.011560939\n0.011560939\n0.011560939\n0.011560939\n-1.040834e-17\n\n\n9\n0.2979278\n9\n0\n0\n0\n0.000000e+00\n0.2979278\n0.010112710\n0.010112710\n0.010112710\n0.010112710\n-2.255141e-17\n\n\n10\n0.3068648\n10\n0\n0\n0\n0.000000e+00\n0.3068648\n0.008937019\n0.008937019\n0.008937019\n0.008937019\n-2.081668e-17\n\n\n11\n0.3148516\n11\n0\n0\n0\n0.000000e+00\n0.3148516\n0.007986783\n0.007986783\n0.007986783\n0.007986783\n-1.734723e-17\n\n\n12\n0.3220662\n12\n0\n0\n0\n0.000000e+00\n0.3220662\n0.007214610\n0.007214610\n0.007214610\n0.007214610\n-1.127570e-17\n\n\n13\n0.3286470\n13\n0\n0\n0\n0.000000e+00\n0.3286470\n0.006580816\n0.006580816\n0.006580816\n0.006580816\n8.673617e-19\n\n\n14\n0.3347016\n14\n0\n0\n0\n0.000000e+00\n0.3347016\n0.006054616\n0.006054616\n0.006054616\n0.006054616\n2.428613e-17\n\n\n15\n0.3403145\n15\n0\n0\n0\n0.000000e+00\n0.3403145\n0.005612866\n0.005612866\n0.005612866\n0.005612866\n-1.301043e-17\n\n\n16\n0.3455527\n16\n0\n0\n0\n0.000000e+00\n0.3455527\n0.005238284\n0.005238284\n0.005238284\n0.005238284\n-6.938894e-18\n\n\n17\n0.3504706\n17\n0\n0\n0\n0.000000e+00\n0.3504706\n0.004917865\n0.004917865\n0.004917865\n0.004917865\n1.734723e-18\n\n\n18\n0.3551123\n18\n0\n0\n0\n0.000000e+00\n0.3551123\n0.004641673\n0.004641673\n0.004641673\n0.004641673\n-2.168404e-17\n\n\n19\n0.3595143\n19\n0\n0\n0\n0.000000e+00\n0.3595143\n0.004401981\n0.004401981\n0.004401981\n0.004401981\n-6.938894e-18\n\n\n20\n0.3637069\n20\n0\n0\n0\n0.000000e+00\n0.3637069\n0.004192673\n0.004192673\n0.004192673\n0.004192673\n2.602085e-18\n\n\n21\n0.3677158\n0\n1\n0\n0\n4.398047e-09\n0.3677158\n0.004008840\n0.004008836\n0.004008836\n0.004008836\n2.602085e-18\n\n\n22\n0.3715622\n1\n1\n0\n0\n1.730539e-08\n0.3715623\n0.003846485\n0.003846472\n0.003846472\n0.003846472\n-1.778092e-17\n\n\n23\n0.3752645\n2\n1\n0\n0\n2.678447e-05\n0.3752913\n0.003729069\n0.003702302\n0.003702302\n0.003702302\n-1.301043e-17\n\n\n24\n0.3788382\n3\n1\n0\n0\n4.942828e-05\n0.3788876\n0.003596256\n0.003573612\n0.003573612\n0.003573612\n-1.301043e-17\n\n\n25\n0.3822963\n4\n1\n0\n0\n6.385415e-05\n0.3823602\n0.003472572\n0.003458146\n0.003458146\n0.003458146\n-1.387779e-17\n\n\n26\n0.3856503\n5\n1\n0\n0\n7.209272e-05\n0.3857224\n0.003362254\n0.003354016\n0.003354016\n0.003354016\n6.071532e-18\n\n\n27\n0.3889100\n6\n1\n0\n0\n7.658223e-05\n0.3889865\n0.003264130\n0.003259640\n0.003259640\n0.003259640\n-5.204170e-18\n\n\n28\n0.3920836\n7\n1\n0\n0\n7.901387e-05\n0.3921627\n0.003176117\n0.003173686\n0.003173686\n0.003173686\n-1.040834e-17\n\n\n29\n0.3951787\n8\n1\n0\n0\n8.037496e-05\n0.3952590\n0.003096387\n0.003095026\n0.003095026\n0.003095026\n-2.385245e-17\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n9231\n0.9795925\n12\n19\n20\n0\n8.327853e-05\n0.9796758\n3.607475e-06\n3.607475e-06\n3.607475e-06\n3.607475e-06\n1.581919e-17\n\n\n9232\n0.9795961\n13\n19\n20\n0\n8.327853e-05\n0.9796794\n3.606640e-06\n3.606640e-06\n3.606640e-06\n3.606640e-06\n3.827276e-17\n\n\n9233\n0.9795997\n14\n19\n20\n0\n8.327853e-05\n0.9796830\n3.605805e-06\n3.605805e-06\n3.605805e-06\n3.605805e-06\n-8.857000e-18\n\n\n9234\n0.9796033\n15\n19\n20\n0\n8.327853e-05\n0.9796866\n3.604971e-06\n3.604971e-06\n3.604971e-06\n3.604971e-06\n-3.186792e-17\n\n\n9235\n0.9796069\n16\n19\n20\n0\n8.327853e-05\n0.9796902\n3.604136e-06\n3.604136e-06\n3.604136e-06\n3.604136e-06\n-4.810512e-17\n\n\n9236\n0.9796106\n17\n19\n20\n0\n8.327853e-05\n0.9796938\n3.603302e-06\n3.603302e-06\n3.603302e-06\n3.603302e-06\n3.612087e-17\n\n\n9237\n0.9796142\n18\n19\n20\n0\n8.327853e-05\n0.9796974\n3.602468e-06\n3.602468e-06\n3.602468e-06\n3.602468e-06\n-1.868893e-17\n\n\n9238\n0.9796178\n19\n19\n20\n0\n8.327853e-05\n0.9797010\n3.601635e-06\n3.601635e-06\n3.601635e-06\n3.601635e-06\n-7.936699e-18\n\n\n9239\n0.9796214\n20\n19\n20\n0\n8.327853e-05\n0.9797046\n3.600801e-06\n3.600801e-06\n3.600801e-06\n3.600801e-06\n5.086136e-17\n\n\n9240\n0.9796250\n0\n20\n20\n0\n8.327853e-05\n0.9797082\n3.599968e-06\n3.599968e-06\n3.599968e-06\n3.599968e-06\n2.912480e-17\n\n\n9241\n0.9796286\n1\n20\n20\n0\n8.327853e-05\n0.9797118\n3.599135e-06\n3.599135e-06\n3.599135e-06\n3.599135e-06\n2.031481e-17\n\n\n9242\n0.9796322\n2\n20\n20\n0\n8.327853e-05\n0.9797154\n3.598303e-06\n3.598303e-06\n3.598303e-06\n3.598303e-06\n6.763982e-18\n\n\n9243\n0.9796358\n3\n20\n20\n0\n8.327853e-05\n0.9797190\n3.597470e-06\n3.597470e-06\n3.597470e-06\n3.597470e-06\n-2.921163e-17\n\n\n9244\n0.9796393\n4\n20\n20\n0\n8.327853e-05\n0.9797226\n3.596638e-06\n3.596638e-06\n3.596638e-06\n3.596638e-06\n5.699685e-18\n\n\n9245\n0.9796429\n5\n20\n20\n0\n8.327853e-05\n0.9797262\n3.595806e-06\n3.595806e-06\n3.595806e-06\n3.595806e-06\n-1.727397e-17\n\n\n9246\n0.9796465\n6\n20\n20\n0\n8.327853e-05\n0.9797298\n3.594975e-06\n3.594975e-06\n3.594975e-06\n3.594975e-06\n-4.977589e-18\n\n\n9247\n0.9796501\n7\n20\n20\n0\n8.327853e-05\n0.9797334\n3.594143e-06\n3.594143e-06\n3.594143e-06\n3.594143e-06\n2.477444e-17\n\n\n9248\n0.9796537\n8\n20\n20\n0\n8.327853e-05\n0.9797370\n3.593312e-06\n3.593312e-06\n3.593312e-06\n3.593312e-06\n5.409449e-17\n\n\n9249\n0.9796573\n9\n20\n20\n0\n8.327853e-05\n0.9797406\n3.592481e-06\n3.592481e-06\n3.592481e-06\n3.592481e-06\n-4.600659e-17\n\n\n9250\n0.9796609\n10\n20\n20\n0\n8.327853e-05\n0.9797442\n3.591651e-06\n3.591651e-06\n3.591651e-06\n3.591651e-06\n3.956999e-17\n\n\n9251\n0.9796645\n11\n20\n20\n0\n8.327853e-05\n0.9797478\n3.590820e-06\n3.590820e-06\n3.590820e-06\n3.590820e-06\n-4.026117e-17\n\n\n9252\n0.9796681\n12\n20\n20\n0\n8.327853e-05\n0.9797514\n3.589990e-06\n3.589990e-06\n3.589990e-06\n3.589990e-06\n2.947717e-17\n\n\n9253\n0.9796717\n13\n20\n20\n0\n8.327853e-05\n0.9797550\n3.589160e-06\n3.589160e-06\n3.589160e-06\n3.589160e-06\n8.646512e-18\n\n\n9254\n0.9796753\n14\n20\n20\n0\n8.327853e-05\n0.9797585\n3.588330e-06\n3.588330e-06\n3.588330e-06\n3.588330e-06\n-9.917909e-18\n\n\n9255\n0.9796789\n15\n20\n20\n0\n8.327853e-05\n0.9797621\n3.587501e-06\n3.587501e-06\n3.587501e-06\n3.587501e-06\n-4.435573e-17\n\n\n9256\n0.9796824\n16\n20\n20\n0\n8.327853e-05\n0.9797657\n3.586672e-06\n3.586672e-06\n3.586672e-06\n3.586672e-06\n-1.940129e-18\n\n\n9257\n0.9796860\n17\n20\n20\n0\n8.327853e-05\n0.9797693\n3.585843e-06\n3.585843e-06\n3.585843e-06\n3.585843e-06\n-1.196561e-17\n\n\n9258\n0.9796896\n18\n20\n20\n0\n8.327853e-05\n0.9797729\n3.585014e-06\n3.585014e-06\n3.585014e-06\n3.585014e-06\n1.828617e-17\n\n\n9259\n0.9796932\n19\n20\n20\n0\n8.327853e-05\n0.9797765\n3.584186e-06\n3.584186e-06\n3.584186e-06\n3.584186e-06\n-4.061396e-17\n\n\n9260\n0.9796968\n20\n20\n20\n0\n8.327853e-05\n0.9797801\n3.583358e-06\n3.583358e-06\n3.583358e-06\n3.583358e-06\n1.500222e-17\n\n\n\n\n\n\nc(sum(joint_probs$V1 * joint_probs$accum_time), \n  sum(joint_probs$V2 * joint_probs$accum_time), \n  sum(joint_probs$V3 * joint_probs$accum_time))\n\n\n00.0009615982869341380.00057948368296313\n\n\n\nc(sum(df$X1 * df$prob), sum(df$X2 * df$prob), sum(df$X3 * df$prob))\n\n\n7.731127094402044.694249683567271.19250319602024\n\n\n\nplot_df &lt;- df %&gt;% group_by(X2, X3) %&gt;% summarise(prob = sum(prob))\nplot_df[,-ncol(plot_df)] &lt;- lapply(plot_df[,-ncol(plot_df)], as.factor)\nhead(plot_df)\n\n\n`summarise()` has grouped output by 'X2'. You can override using the `.groups` argument.\n\n\n\n\n\nA grouped_df: 6 × 3\n\n\nX2\nX3\nprob\n\n\n&lt;fct&gt;\n&lt;fct&gt;\n&lt;dbl&gt;\n\n\n\n\n0\n0\n0.3637069369\n\n\n0\n1\n0.0054461936\n\n\n0\n2\n0.0026874034\n\n\n0\n3\n0.0016935722\n\n\n0\n4\n0.0011754205\n\n\n0\n5\n0.0008663035\n\n\n\n\n\n\nggplot(plot_df, aes(x=X2, y=X3)) +\n    geom_tile(aes(fill = prob)) + \n    geom_text(aes(label = round(prob, 3))) +\n    scale_fill_distiller(palette = 'PiYG',direction = 1,\n                    limit=max(abs(plot_df$prob)) * c(-1, 1)\n                    ) +\n    theme_minimal() +\n     theme(panel.grid.major = element_blank(), \n            panel.grid.minor = element_blank(), \n            text=element_text(size=17))\n\n\n\n\n\n\n\n\n\nggplot(plot_df, aes(x=X2, y=X3)) +\n    geom_tile(aes(fill = log10(prob))) + \n    geom_text(aes(label = round(log10(prob), 2))) +\n    scale_fill_distiller(palette = 'PiYG',direction = 1,\n                    limit=max(abs(log10(plot_df$prob))) * c(-1, 1)\n                    ) +\ntheme_minimal() +\n theme(panel.grid.major = element_blank(), \n        panel.grid.minor = element_blank(), \n        text=element_text(size=17))\n\n\n\n\n\n\n\n\n\n\n# plot_graph &lt;- function(gam, constrained=TRUE, \n#                        subgraphs=FALSE, ranksep=2, nodesep=1,\n#                        subgraphfun=function(state, index) paste(state[-length(state)], collapse=\"\"), \n#                        size=c(6, 6), fontsize=10, rankdir=\"LR\", align=FALSE, nodecolor='white', rainbow=FALSE, penwidth=1) {\n\n\n#     format_rate &lt;- function(rate) {\n#         # tol = .Machine$double.eps^0.5\n#         # if (min(abs(c(rate%%1, rate%%1-1))) &lt; tol) {\n#         if (rate == round(rate)) {\n#             return(rate)\n#         } else {\n#             return(formatC(rate, format = \"e\", digits = 2))\n#         }\n#     }\n\n#     random_color &lt;- function() {\n#         if (rainbow) {\n#             return(paste(\"#\", paste0(sample(c(0:9, LETTERS[1:6]), 6, T), collapse = ''), sep=''))\n#         } else {\n#             return('#000000')\n#         }\n#     }\n\n#     sub_graphs = list()\n#     state_classes = list()\n    \n#     if (constrained) {\n#         constrained &lt;- 'true'\n#     } else {\n#         constrained &lt;- 'false'\n#     }\n\n#     states &lt;- c()\n#     for (i in 1:(nrow(gam$states))) {\n#         states &lt;- c(states, paste0(i, ' [label=\"', paste(gam$states[i,], collapse = \",\"), '\"];'))\n#     }\n    \n#     edge_templ &lt;- '\"FROM\" -&gt; \"TO\" [constraint=true, label=\"LABEL\",labelfloat=false,color=\"COLOR\",fontcolor=\"COLOR\"];'\n\n#     subgraph_template &lt;- '\n#     subgraph cluster_FREQBIN {\n#         rank=same;\n#         style=filled;\n#         color=whitesmoke;\n#         node [style=filled];\n#         NODES;\n#         label = \"FREQBIN\";\n#     }\n#     '\n#     start_name &lt;- 'IPV'\n#     absorbing_name &lt;- 'Absorb'\n#     edges &lt;- c()\n#     # IPV edges\n#     for (i in 1:length(gam$IPV)) {\n#         if (gam$IPV[i] &gt; 0) {\n#             edge &lt;- edge_templ\n#             edge &lt;- sub('FROM', start_name, edge)\n#             edge &lt;- sub('TO', i, edge)\n#             edge &lt;- sub('LABEL', gam$IPV[i], edge)\n#             edge &lt;- gsub('COLOR', random_color(), edge)                        \n#             edges &lt;- c(edges, edge)\n#         }\n#     }    \n#     # Matrix edges\n#     for (i in 1:(nrow(gam$states))) {\n#         for (j in 1:nrow(gam$states)) {\n#             if ((i != j) && (gam$SIM[i, j] &gt; 0)) {\n#                 edge &lt;- edge_templ\n#                 edge &lt;- sub('FROM', i, edge)\n#                 edge &lt;- sub('TO', j, edge)\n#                 edge &lt;- sub('LABEL', format_rate(gam$SIM[i, j]), edge)\n#                 edge &lt;- gsub('COLOR', random_color(), edge)\n#                 edges &lt;- c(edges, edge)\n#             }\n#         }\n#     }\n\n#     absorb_rates &lt;- -rowSums(gam$SIM)\n#     for (i in 1:nrow(gam$states)) {\n\n#         # TODO: Avoid the hack below by changing the function to use the graph instead of the matrix\n#         if (absorb_rates[i] &gt; abs(1e-14)) {\n#         # if (absorb_rates[i] &gt; 0) {\n#             edge &lt;- edge_templ\n#             edge &lt;- sub('FROM', i, edge)\n#             edge &lt;- sub('TO', absorbing_name, edge)\n#             edge &lt;- sub('LABEL', absorb_rates[i], edge)\n#             edge &lt;- gsub('COLOR', random_color(), edge)            \n#             edges &lt;- c(edges, edge)\n#         }\n#     }\n\n#     graph_spec &lt;- paste(c(states, edges), collapse = '\\n')\n\n#     rank_same &lt;- ''\n\n#     if (subgraphs) {        \n#         for (i in 1:(nrow(gam$states))) {\n#             sg &lt;- subgraphfun(gam$states[i,], index=i)\n#             sub_graphs[[sg]] &lt;- c(sub_graphs[[sg]], i)\n#         }\n#         for (sg in labels(sub_graphs)) {\n            \n#             nodes &lt;- sub_graphs[[sg]]\n#             tmpl &lt;- subgraph_template\n#             node_str &lt;- ''\n#             for (i in 1:length(nodes)) {\n#                 node_str &lt;- paste(node_str, paste('\"', nodes[i], '\" ', sep=''), sep=' ')\n#             }\n#             tmpl &lt;- sub('NODES', node_str, tmpl)\n#             tmpl &lt;- sub('FREQBIN', sg, tmpl)            \n#             tmpl &lt;- sub('FREQBIN', sg, tmpl)            \n#             graph_spec &lt;- paste(graph_spec, tmpl)\n#         }\n\n\n#         if (align) {\n#             for (i in 1:(nrow(gam$states))) {\n#                 sc &lt;- paste(head(gam$states[i,], -1), collapse = \",\")\n#                 state_classes[[sc]] &lt;- c(state_classes[[sc]], i)\n#             }\n#             for (sc in labels(state_classes)) {\n#                 rank_same &lt;- paste(rank_same, '{rank=same; ', sep='')\n#                 nodes &lt;- state_classes[[sc]]\n#                 for (i in 1:length(nodes)) {\n#                     rank_same &lt;- paste(rank_same, paste('\"', nodes[i], '\" ', sep=''), sep=' ')\n#                 }            \n#                 rank_same &lt;- paste(rank_same, ' }', sep='\\n')\n#             }\n#         }\n    \n#     }\n\n#     style_str &lt;- '\n#         graph [compound=true newrank=true pad=\"0.5\", ranksep=\"RANKSEP\", nodesep=\"NODESEP\"] \n#         rankdir=RANKDIR;\n#         size=\"SIZEX,SIZEY\";\n#         fontname=\"Helvetica,Arial,sans-serif\"\n#       node [fontname=\"Helvetica,Arial,sans-serif\", fontsize=FONTSIZE, style=filled, fillcolor=\"NODECOLOR\"]\n#       edge [fontname=\"Helvetica,Arial,sans-serif\", fontsize=FONTSIZE, penwidth=PENWIDTH]\n#         Absorb [style=filled,color=\"lightgrey\"]\n#         IPV [style=filled,color=\"lightgrey\"]\n#         RANKSAME\n#     '\n#     style_str &lt;- sub('SIZEX', size[1], style_str)\n#     style_str &lt;- sub('SIZEY', size[2], style_str)\n#     style_str &lt;- gsub('FONTSIZE', fontsize, style_str)    \n#     style_str &lt;- gsub('RANKDIR', rankdir, style_str)    \n#     style_str &lt;- gsub('RANKSAME', rank_same, style_str)\n#     style_str &lt;- gsub('RANKSEP', ranksep, style_str)\n#     style_str &lt;- gsub('NODESEP', nodesep, style_str)\n#     graph_string &lt;- paste('digraph G {', style_str, graph_spec, '}', sep='\\n')\n#     graph_string &lt;- gsub('NODECOLOR', nodecolor, graph_string)  \n#     graph_string &lt;- gsub('PENWIDTH', penwidth, graph_string)  \n#     system(\"dot -Tsvg -o tmp.svg\", input=graph_string, intern=TRUE)\n#     return(display_svg(file=\"tmp.svg\"))\n# }\n                  \nsample_size &lt;- 3\nmutation_rate &lt;- 1\nmax_tons &lt;- 1\ntotal_tons &lt;- Inf\nbase &lt;- max_tons + 1\ngraph &lt;- joint_prob_coalescent(sample_size, mutation_rate, max_tons, total_tons=total_tons)\n\nplot_graph(graph_as_matrix(graph), rainbow=TRUE, size=c(10, 8), align=TRUE,\n           fontsize=16, ranksep=1, nodesep=0.25,\n           subgraphs=TRUE,\n           # rankdir=\"TB\",\n           subgraphfun=function(state, index) as.character((index+1) %/% 2)\n           # subgraphfun=function(state, index) paste(state[-length(state)], collapse=\"\")\n)"
  },
  {
    "objectID": "examples/python/experiments.html",
    "href": "examples/python/experiments.html",
    "title": "Experments",
    "section": "",
    "text": "Timings reported in paper\n\ndevtools::install_github(\"TobiasRoikjer/PtDAlgorithms\")\nlibrary(ptdalgorithms)\nset.seed(1234)\n\n\nconstruct_rabbit_graph_R &lt;- function(number_of_rabbits, flooding_rate_l, flooding_rate_r) {\n    # We represent the vector as two integers, the number of rabbits on the left and right island\n    state_vector_length &lt;- 2\n    graph &lt;- create_graph(state_vector_length)\n    initial_state &lt;- c(number_of_rabbits, 0)\n    # The initial state is the only starting state, with 100% starting probability\n    add_edge(\n      starting_vertex(graph),\n      find_or_create_vertex(graph, initial_state),\n      1\n    )\n    index &lt;- 2\n    # Iterate over all unvisited vertices\n    while (index &lt;= vertices_length(graph)) {\n      vertex &lt;- vertex_at(graph, index)\n      state &lt;- vertex$state\n      if (state[1] &gt; 0) {\n        # Rabbit jump left to right\n        child_state &lt;- c(state[1] - 1, state[2] + 1)\n        add_edge(\n          vertex,\n          find_or_create_vertex(graph, child_state),\n          1\n        )\n\n        # Left island flooding\n        child_state &lt;- c(0, state[2])\n        add_edge(\n          vertex,\n          find_or_create_vertex(graph, child_state),\n          flooding_rate_l\n        )\n      }\n\n      if (state[2] &gt; 0) {\n        # Rabbit jump right to left\n        child_state &lt;- c(state[1] + 1, state[2] - 1)\n        add_edge(\n          vertex,\n          find_or_create_vertex(graph, child_state),\n          1\n        )\n        # Right island flooding with rate of 4\n        child_state &lt;- c(state[1], 0)\n        add_edge(\n          vertex,\n          find_or_create_vertex(graph, child_state),\n          flooding_rate_r\n        )\n      }\n      index &lt;- index + 1\n    }\n    return(graph)\n}\n\n\nRcpp::sourceCpp(\"./rabbit_construction_c.cpp\")\n\n\nRABBIT_NUMBERS &lt;- c(10, 50, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300,1400,1500)\ndf &lt;- data.frame()\n\nfor (rabbits in RABBIT_NUMBERS) {\n    start &lt;- proc.time()[3]\n    if (rabbits &lt;= 500) {\n    construct_rabbit_graph_R(rabbits, 2, 4)\n    }\n    end &lt;- proc.time()[3]\n    time_R &lt;- end-start\n    start &lt;- proc.time()[3]\n    \n    graph &lt;- construct_rabbit_graph(rabbits, 2, 4)\n    \n    end &lt;- proc.time()[3]\n    time_c = end-start\n    df &lt;- rbind(df, list(rabbits=rabbits, time_c=time_c, time_R=time_R, vertices=vertices_length(graph)))\n}\n\ndf\n\n\nA data.frame: 17 × 4\n\n\nrabbits\ntime_c\ntime_R\nvertices\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;int&gt;\n\n\n\n\n10\n0.001\n0.002\n67\n\n\n50\n0.000\n0.263\n1327\n\n\n100\n0.003\n0.262\n5152\n\n\n200\n0.020\n1.297\n20302\n\n\n300\n0.039\n5.867\n45452\n\n\n400\n0.089\n5.222\n80602\n\n\n500\n0.228\n8.179\n125752\n\n\n600\n0.211\n0.000\n180902\n\n\n700\n0.352\n0.000\n246052\n\n\n800\n0.877\n0.000\n321202\n\n\n900\n0.621\n0.000\n406352\n\n\n1000\n1.157\n0.000\n501502\n\n\n1100\n1.445\n0.000\n606652\n\n\n1200\n1.599\n0.000\n721802\n\n\n1300\n2.587\n0.000\n846952\n\n\n1400\n2.508\n0.000\n982102\n\n\n1500\n3.843\n0.000\n1127252\n\n\n\n\n\n\nRABBIT_NUMBERS &lt;- c(10, 50, 100, 150, 200, 250)\ndf &lt;- data.frame()\n\nfor (rabbits in RABBIT_NUMBERS) {\n    graph &lt;- construct_rabbit_graph(rabbits, 2, 4)\n    matrix_time &lt;- NA\n    if (rabbits &lt;= 100) {\n        M &lt;- graph_as_matrix(graph)\n    \n    start &lt;- proc.time()[3]\n   \n        solve(M$SIM)\n    end &lt;- proc.time()[3]\n        matrix_time &lt;- end - start\n    }\n    \n    start &lt;- proc.time()[3]\n    expectation(graph)\n    end &lt;- proc.time()[3]\n    time = end-start\n    df &lt;- rbind(df, list(rabbits=rabbits, time=time, matrix_time=matrix_time,vertices=vertices_length(graph)))\n}\n\ndf\n\n\nRABBIT_NUMBERS &lt;- c(10, 50, 100, 150, 200)\ndf &lt;- data.frame()\n\nfor (rabbits in RABBIT_NUMBERS) {\n    graph &lt;- construct_rabbit_graph(rabbits, 2, 4)\n\n      expectation(graph)\n    start &lt;- proc.time()[3]\n                  for (i in 1:100) {\n    expectation(graph)\n                      }\n    end &lt;- proc.time()[3]\n    time = end-start\n    df &lt;- rbind(df, list(rabbits=rabbits, time=time,vertices=vertices_length(graph)))\n}\n\ndf\n\n\nA data.frame: 5 × 3\n\n\nrabbits\ntime\nvertices\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;int&gt;\n\n\n\n\n10\n0.000\n67\n\n\n50\n0.013\n1327\n\n\n100\n0.090\n5152\n\n\n150\n0.324\n11477\n\n\n200\n0.755\n20302\n\n\n\n\n\n\nRABBIT_NUMBERS &lt;- c(10, 50, 100, 150, 200)\ndf &lt;- data.frame()\n\nfor (rabbits in RABBIT_NUMBERS) {\n    graph &lt;- construct_rabbit_graph(rabbits, 2, 4)\n\n    start &lt;- proc.time()[3]\n    ctx &lt;- distribution_context(graph, 10000)\n    \n    while (distribution_context_state(ctx)$cdf &lt; 0.99) {\n        distribution_context_step(ctx)\n    }\n    end &lt;- proc.time()[3]\n    time = end-start\n    df &lt;- rbind(df, list(rabbits=rabbits, time=time,vertices=vertices_length(graph)))\n}\n\ndf\n\n\nA data.frame: 5 × 3\n\n\nrabbits\ntime\nvertices\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;int&gt;\n\n\n\n\n10\n0.135\n67\n\n\n50\n0.854\n1327\n\n\n100\n2.945\n5152\n\n\n150\n7.474\n11477\n\n\n200\n30.452\n20302"
  },
  {
    "objectID": "examples/showcase_rpy2/showcase.html",
    "href": "examples/showcase_rpy2/showcase.html",
    "title": "Showcase for ptdalgorithms",
    "section": "",
    "text": "Python header:\n%load_ext rpy2.ipython\n\nfrom IPython.display import Image\nfrom graphviz import Digraph\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\nsns.set_style('ticks')\nfrom matplotlib_inline.backend_inline import set_matplotlib_formats\nset_matplotlib_formats('retina', 'png')\n\ndef plot_graph(states, ipv, sim, constrained=True, size='10'):\n\n    constrained = constrained and 'true' or 'false'\n    states = np.array(states)\n    \n    # add the missing row and col to SIM\n    rates = np.r_[np.c_[sim, -sim.sum(axis=1)], np.zeros((1, len(sim)+1))]\n\n    dot = Digraph()\n    dot.node('S', 'S')\n    for i in range(1, len(states)):\n        dot.node(str(i), str(states[i]))\n    for i in range(len(ipv)):\n        if ipv[i]:\n            dot.edge('S', str(i+1), constraint=constrained, label=str(ipv[i]))\n    for i in range(1, len(states)):\n        for j in range(1, len(states)):\n            if i != j and rates[i-1, j-1] &gt; 0:\n                dot.edge(str(i), str(j), constraint=constrained, label=str(rates[i-1, j-1]))\n    dot.graph_attr['size'] = size                \n    return dot\nR header:\n%%R\nlibrary(tidyverse)\n\nlibrary(devtools)\nremove.packages(\"ptdalgorithms\")\n\ndevtools::install_github(\"TobiasRoikjer/PtDAlgorithms\")\n\nlibrary(ptdalgorithms)\n\nR[write to console]: Removing package from ‘/Users/kmt/miniconda3/envs/phasetypes/lib/R/library’\n(as ‘lib’ is unspecified)\n\nR[write to console]: Updating HTML index of packages in '.Library'\n\nR[write to console]: Making 'packages.html' ...\nR[write to console]:  done\n\nR[write to console]: Downloading GitHub repo TobiasRoikjer/PtDAlgorithms@HEAD\n\n\n\n* checking for file ‘/private/var/folders/33/sv_s_4ps2gjgpwdxjvz9jly00000gn/T/RtmpmKKfNf/remotes123b76f7b0b3/TobiasRoikjer-PtDAlgorithms-d022b12/DESCRIPTION’ ... OK\n* preparing ‘ptdalgorithms’:\n* checking DESCRIPTION meta-information ... OK\n* cleaning src\n* checking for LF line-endings in source and make files and shell scripts\n* checking for empty or unneeded directories\nOmitted ‘LazyData’ from DESCRIPTION\n* building ‘ptdalgorithms_1.0.0.tar.gz’\n\n\n\n* installing *source* package ‘ptdalgorithms’ ...\n** using staged installation\n** libs\n\n\nx86_64-apple-darwin13.4.0-clang++ -std=gnu++14 -I\"/Users/kmt/miniconda3/envs/phasetypes/lib/R/include\" -DNDEBUG  -I'/Users/kmt/miniconda3/envs/phasetypes/lib/R/library/Rcpp/include' -D_FORTIFY_SOURCE=2 -isystem /Users/kmt/miniconda3/envs/phasetypes/include -mmacosx-version-min=10.9 -I/Users/kmt/miniconda3/envs/phasetypes/include  -I../api/cpp -I../api/c -Ic/ -Icpp/ -fPIC  -march=core2 -mtune=haswell -mssse3 -ftree-vectorize -fPIC -fPIE -fstack-protector-strong -O2 -pipe -stdlib=libc++ -fvisibility-inlines-hidden  -fmessage-length=0 -isystem /Users/kmt/miniconda3/envs/phasetypes/include -fdebug-prefix-map=/Users/runner/miniforge3/conda-bld/r-base-split_1639563465184/work=/usr/local/src/conda/r-base-4.1.2 -fdebug-prefix-map=/Users/kmt/miniconda3/envs/phasetypes=/usr/local/src/conda-prefix  -c RcppExports.cpp -o RcppExports.o\nx86_64-apple-darwin13.4.0-clang++ -std=gnu++14 -I\"/Users/kmt/miniconda3/envs/phasetypes/lib/R/include\" -DNDEBUG  -I'/Users/kmt/miniconda3/envs/phasetypes/lib/R/library/Rcpp/include' -D_FORTIFY_SOURCE=2 -isystem /Users/kmt/miniconda3/envs/phasetypes/include -mmacosx-version-min=10.9 -I/Users/kmt/miniconda3/envs/phasetypes/include  -I../api/cpp -I../api/c -Ic/ -Icpp/ -fPIC  -march=core2 -mtune=haswell -mssse3 -ftree-vectorize -fPIC -fPIE -fstack-protector-strong -O2 -pipe -stdlib=libc++ -fvisibility-inlines-hidden  -fmessage-length=0 -isystem /Users/kmt/miniconda3/envs/phasetypes/include -fdebug-prefix-map=/Users/runner/miniforge3/conda-bld/r-base-split_1639563465184/work=/usr/local/src/conda/r-base-4.1.2 -fdebug-prefix-map=/Users/kmt/miniconda3/envs/phasetypes=/usr/local/src/conda-prefix  -c ptdalgorithms.cpp -o ptdalgorithms.o\nx86_64-apple-darwin13.4.0-clang++ -std=gnu++14 -dynamiclib -Wl,-headerpad_max_install_names -undefined dynamic_lookup -single_module -multiply_defined suppress -L/Users/kmt/miniconda3/envs/phasetypes/lib/R/lib -Wl,-dead_strip_dylibs -Wl,-pie -Wl,-headerpad_max_install_names -Wl,-dead_strip_dylibs -Wl,-rpath,/Users/kmt/miniconda3/envs/phasetypes/lib -L/Users/kmt/miniconda3/envs/phasetypes/lib -o ptdalgorithms.dylib RcppExports.o ptdalgorithms.o -L/Users/kmt/miniconda3/envs/phasetypes/lib/R/lib -lR -Wl,-framework -Wl,CoreFoundation\n\n\nld: warning: -pie being ignored. It is only used when linking a main executable\ninstalling to /Users/kmt/miniconda3/envs/phasetypes/lib/R/library/00LOCK-ptdalgorithms/00new/ptdalgorithms/libs\n** R\n** byte-compile and prepare package for lazy loading\n** help\n*** installing help indices\n** building package indices\n** testing if installed package can be loaded from temporary location\n** checking absolute paths in shared objects and dynamic libraries\n** testing if installed package can be loaded from final location\n** testing if installed package keeps a record of temporary installation path\n* DONE (ptdalgorithms)"
  },
  {
    "objectID": "examples/showcase_rpy2/showcase.html#standard-coalescent",
    "href": "examples/showcase_rpy2/showcase.html#standard-coalescent",
    "title": "Showcase for ptdalgorithms",
    "section": "Standard coalescent",
    "text": "Standard coalescent\nIf you already have the subintensity matrix and initial probability vector:\n\n%%R -o sim -o ipv\nsim = matrix(c(-6, 6, 0, 0, \n               0, -3, 1, 2,\n               0, 0, -1, 0,\n               0, 0, 0, -1), nrow=4, ncol=4, byrow = TRUE)\nipv = c(1, 0, 0, 0)\nsim\n\n     [,1] [,2] [,3] [,4]\n[1,]   -6    6    0    0\n[2,]    0   -3    1    2\n[3,]    0    0   -1    0\n[4,]    0    0    0   -1\n\n\n\n%%R \ngraph &lt;- matrix_as_graph(ipv, sim)\n\nNote that the state vectors are ofcause undefined (all zero) when constructing the graph this way:\n\n%%R\ngraph_as_matrix(graph)\n\n$states\n     [,1]\n[1,]    0\n[2,]    0\n[3,]    0\n[4,]    0\n\n$SIM\n     [,1] [,2] [,3] [,4]\n[1,]   -6    6    0    0\n[2,]    0   -3    1    2\n[3,]    0    0   -1    0\n[4,]    0    0    0   -1\n\n$IPV\n[1] 1 0 0 0\n\n\n\n\n%%R\ndph(0.9, graph)\n\n[1] 0.5362689\n\n\nIf you want to generate the state space:\n\n%%R -o states -o ipv -o sim -o n -o graph\nn &lt;- 6\n  \nstate_vector_length &lt;- n\ngraph &lt;- create_graph(state_vector_length)\nstarting_vertex &lt;- vertex_at(graph, 1)\ninitial_state &lt;- rep(0, n)\ninitial_state[1] &lt;- n\n\nadd_edge(\n  starting_vertex,\n  create_vertex(graph, initial_state),\n  1\n)\nindex &lt;- 2\n\nwhile (index &lt;= vertices_length(graph)) {\n  vertex &lt;- vertex_at(graph, index)\n  \n  # loop over all classes of lineages\n  for (i in 1:n) {\n    for (j in i:n) {\n      state &lt;- vertex$state\n      \n      # if same class, there need to be at least two to coalesce\n      if (i == j) {\n        if (state[i] &lt; 2) {\n          next;\n        }\n        # coal rate\n        rate &lt;- state[i] * (state[i] - 1) / 2\n      } else {\n        # else at least one in each class to coalesce\n        if (state[i] &lt; 1 || state[j] &lt; 1) {\n          next;\n        }\n        # number of combinations\n        rate &lt;- state[i] * state[j]\n      }\n      \n      # copy state\n      child_state &lt;- state\n      # update child state\n      child_state[i] &lt;- child_state[i] - 1\n      child_state[j] &lt;- child_state[j] - 1\n      child_state[i+j] &lt;- child_state[i+j] + 1\n      \n      add_edge(\n          vertex,\n          find_or_create_vertex(graph, child_state),\n          rate, c(rate)\n        )\n    }\n  }\n      \n  index &lt;- index + 1\n}\n\nstates &lt;- t(sapply(1:vertices_length(graph), function(index) vertex_at(graph, index)$state ))\nipv &lt;- graph_as_matrix(graph)$IPV\nsim &lt;- graph_as_matrix(graph)$SIM\n\nvertices_length(graph)\n\n[1] 12\n\n\n\nplot_graph(states, ipv, sim)\n\n\n\n\n\n\n\n\nAs matrices:\n\n%%R -o states -o sim\nmatrices &lt;- graph_as_matrix(graph)\nstates &lt;- matrices$states\nsim &lt;- matrices$SIM\nmatrices\n\n$states\n      [,1] [,2] [,3] [,4] [,5] [,6]\n [1,]    6    0    0    0    0    0\n [2,]    4    1    0    0    0    0\n [3,]    2    2    0    0    0    0\n [4,]    3    0    1    0    0    0\n [5,]    0    3    0    0    0    0\n [6,]    1    1    1    0    0    0\n [7,]    2    0    0    1    0    0\n [8,]    0    0    2    0    0    0\n [9,]    0    1    0    1    0    0\n[10,]    1    0    0    0    1    0\n\n$SIM\n      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n [1,]  -15   15    0    0    0    0    0    0    0     0\n [2,]    0  -10    6    4    0    0    0    0    0     0\n [3,]    0    0   -6    0    1    4    1    0    0     0\n [4,]    0    0    0   -6    0    3    3    0    0     0\n [5,]    0    0    0    0   -3    0    0    0    3     0\n [6,]    0    0    0    0    0   -3    0    1    1     1\n [7,]    0    0    0    0    0    0   -3    0    1     2\n [8,]    0    0    0    0    0    0    0   -1    0     0\n [9,]    0    0    0    0    0    0    0    0   -1     0\n[10,]    0    0    0    0    0    0    0    0    0    -1\n\n$IPV\n [1] 1 0 0 0 0 0 0 0 0 0\n\n\n\nInvert subintensity matrix to get Green matrix:\n\n%%R\nU &lt;- -solve(matrices$SIM)\nU\n\n            [,1] [,2]      [,3]       [,4]       [,5]      [,6]       [,7]\n [1,] 0.06666667  0.1 0.1000000 0.06666667 0.03333333 0.2000000 0.10000000\n [2,] 0.00000000  0.1 0.1000000 0.06666667 0.03333333 0.2000000 0.10000000\n [3,] 0.00000000  0.0 0.1666667 0.00000000 0.05555556 0.2222222 0.05555556\n [4,] 0.00000000  0.0 0.0000000 0.16666667 0.00000000 0.1666667 0.16666667\n [5,] 0.00000000  0.0 0.0000000 0.00000000 0.33333333 0.0000000 0.00000000\n [6,] 0.00000000  0.0 0.0000000 0.00000000 0.00000000 0.3333333 0.00000000\n [7,] 0.00000000  0.0 0.0000000 0.00000000 0.00000000 0.0000000 0.33333333\n [8,] 0.00000000  0.0 0.0000000 0.00000000 0.00000000 0.0000000 0.00000000\n [9,] 0.00000000  0.0 0.0000000 0.00000000 0.00000000 0.0000000 0.00000000\n[10,] 0.00000000  0.0 0.0000000 0.00000000 0.00000000 0.0000000 0.00000000\n           [,8]      [,9]     [,10]\n [1,] 0.2000000 0.4000000 0.4000000\n [2,] 0.2000000 0.4000000 0.4000000\n [3,] 0.2222222 0.4444444 0.3333333\n [4,] 0.1666667 0.3333333 0.5000000\n [5,] 0.0000000 1.0000000 0.0000000\n [6,] 0.3333333 0.3333333 0.3333333\n [7,] 0.0000000 0.3333333 0.6666667\n [8,] 1.0000000 0.0000000 0.0000000\n [9,] 0.0000000 1.0000000 0.0000000\n[10,] 0.0000000 0.0000000 1.0000000\n\n\nCompute expectation from matrices:\n\n%%R\nmatrices$IPV %*% U %*% rep(1, length(matrices$IPV))\n\n         [,1]\n[1,] 1.666667\n\n\nCompute moments:\n\n%%R\nexpectation(graph)\n\n[1] 1.666667\n\n\nINFO: building reward compute graph...\n\n\n\n%%R\nexpected_waiting_time(graph)\n\n [1] 1.666667 1.666667 1.600000 1.500000 1.500000 1.333333 1.333333 1.333333\n [9] 1.000000 1.000000 1.000000 0.000000\n\n\n\n%%R\nvariance(graph)\n\n[1] 1.153333\n\n\n\n%%R\n2 * expected_waiting_time(graph, expected_waiting_time(graph)) - expected_waiting_time(graph) * expected_waiting_time(graph)\n\n [1] 1.153333 1.153333 1.148889 1.138889 1.138889 1.111111 1.111111 1.111111\n [9] 1.000000 1.000000 1.000000 0.000000\n\n\n\n%%R\nmoments(graph, 4)\n\n[1]  1.666667  3.931111 12.482222 50.914400\n\n\nMarginal expectations using rewards:\n\n%%R\nstate_matrix &lt;- sapply(1:vertices_length(graph), function(index) vertex_at(graph, index)$state )\nstate_matrix\n\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12]\n[1,]    0    6    4    2    3    0    1    2    0     0     1     0\n[2,]    0    0    1    2    0    3    1    0    1     0     0     0\n[3,]    0    0    0    0    1    0    1    0    0     2     0     0\n[4,]    0    0    0    0    0    0    0    1    1     0     0     0\n[5,]    0    0    0    0    0    0    0    0    0     0     1     0\n[6,]    0    0    0    0    0    0    0    0    0     0     0     1\n\n\nRows happens to be our reward vectors. E.g. singleton rewards:\n\n%%R\nrewards &lt;- sapply(1:vertices_length(graph), function(index) vertex_at(graph, index)$state )\nsingletons &lt;- rewards[1,]\ndoubletons &lt;- rewards[2,]\ntripletons &lt;- rewards[3,]\nsingletons\n\n [1] 0 6 4 2 3 0 1 2 0 0 1 0\n\n\nExpected tripleton branch length:\n\n%%R\nexpectation(graph, tripletons)\n\n[1] 0.6666667\n\n\nSFS:\n\n%%R -o sfs\nsfs &lt;- sapply(1:(dim(rewards)[1]-1), function(i) expectation(graph, rewards[i,]))\nsfs\n\n[1] 2.0000000 1.0000000 0.6666667 0.5000000 0.4000000\n\n\n\nsns.barplot(x=list(range(1, len(sfs)+1)), y=sfs)\nsns.despine()\n\n\n\n\n\n\n\n\nCovariance:\n\n%%R\ncovariance(graph, singletons, doubletons)\n\n[1] -0.1733333\n\n\n\n%%R\ncovariance(graph, singletons, tripletons)\n\n[1] -0.1\n\n\nCovariane between “ton” branch length:\n\n%%R -o cov_mat\ncov_mat &lt;- matrix(nrow=n-1,ncol=n-1)\n\nfor (i in 1:(n-1)) {\n    for (j in 1:(n-1)) {\n        cov_mat[i, j] &lt;- covariance(graph, rewards[i,], rewards[j,])\n    }\n}\n\n\nplt.subplots(1, 1, figsize=(7, 5))\nticks = list(range(1,int(n)))\nax = sns.heatmap(cov_mat, cmap=\"PiYG\", \n                annot=True,\n                center=0,\n                yticklabels=ticks,\n                xticklabels=ticks\n                )\nax.invert_yaxis()\n\n\n\n\n\n\n\n\nDistributions of each “ton” branch length:\n\n%%R -o result\n\nresult = data.frame()\nfor (i in 1:(dim(rewards)[1]-1)) {\n    x &lt;- seq(from = 0, to = 5, by = 0.01)\n    pdf &lt;- dph(x, reward_transform(graph, rewards[i, ]))\n    df &lt;- data.frame(prob = pdf, t=x, ton=i)\n    result &lt;- rbind(result, df)\n}\n#result %&gt;% ggplot(aes(y=prob, x=t, color=ton, group=ton)) + geom_line(size=1)\n\n\nsns.lineplot(data=result, y='prob', x='t', hue='ton')\nsns.despine()\n\n\n\n\n\n\n\n\nCompute expectations from the distributions:\n\n%%R -o sfs\nctx &lt;- distribution_context(graph,1000)\nprev_size &lt;- 0\nwhile (distribution_context_state(ctx)$cdf &lt; 0.999) { \n    distribution_context_step(ctx)\n}\nexpected_visits &lt;- distribution_context_accumulated_visiting_time(ctx)\nsfs &lt;- sapply(1:(dim(rewards)[1]-1), function(i) sum(expected_visits * rewards[i,]))\nsfs\n\n[1] 1.9996008 0.9996008 0.6662674 0.4996008 0.3996008\n\n\n\nsns.barplot(x=list(range(1, len(sfs)+1)), y=sfs)\nsns.despine()\n\n\n\n\n\n\n\n\nChanging rates (edge weights) using parametrization:\n\n%%R -o states -o ipv -o sim\n\ngraph_update_weights_parameterized(graph, c(2))\n\nstates &lt;- t(sapply(1:vertices_length(graph), function(index) vertex_at(graph, index)$state ))\nipv &lt;- graph_as_matrix(graph)$IPV\nsim &lt;- graph_as_matrix(graph)$SIM\n\nChange rates back to normal:\n\nplot_graph(states, ipv, sim)\n\n\n\n\n\n\n\n\n\n%%R -o states -o ipv -o sim\n\ngraph_update_weights_parameterized(graph, c(1))\n\nstates &lt;- t(sapply(1:vertices_length(graph), function(index) vertex_at(graph, index)$state ))\nipv &lt;- graph_as_matrix(graph)$IPV\nsim &lt;- graph_as_matrix(graph)$SIM\n\n\nplot_graph(states, ipv, sim)"
  },
  {
    "objectID": "examples/showcase_rpy2/showcase.html#time-inhomgeneous-coalescent",
    "href": "examples/showcase_rpy2/showcase.html#time-inhomgeneous-coalescent",
    "title": "Showcase for ptdalgorithms",
    "section": "Time-inhomgeneous coalescent",
    "text": "Time-inhomgeneous coalescent\nThe distribution context is always made on the graph without rewards transformation. You can then:\n\nGet the distribution (and from that all moments) of time to absorbtion. Note that you cannot use dph for this as this assumes the current edge-weights and not seqentially updated ones in the distribution context.\nGet the marginal exepectations by summing over the products of the expected accumulated visiting times and rewards.\n\n\n%%R -o cdf1 -o cdf2 -o cdf3\n\ncdf_timeinhom &lt;- function(graph, eqopues, sizes) {\n\n    tmrca_pdf &lt;- c()\n    time &lt;- c()\n    \n    ctx &lt;- distribution_context(graph, 1000)\n    prev_size &lt;- 0\n    while (distribution_context_state(ctx)$cdf &lt; 0.999) { \n        tmrca_pdf[[(length(tmrca_pdf) + 1)]] &lt;- distribution_context_state(ctx)$cdf\n        time[[(length(time) + 1)]] &lt;- distribution_context_state(ctx)$time\n        \n        size &lt;- sizes[findInterval(distribution_context_state(ctx)$time, epoques)]\n        if (size != prev_size) {\n            graph_update_weights_parameterized(graph, c(1/size))\n        }\n        prev_size &lt;- size\n        distribution_context_step(ctx)\n    }\n\n    return(data.frame(prob = unlist(tmrca_pdf), t=unlist(time)))\n\n}\n\nepoques = c(0, 1, 2, 3, 4)\ncdf1 &lt;- cdf_timeinhom(graph, epoques, c(1, 1, 1, 1, 1))\ncdf2 &lt;- cdf_timeinhom(graph, epoques, c(1, 2, 4, 8, 16))\ncdf3 &lt;- cdf_timeinhom(graph, epoques, c(16, 8, 4, 2, 1))\n\n\nfig, axes = plt.subplots(1, 3, figsize=(12, 4))\naxes[0].plot(cdf1.t, cdf1.prob)\naxes[1].plot(cdf2.t, cdf2.prob)\naxes[2].plot(cdf3.t, cdf3.prob)\nsns.despine()\n\n\n\n\n\n\n\n\n\n%%R -o sfs1 -o sfs2 -o sfs3\n\nsfs_timeinhom &lt;- function(graph, eqopues, sizes) {\n\n    tmrca_pdf &lt;- c()\n    time &lt;- c()\n    \n    ctx &lt;- distribution_context(graph, 1000)\n    prev_size &lt;- 0\n    while (distribution_context_state(ctx)$cdf &lt; 0.999) { \n        # tmrca_pdf &lt;- c(tmrca_pdf, distribution_context_state(ctx)$pdf)\n        # time &lt;- c(time, distribution_context_state(ctx)$time)\n        tmrca_pdf[[(length(tmrca_pdf) + 1)]] &lt;- distribution_context_state(ctx)$pdf\n        time[[(length(time) + 1)]] &lt;- distribution_context_state(ctx)$time\n        \n        size &lt;- sizes[findInterval(distribution_context_state(ctx)$time, epoques)]\n        if (size != prev_size) {\n            graph_update_weights_parameterized(graph, c(1/size))\n        }\n        prev_size &lt;- size\n        distribution_context_step(ctx)\n    }\n    expected_visits &lt;- distribution_context_accumulated_visiting_time(ctx)\n    \n    sfs &lt;- c()\n    for (i in 1:(dim(rewards)[1]-1)) {\n        sfs &lt;- c(sfs, sum(expected_visits * rewards[i, ]))\n    }\n    return(sfs)\n}\n\nepoques = c(0, 1, 2, 3, 4)\nsfs1 &lt;- sfs_timeinhom(graph, epoques, c(1, 1, 1, 1, 1))\nsfs2 &lt;- sfs_timeinhom(graph, epoques, c(1, 2, 4, 8, 16))\nsfs3 &lt;- sfs_timeinhom(graph, epoques, c(16, 8, 4, 2, 1))\n\n\nfig, axes = plt.subplots(1, 3, figsize=(12, 4))\nsns.barplot(x=list(range(1, len(sfs1)+1)), y=sfs1, ax=axes[0]).set_title(\"Constant 1\")\nsns.barplot(x=list(range(1, len(sfs2)+1)), y=sfs2, ax=axes[1]).set_title(\"Exp growth from 1\")\nsns.barplot(x=list(range(1, len(sfs3)+1)), y=sfs3, ax=axes[2]).set_title(\"Exp decline to 1\")\nsns.despine()"
  },
  {
    "objectID": "examples/showcase_rpy2/showcase.html#super-simple-model-in-keynote-presentation",
    "href": "examples/showcase_rpy2/showcase.html#super-simple-model-in-keynote-presentation",
    "title": "Showcase for ptdalgorithms",
    "section": "Super simple model in Keynote presentation",
    "text": "Super simple model in Keynote presentation\nSimplest possible model as example of how higher order moments are computed.\n\n%%R -o states -o ipv -o sim\n\ngraph &lt;- create_graph(1)\n\nA &lt;- create_vertex(graph, c(1))\nB &lt;- create_vertex(graph, c(2))\nC &lt;- create_vertex(graph, c(3))\nD &lt;- create_vertex(graph, c(4))\n\nadd_edge(starting_vertex(graph), A, 1)\nadd_edge(A, B, 1)\nadd_edge(B, C, 1)\nadd_edge(C, D, 1)\n\nstates &lt;- t(sapply(1:vertices_length(graph), function(index) vertex_at(graph, index)$state, simplify = FALSE))\nipv &lt;- graph_as_matrix(graph)$IPV\nsim &lt;- graph_as_matrix(graph)$SIM\n\n\nplot_graph(states, ipv, sim, constrained=False)\n\n\n\n\n\n\n\n\n\n%%R\nexpected_waiting_time(graph)\n\n[1] 3 3 2 1 0\n\n\nINFO: building reward compute graph...\n\n\n\n%%R\nexpected_waiting_time(graph, expected_waiting_time(graph))\n\n[1] 6 6 3 1 0\n\n\n\n%%R\nmoments(graph, 3)\n\n[1]  3 12 60\n\n\n\n%%R\n2 * expected_waiting_time(graph, expected_waiting_time(graph)) - expected_waiting_time(graph) * expected_waiting_time(graph)\n\n[1] 3 3 2 1 0\n\n\n\n%%R\nvariance(graph)\n\n[1] 3"
  },
  {
    "objectID": "examples/showcase_rpy2/showcase.html#model-with-two-loci-two-islands-with-samples-from-one-population",
    "href": "examples/showcase_rpy2/showcase.html#model-with-two-loci-two-islands-with-samples-from-one-population",
    "title": "Showcase for ptdalgorithms",
    "section": "Model with two loci, two islands, with samples from one population",
    "text": "Model with two loci, two islands, with samples from one population\nEach state has the following three properties: 1. nr decendants at locus 1 2. nr decendants at locus 2 3. what population the lineage is currently in\n\n%%R\nRcpp::sourceCpp(\"./two_locus_two_island.cpp\")\n\nld: warning: -pie being ignored. It is only used when linking a main executable\n\n\n\n# %%R\n\n# setClass(\"conf\", slots=list(locus1=\"numeric\", locus2=\"numeric\", population=\"numeric\"))\n\n# obj &lt;- new(\"conf\", locus1=3, locus2=2, population=1)\n# obj@population\n\n# r_index_to_props &lt;- function(s, i) {\n#     #' returns the locus1, locus2, population\n#     #' conformation of lineages represented by\n#     #' state vector index i.\n#     stopifnot(i &gt; 0)\n#     d &lt;- s + 1 # dim\n#     idx &lt;- i - 1\n#     p &lt;- idx %/% d**2\n#     stopifnot(i &lt;= 2*d**2)\n#     a &lt;- (idx - p*d**2) %/% d\n#     b &lt;- (idx - p*d**2) %% d\n#     return(new(\"conf\", locus1=a, locus2=b, population=p+1))\n# }\n# r_props_to_index &lt;- function(s, a, b, p) {\n#     #' returns the state vector index representing\n#     #' the locus1, locus2, population conformation.\n#     d &lt;- s + 1\n#     i = (p-1)*d**2 + a*d + b + 1\n#     return(i)\n# }\n\n\n# %%R\n# n &lt;- 2\n# for (p in 1:2) {\n#     for (i in 0:n) {\n#         for (j in 0:n) {\n#             print(props_to_index(n, i, j, p))\n#             print(r_props_to_index(n, i, j, p))\n#         }\n#     }\n# }\n\n\n%%time\n%%R -o s\ns &lt;- 6\nN &lt;- 1\nM &lt;- 0\nR &lt;- 1\ntli_graph &lt;- construct_twolocus_island_graph(s, N, M, R)\nprint(vertices_length(tli_graph))\n\n[1] 1044\nCPU times: user 89.9 ms, sys: 5.22 ms, total: 95.2 ms\nWall time: 93.1 ms\n\n\n\n%%R -o outgoing_edge_counts\nsi &lt;- sign(graph_as_matrix(tli_graph)$SIM)\ndiag(si) &lt;- 0\noutgoing_edge_counts &lt;- rowSums(si)\nprint(mean(outgoing_edge_counts))\n# qplot(outgoing_edge_counts, bins=100, asp=1)\n\n[1] 7.74856\n\n\n\nplt.hist(outgoing_edge_counts, bins=100) ;\n\n\n\n\n\n\n\n\n\n%%time\n%%R\nexpectation(tli_graph)\n\n[1] 2.220418\nCPU times: user 21.1 ms, sys: 6.65 ms, total: 27.8 ms\nWall time: 24 ms\n\n\nINFO: building reward compute graph...\n\n\n\n# %%time\n# %%R\n# graph_update_weights_parameterized(tli_graph, c(1, 1, 1))\n# expectation(tli_graph)\n\n\n# %%R -o graph -o states -o ipv -o sim\n\n# ###########################\n# # sample size\n# s &lt;- 2\n# ###########################\n\n# # number of populations\n# p &lt;- 2 # needs to be 2\n# # state vector length\n# n &lt;- p*(s+1)**2\n\n# graph &lt;- create_graph(n)\n# index &lt;- 1\n# # first_vertex &lt;- create_vertex(graph, c(rep(0, s+2), s, rep(0, n-s-3))) # assumes that p=2\n# state &lt;- rep(0, n)\n# state[conf_to_index(s, 1, 1, 1)] &lt;- s\n# first_vertex &lt;- create_vertex(graph, state) # assumes that p=2\n# add_edge(starting_vertex(graph), first_vertex, 1)\n\n# index &lt;- 2\n# while (index &lt;= vertices_length(graph)) {\n    \n#   vertex &lt;- vertex_at(graph, index)\n#   state &lt;- vertex$state\n  \n#   count &lt;- 0\n#   for (i in 1:n) {\n#       count &lt;- count + state[i]\n#   }\n#   if (count &lt;= 1) {\n#       # Only one lineage, stop\n#       index &lt;- index + 1\n#       next\n#   }    \n    \n#   for (i in 1:n) {\n#     conf_i &lt;- index_to_conf(s, i)\n    \n#     # coalescence #########################\n#     for (j in i:n) {\n#       conf_j &lt;- index_to_conf(s, j)\n      \n#       if (conf_i@population != conf_j@population) {\n#         # different populations\n#         next\n#       }\n#       if (i == j) {\n#         if (state[i] &lt; 2) {\n#           next;\n#         }\n#         rate &lt;- state[i] * (state[i] - 1) / 2\n#       } else {\n#         if (state[i] &lt; 1 || state[j] &lt; 1) {\n#           next;\n#         }\n#         rate &lt;- state[i] * state[j]\n#       }\n      \n#       child_state &lt;- state\n        \n#       # lineages with index i and j coalesce:  \n#       child_state[i] &lt;- child_state[i] - 1\n#       child_state[j] &lt;- child_state[j] - 1\n#       stopifnot(conf_i@locus1+conf_j@locus1 &lt;= s)\n#       stopifnot(conf_i@locus2+conf_j@locus2 &lt;= s)\n\n#       # coalescene into lineage with index k\n#       k = conf_to_index(s, conf_i@locus1+conf_j@locus1, conf_i@locus2+conf_j@locus2, conf_i@population)\n#       child_state[k] &lt;- child_state[k] + 1\n      \n#       child_vertex &lt;- find_or_create_vertex(graph, child_state)\n#       add_edge(vertex, child_vertex, rate)\n#     }\n    \n#     # recombination #######################\n#     if (state[i] &gt; 0 && conf_i@locus1 &gt; 0 && conf_i@locus2 &gt; 0) {\n      \n#       rate &lt;- 3\n#       child_state &lt;- state\n        \n#       # a lineage with index i recombines to produce lineages with index k and l\n#       k = conf_to_index(s, conf_i@locus1, 0, conf_i@population)\n#       l = conf_to_index(s, 0, conf_i@locus2, conf_i@population)\n#       child_state[i] &lt;- child_state[i] - 1\n#       child_state[k] &lt;- child_state[k] + 1\n#       child_state[l] &lt;- child_state[l] + 1\n      \n#       child_vertex &lt;- find_or_create_vertex(graph, child_state)\n#       add_edge(vertex, child_vertex, rate)\n#     }\n    \n#     # migration ###########################\n#     if (state[i] &gt; 0) {\n      \n#       rate &lt;- 0.001\n#       child_state &lt;- state\n        \n#       if (conf_i@population == 1) {\n#         m = 2\n#       } else {\n#         m = 1\n#       }\n#       # \n#       k = conf_to_index(s, conf_i@locus1, conf_i@locus2, m)\n#       child_state[i] &lt;- child_state[i] - 1\n#       child_state[k] &lt;- child_state[k] + 1\n      \n#       child_vertex &lt;- find_or_create_vertex(graph, child_state)\n#       add_edge(vertex, child_vertex, rate)\n#     }\n#   }\n  \n#   index &lt;- index + 1\n    \n#   if ((index %% 50) == 0) {\n#     cat(index, vertices_length(graph), \"\\n\")\n#   }\n    \n# }\n\n# states &lt;- t(sapply(1:vertices_length(graph), function(index) vertex_at(graph, index)$state, simplify = FALSE))\n# ipv &lt;- graph_as_matrix(graph)$IPV\n# sim &lt;- graph_as_matrix(graph)$SIM\n\n# graph_as_matrix(graph)\n\n\n%%R\nrewards &lt;- sapply(1:vertices_length(tli_graph), function(index) vertex_at(tli_graph, index)$state )\n\n\nVarying population size in epoques\n\n# %%time\n# %%R -o n1 -o n2 -o m1 -o m2 -o split_t -o im_expectation -o a_expectation\n\n# # parameters\n# n &lt;- 10\n\n# # graphs with paramerized N\n# g &lt;- kingman(n)\n\n\n# expectation &lt;- matrix(nrow=n1+1,ncol=n2+1)\n# prev_t &lt;- 0\n# epoque_start_prob &lt;- c(1,0,0,0...)\n\n# for (t in 1:5) {\n\n#     rescale_...\n#     epoque_expected_visits &lt;- accumulated_visiting_time(g, t-prev_t)\n#     for (i in 0:n1) {\n#       for (j in 0:n2) {\n#         expectation[i+1,j+1] &lt;- expectation[i+1,j+1] + sum(epoque_start_prob * epoque_expected_visits * rewards_at(im_g, i,j,n1,n2))\n#       }\n#     }\n#     epoque_start_prob &lt;- epoque_expected_visits\n#     prev_t &lt;- 1\n# }\n\n\n\n\n\nTwo-locus SFS for a two-island model\nExpected ARG branches with i and j tons from each locus\n\n%%R -o exp_mat\nexp_mat &lt;- matrix(nrow=s-1,ncol=s-1)\nfor (i in 1:s-1) {\n  for (j in 1:s-1) {\n    exp_mat[i,j] &lt;- expectation(tli_graph, rewards[props_to_index(s, i, j, 1),] + rewards[props_to_index(s, i, j, 2),])\n  }\n}\n\n\n# plt.subplots(1, 1, figsize=(7, 5))\n# ax = sns.heatmap(exp_mat, cmap=\"PiYG\", \n#                  center=0,\n#                 annot=True\n#                 )\n# ax.invert_yaxis()\n\n\nplt.subplots(1, 1, figsize=(7, 5))\nticks = list(range(1,int(s)))\nax = sns.heatmap(exp_mat, cmap=\"PiYG\", \n                 center=0,\n                yticklabels=ticks,\n                xticklabels=ticks,\n                annot=True\n                )\nax.invert_yaxis()\n\n\n\n\n\n\n\n\n\n\nMarginal SFSs for each locus\n\n%%R -o sfs_locus1 -o sfs_locus2\n\nsfs_locus1 &lt;- colSums(exp_mat)\nsfs_locus2 &lt;- rowSums(exp_mat)\n\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 4))\nsns.barplot(x=list(range(1, len(sfs_locus1)+1)), y=sfs_locus1, ax=axes[0]).set_title(\"\")\nsns.barplot(x=list(range(1, len(sfs_locus2)+1)), y=sfs_locus2, ax=axes[1]).set_title(\"\")\nsns.despine()\n\n\n\n\n\n\n\n\n\n\nCovariance of ARG branches in the two populations\nCovariance of two-locus “ton” branch length (e.g. singletons at locus 1 and doubletons at locus 2) spent in each population.\n\n%%R -o cov_mat\nfun &lt;- function(a, b) mapply(function(i, j) covariance(tli_graph, rewards[props_to_index(s, i, j, 1),], rewards[props_to_index(s, i, j, 2),]), a, b)\ncov_mat &lt;- outer(1:(s-1), 1:(s-1), fun)\n\n\nplt.subplots(1, 1, figsize=(7, 5))\nticks = list(range(1,int(s)))\nax = sns.heatmap(cov_mat, cmap=\"PiYG\", \n                 center=0,\n                yticklabels=ticks,\n                xticklabels=ticks,\n                annot=True\n                )\nax.invert_yaxis()\n\n\n\n\n\n\n\n\nShows that when there are hte same number of decendants at each locus (mostly becuase of no recombination) then the covariance is highest. Mostly for small tons where there are many lineages to back and forth between popoulations.\n\n\nCovriance between tons at each locus\n\n%%R -o cov_mat\nr_props_to_index &lt;- function(s, a, b, p) {\n    return((p-1)*(s + 1)**2 + a*(s + 1) + b + 1)\n}\n\nlocus1_rewards &lt;- function(i) {\n    colSums(rewards[r_props_to_index(s, i, 1:s, 1),]) + colSums(rewards[r_props_to_index(s, i, 1:s, 2),])\n}\nlocus2_rewards &lt;- function(j) {\n    colSums(rewards[r_props_to_index(s, 1:s, j, 1),]) + colSums(rewards[r_props_to_index(s, 1:s, j, 2),])\n}\nfun &lt;- function(a, b) mapply(function(i, j) covariance(tli_graph, locus1_rewards(i), locus2_rewards(j)), a, b)\ncov_mat &lt;- outer(1:(s-1), 1:(s-1), fun)\n\n\nplt.subplots(1, 1, figsize=(7, 5))\nticks = list(range(1,int(s)))\nax = sns.heatmap(cov_mat, cmap=\"PiYG\", \n                annot=True,\n                center=0,\n                yticklabels=ticks,\n                xticklabels=ticks\n                )\nax.invert_yaxis()\n\n\n\n\n\n\n\n\n\n%%R\ntli_graph &lt;- construct_twolocus_island_graph(s, 1, 1, 1)\nrewards &lt;- sapply(1:vertices_length(tli_graph), function(index) vertex_at(tli_graph, index)$state )\n\n\n%%R -o cov_mat\nr_props_to_index &lt;- function(s, a, b, p) {\n    return((p-1)*(s + 1)**2 + a*(s + 1) + b + 1)\n}\n\nlocus1_rewards &lt;- function(i) {\n    colSums(rewards[r_props_to_index(s, i, 1:s, 1),]) + colSums(rewards[r_props_to_index(s, i, 1:s, 2),])\n}\nlocus2_rewards &lt;- function(j) {\n    colSums(rewards[r_props_to_index(s, 1:s, j, 1),]) + colSums(rewards[r_props_to_index(s, 1:s, j, 2),])\n}\nfun &lt;- function(a, b) mapply(function(i, j) covariance(tli_graph, locus1_rewards(i), locus2_rewards(j)), a, b)\ncov_mat &lt;- outer(1:(s-1), 1:(s-1), fun)\n\nINFO: building reward compute graph...\n\n\n\nplt.subplots(1, 1, figsize=(7, 5))\nticks = list(range(1,int(s)))\nax = sns.heatmap(cov_mat, cmap=\"PiYG\", \n                annot=True,\n                center=0,\n                yticklabels=ticks,\n                xticklabels=ticks\n                )\nax.invert_yaxis()"
  },
  {
    "objectID": "examples/showcase_rpy2/showcase.html#rabbit-model",
    "href": "examples/showcase_rpy2/showcase.html#rabbit-model",
    "title": "Showcase for ptdalgorithms",
    "section": "Rabbit model",
    "text": "Rabbit model\n\n#Image(\"../images/rabbitislands.png\", width=600)\n\n\n%%R\nRcpp::sourceCpp(\"./rabbit_construction.cpp\")\n\nld: warning: -pie being ignored. It is only used when linking a main executable\n\n\n\n%%time\n%%R\ngraph &lt;- construct_rabbit_graph(1000, 4, 2)\nprint(vertices_length(graph))\nexpectation(graph)\n\n[1] 501502\n\n\nINFO: building reward compute graph...\n\n\n[1] 0.3056984\nCPU times: user 52.3 s, sys: 49.9 s, total: 1min 42s\nWall time: 2min 22s\n\n\n\n%%R -o states -o ipv -o sim\nL &lt;- 2\n  \ntim &lt;- proc.time()\nstate_vector_length &lt;- 2\ngraph &lt;- create_graph(state_vector_length)\nstarting_vertex &lt;- vertex_at(graph, 1)\ninitial_state &lt;- c(L, 0)\n\nadd_edge(\n  starting_vertex,\n  create_vertex(graph, initial_state),\n  1\n)\nindex &lt;- 2\n\nwhile (index &lt;= vertices_length(graph)) {\n  vertex &lt;- vertex_at(graph, index)\n  state &lt;- vertex$state\n  \n  if (state[1] &gt; 0) {\n    # Rabbit jump left to right\n    child_state &lt;- c(state[1] - 1, state[2] + 1)\n    add_edge(\n      vertex,\n      find_or_create_vertex(graph, child_state),\n      1\n      # 0, c(1, 0)\n    )\n    \n    # Island flooding\n    child_state &lt;- c(0, state[2])\n    add_edge(\n      vertex,\n      find_or_create_vertex(graph, child_state),\n      2\n      # 0, c(0, 1)\n\n    )\n  }\n  \n  if (state[2] &gt; 0) {\n    # Rabbit jump right to left\n    child_state &lt;- c(state[1] + 1, state[2] - 1)\n    add_edge(\n      vertex,\n      find_or_create_vertex(graph, child_state),\n      1\n      # 0, c(1, 0)\n    )\n    \n    # Island flooding\n    child_state &lt;- c(state[1], 0)\n    add_edge(\n      vertex,\n      find_or_create_vertex(graph, child_state),\n      4\n      # 0, c(0, 2)\n    )\n  }\n  \n  index &lt;- index + 1\n}\n\nstates &lt;- t(sapply(1:vertices_length(graph), function(index) vertex_at(graph, index)$state ))\nipv &lt;- graph_as_matrix(graph)$IPV\nsim &lt;- graph_as_matrix(graph)$SIM\n\nvertices_length(graph)\n\n[1] 8\n\n\n\n%%R\ngraph_update_weights_parameterized(graph, c(1, 2))\n\n\n%%R\nstates &lt;- t(sapply(1:vertices_length(graph), function(index) vertex_at(graph, index)$state ))\nipv &lt;- graph_as_matrix(graph)$IPV\nsim &lt;- graph_as_matrix(graph)$SIM\nstates\n\n     [,1] [,2]\n[1,]    0    0\n[2,]    2    0\n[3,]    1    1\n[4,]    0    0\n[5,]    0    2\n[6,]    0    1\n[7,]    2    0\n[8,]    1    0\n\n\n\nplot_graph(states, ipv, sim)\n\n\n\n\n\n\n\n\n\n%%R\nexpectation(graph)\n\n[1] 0.5038265\n\n\nINFO: building reward compute graph..."
  },
  {
    "objectID": "examples/showcase_rpy2/showcase.html#running-time-experiments",
    "href": "examples/showcase_rpy2/showcase.html#running-time-experiments",
    "title": "Showcase for ptdalgorithms",
    "section": "Running time experiments",
    "text": "Running time experiments\n\n%%R\n\ncat(\"rabbits,vertices,time_to_construct,time_build_moment_graph,time_compute_expectation,time_compute_first_10_moments\\n\")\nflush.console()\nfor (L in c(10, 50, 100, 150, 200, 250, 300, 350, 400, 450, 500)) {\n  \n  tim &lt;- proc.time()\n  state_vector_length &lt;- 2\n  graph &lt;- create_graph(state_vector_length)\n  starting_vertex &lt;- vertex_at(graph, 1)\n  initial_state &lt;- c(L, 0)\n  cat(L)\n  cat(\",\")\n  flush.console()\n  add_edge(\n    starting_vertex,\n    create_vertex(graph, initial_state),\n    1\n  )\n  index &lt;- 2\n  \n  while (index &lt;= vertices_length(graph)) {\n    vertex &lt;- vertex_at(graph, index)\n    state &lt;- vertex$state\n    \n    if (state[1] &gt; 0) {\n      # Rabbit jump left to right\n      child_state &lt;- c(state[1] - 1, state[2] + 1)\n      add_edge(\n        vertex,\n        find_or_create_vertex(graph, child_state),\n        1\n      )\n      \n      # Island flooding\n      child_state &lt;- c(0, state[2])\n      add_edge(\n        vertex,\n        find_or_create_vertex(graph, child_state),\n        1\n      )\n    }\n    \n    if (state[2] &gt; 0) {\n      # Rabbit jump right to left\n      child_state &lt;- c(state[1] + 1, state[2] - 1)\n      add_edge(\n        vertex,\n        find_or_create_vertex(graph, child_state),\n        1\n      )\n      \n      # Island flooding\n      child_state &lt;- c(state[1], 0)\n      add_edge(\n        vertex,\n        find_or_create_vertex(graph, child_state),\n        1\n      )\n    }\n    \n    index &lt;- index + 1\n  }\n  \n  cat(vertices_length(graph))\n  cat(\",\")\n  now &lt;- proc.time()\n  cat((now - tim)[3])\n  cat(\",\")\n  flush.console()\n  tim &lt;- proc.time()\n  expected_waiting_time(graph)\n  now &lt;- proc.time()\n  cat((now - tim)[3])\n  cat(\",\")\n  flush.console()\n  \n  \n  tim &lt;- proc.time()\n  expected_waiting_time(graph)\n  now &lt;- proc.time()\n  cat((now - tim)[3])\n  cat(\",\")\n  flush.console()\n  \n  tim &lt;- proc.time()\n  \n  rw &lt;-  rep(1, vertices_length(graph))\n  \n  for (i in 1:10) {\n    rw &lt;- expected_waiting_time(graph, rw)\n  }\n  now &lt;- proc.time()\n  cat((now - tim)[3])\n  cat(\"\\n\")\n  flush.console()\n}\n\n\n\ncat(\"rabbits,vertices,time_convert_matrix,time_inverse_matrix\\n\")\nflush.console()\nfor (L in c(10, 50, 100, 150, 200, 250, 300, 350, 400, 450, 500)) {\n  \n  tim &lt;- proc.time()\n  state_vector_length &lt;- 2\n  graph &lt;- create_graph(state_vector_length)\n  starting_vertex &lt;- vertex_at(graph, 1)\n  initial_state &lt;- c(L, 0)\n  cat(L)\n  cat(\",\")\n  flush.console()\n  add_edge(\n    starting_vertex,\n    create_vertex(graph, initial_state),\n    1\n  )\n  index &lt;- 2\n  \n  while (index &lt;= vertices_length(graph)) {\n    vertex &lt;- vertex_at(graph, index)\n    state &lt;- vertex$state\n    \n    if (state[1] &gt; 0) {\n      # Rabbit jump left to right\n      child_state &lt;- c(state[1] - 1, state[2] + 1)\n      add_edge(\n        vertex,\n        find_or_create_vertex(graph, child_state),\n        1\n      )\n      \n      # Island flooding\n      child_state &lt;- c(0, state[2])\n      add_edge(\n        vertex,\n        find_or_create_vertex(graph, child_state),\n        1\n      )\n    }\n    \n    if (state[2] &gt; 0) {\n      # Rabbit jump right to left\n      child_state &lt;- c(state[1] + 1, state[2] - 1)\n      add_edge(\n        vertex,\n        find_or_create_vertex(graph, child_state),\n        1\n      )\n      \n      # Island flooding\n      child_state &lt;- c(state[1], 0)\n      add_edge(\n        vertex,\n        find_or_create_vertex(graph, child_state),\n        1\n      )\n    }\n    \n    index &lt;- index + 1\n  }\n  \n  cat(vertices_length(graph))\n  cat(\",\")\n  flush.console()\n  tim &lt;- proc.time()\n  M &lt;- graph_as_matrix(graph)\n  now &lt;- proc.time()\n  cat((now - tim)[3])\n  cat(\",\")\n  flush.console()\n  \n  \n  tim &lt;- proc.time()\n  solve(M$SIM)\n  now &lt;- proc.time()\n  cat((now - tim)[3])\n  cat(\"\\n\")\n  flush.console()\n}\n\nrabbits,vertices,time_to_construct,time_build_moment_graph,time_compute_expectation,time_compute_first_10_moments\n10,68,0.022,0.002,0,0.001\n50,1328,0.114,0.015,0,0.002\n100,\n\n\nINFO: building reward compute graph...\nINFO: building reward compute graph...\n\n\n5153,1.567,0.043,0.001,0.014\n150,\n\n\nINFO: building reward compute graph...\n\n\n11478,0.626,0.11,0.004,0.046\n200,\n\n\nINFO: building reward compute graph...\n\n\n20303,1.129,\n\n\nINFO: building reward compute graph...\n\n\n0.281,0.01,0.096\n250,31628,2.184,\n\n\nINFO: building reward compute graph...\n\n\n0.532,0.022,0.197\n300,45453,3.139,\n\n\nINFO: building reward compute graph...\n\n\n0.869,0.035,0.314\n350,61778,4.381,\n\n\nINFO: building reward compute graph...\n\n\n1.714,0.058,0.656\n400,80603,7.666,\n\n\nINFO: building reward compute graph...\n\n\n3.927,0.148,1.349\n450,101928,11.044,\n\n\nINFO: building reward compute graph...\n\n\n5.916,0.199,1.846\n500,125753,14.196,\n\n\nINFO: building reward compute graph...\n\n\n8.116,0.251,2.542\nrabbits,vertices,time_convert_matrix,time_inverse_matrix\n10,68,0,0.006\n50,1328,0.019,0.159\n100,5153,1.073,6.517\n150,11478,4.46,58.847\n200,20303,19.5,1361.119\n250,31628,51.197,978.453\n300,45453,110.844,"
  },
  {
    "objectID": "examples/R/full_r_api_example.html",
    "href": "examples/R/full_r_api_example.html",
    "title": "Full R API example of ptdalgorithms",
    "section": "",
    "text": "This notebook will describe almost all functions of the ptdalgorithms R package. The core functionality is implemented in C, with a binding layer to R through C++ and Rcpp. Except for the specified construction code of the state space, most code will be almost equally fast to invoking the C api directly (maybe twice as slow). The package is based on graph algorithms published in (…), and is many orders of magnitude faster than matrix-based equations which are usually applied. We do not recommend using the C++ api directly.\nWe will show how to install the package and construct a state space through the R api. We will then show how to compute the moments (expectation, variance) through the ptdalgorithms package, and how to compute the distribution functions. This means that you can make discrete and continuous phase-type distributions, compute their moments, distribution functions, sample from them, compute rewards and multivariate distributions, and time inhomogenous distributions.\nWe will also show how easy it is to create the state-space in C and return it to R, to make large graphs!"
  },
  {
    "objectID": "examples/R/full_r_api_example.html#installing-the-ptdalgorithms-library",
    "href": "examples/R/full_r_api_example.html#installing-the-ptdalgorithms-library",
    "title": "Full R API example of ptdalgorithms",
    "section": "Installing the ptdalgorithms library",
    "text": "Installing the ptdalgorithms library\n\n# We install the package through devtools::install_github\n# This requires the \"devtools\" package to be installed\ninstall.packages(\"devtools\",  INSTALL_opts = c('--no-lock'))\nlibrary(devtools)\ndevtools::install_github(\"TobiasRoikjer/PtDAlgorithms\")\n\nWarning message:\n“unable to access index for repository https://cran.r-project.org/src/contrib:\n  cannot open URL 'https://cran.r-project.org/src/contrib/PACKAGES'”\nWarning message:\n“package ‘devtools’ is not available for this version of R\n\nA version of this package for your version of R might be available elsewhere,\nsee the ideas at\nhttps://cran.r-project.org/doc/manuals/r-patched/R-admin.html#Installing-packages”\nLoading required package: usethis\n\n\n\nERROR: Error: Failed to install 'unknown package' from GitHub:\n  Couldn't connect to server\n\nError: Failed to install 'unknown package' from GitHub:\n  Couldn't connect to server\nTraceback:\n\n1. devtools::install_github(\"TobiasRoikjer/PtDAlgorithms\")\n2. pkgbuild::with_build_tools({\n .     ellipsis::check_dots_used(action = getOption(\"devtools.ellipsis_action\", \n .         rlang::warn))\n .     {\n .         remotes &lt;- lapply(repo, github_remote, ref = ref, subdir = subdir, \n .             auth_token = auth_token, host = host)\n .         install_remotes(remotes, auth_token = auth_token, host = host, \n .             dependencies = dependencies, upgrade = upgrade, force = force, \n .             quiet = quiet, build = build, build_opts = build_opts, \n .             build_manual = build_manual, build_vignettes = build_vignettes, \n .             repos = repos, type = type, ...)\n .     }\n . }, required = FALSE)\n3. install_remotes(remotes, auth_token = auth_token, host = host, \n .     dependencies = dependencies, upgrade = upgrade, force = force, \n .     quiet = quiet, build = build, build_opts = build_opts, build_manual = build_manual, \n .     build_vignettes = build_vignettes, repos = repos, type = type, \n .     ...)\n4. tryCatch(res[[i]] &lt;- install_remote(remotes[[i]], ...), error = function(e) {\n .     stop(remote_install_error(remotes[[i]], e))\n . })\n5. tryCatchList(expr, classes, parentenv, handlers)\n6. tryCatchOne(expr, names, parentenv, handlers[[1L]])\n7. value[[3L]](cond)\n\n\n\n# Import the functions in the library\nlibrary(ptdalgorithms)\n\n# The library supports setting seeds for some of its\n# sampling capability, as any other R package\nset.seed(1234)"
  },
  {
    "objectID": "examples/R/full_r_api_example.html#example-of-rabbit-graph",
    "href": "examples/R/full_r_api_example.html#example-of-rabbit-graph",
    "title": "Full R API example of ptdalgorithms",
    "section": "Example of rabbit graph",
    "text": "Example of rabbit graph\n\n\n\nExample of rabbit graph"
  },
  {
    "objectID": "examples/R/full_r_api_example.html#continuous-phase-type-distribution",
    "href": "examples/R/full_r_api_example.html#continuous-phase-type-distribution",
    "title": "Full R API example of ptdalgorithms",
    "section": "Continuous phase-type distribution",
    "text": "Continuous phase-type distribution\n\n# We can now construct the graphs by the function.\n# The flooding rates are set to 2 and 4\ngraph &lt;- construct_rabbit_graph(2, flooding_rate_l=2, flooding_rate_r=4)\n\ncat(paste(\"The graph has\", vertices_length(graph), \"vertices\\n\"))\ncat(\"The states are:\\n\")\nM &lt;- states(graph)\ncolnames(M) &lt;- c(\"Rabbits left\", \"Rabbits right\")\nprint(M)\n\n# This phase-type distribution models the time until all rabits have died\n# We can find the expectation, variance, moments\ncat(paste(\n    \"\\nExpectation:\", round(expectation(graph),5),\n    \"\\nVariance: \", round(variance(graph),5),\n    \"\\nFirst three moments:\", paste(round(moments(graph,3),5), collapse=\" \"), \"\\n\"))\n\n# We can find the expected waiting time for all start vertices\ncat(paste0(\"Expected waiting time if starting in any vertex:\\n\\t\", paste(round(expected_waiting_time(graph),5), collapse=\"\\n\\t\"), \"\\n\"))\n\n# We can convert this to a matrix-based representation.\n# This is only for easy \"compatibility\" and is rarely useful\ncat(\"We can convert this to a sub-intensity matrix representation if we want.\\n\")\ncat(\"Notice how the indices do *not* correspond to our graph indices\\n\")\nprint(graph_as_matrix(graph))\n\nThe graph has 7 vertices\nThe states are:\n     Rabbits left Rabbits right\n[1,]            0             0\n[2,]            2             0\n[3,]            1             1\n[4,]            0             0\n[5,]            0             2\n[6,]            0             1\n[7,]            1             0\n\nExpectation: 0.50383 \nVariance:  0.22646 \nFirst three moments: 0.50383 0.4803 0.65591 \nExpected waiting time if starting in any vertex:\n    0.50383\n    0.50383\n    0.51148\n    0\n    0.3023\n    0.28571\n    0.42857\nWe can convert this to a sub-intensity matrix representation if we want.\nNotice how the indices do *not* correspond to our graph indices\n$states\n     [,1] [,2]\n[1,]    0    2\n[2,]    1    1\n[3,]    2    0\n[4,]    1    0\n[5,]    0    1\n\n$SIM\n     [,1] [,2] [,3] [,4] [,5]\n[1,]   -5    1    0    0    0\n[2,]    1   -8    1    4    2\n[3,]    0    1   -3    0    0\n[4,]    0    0    0   -3    1\n[5,]    0    0    0    1   -5\n\n$IPV\n[1] 0 0 1 0 0\n\n\n\n\n# We can find the distribution function for the graph. We show here the PDF and CDF\n# The functions are smart, and the results are *not* recomputed unless\n# the graph changes. \ntime &lt;- seq(0,2,by=0.01)\npdf &lt;- dph(time, graph)\ncdf &lt;- pph(time, graph)\ncat(\"PDF and CDF of distribution. Observe the long tails!\\n\")\noptions(repr.plot.width=10, repr.plot.height=4)\npar(mfrow=c(1,2)) \nplot(time, pdf)\ntitle(\"Probability density function\")\nplot(time, cdf)\ntitle(\"Cumulative density function\")\n\nPDF and CDF of distribution. Observe the long tails!"
  },
  {
    "objectID": "examples/R/full_r_api_example.html#rewards",
    "href": "examples/R/full_r_api_example.html#rewards",
    "title": "Full R API example of ptdalgorithms",
    "section": "Rewards",
    "text": "Rewards\n\n# We can add rewards which are based on the number of rabbits on the second island.\n# The phase-type distribution is now the total accumulated time that any rabbits spends on the\n# right island prior to them all being flooded\nrewards &lt;- states(graph)[,2]\n# Alternative: rewards &lt;- sapply(1:vertices_length(graph), function(i){vertex_at(graph, i)$state[2]})\n\n# Using rewards to the moment functions etc. is much faster than actually\n# changing the graph\ncat(paste(\n    \"\\nExpectation:\", round(expectation(graph, rewards),5),\n    \"\\nVariance: \", round(variance(graph, rewards),5),\n    \"\\nFirst three moments:\", paste(round(moments(graph,3, rewards),5), collapse=\" \"), \"\\n\"))\n\n\nExpectation: 0.09439 \nVariance:  0.04635 \nFirst three moments: 0.09439 0.05526 0.05233 \n\n\n\n# Using rewards to the moment functions etc. is much faster than actually\n# changing the graph, but sometimes we might want to be interested in reward transforming\n# the phase-type distribution, giving us the full distribution of accumulated rewards.\n# For example if we want the pdf/cdf\nright_graph &lt;- reward_transform(graph, states(graph)[,2])\ncat(paste(\n    \"\\nExpectation:\", round(expectation(right_graph),5),\n    \"\\nVariance: \", round(variance(right_graph),5),\n    \"\\nFirst three moments:\", paste(round(moments(right_graph,3),5), collapse=\" \"),\n    \"\\nDefect: \", round(defect(right_graph),5), \"\\n\"))\n\n# We can find the distribution function for the the total accumulate\n# time spent by any rabbit on an island. We show here the PDF and CDF\naccumulated_rewards &lt;- seq(0,2,by=0.01)\npdf &lt;- dph(accumulated_rewards, right_graph)\ncdf &lt;- pph(accumulated_rewards, right_graph)\ncat(\"PDF and CDF of distribution. Notice how we have a *defect*\\ni.e. a probability of obtaining *no* rewards\\n\")\ncat(\"The *defect* is plotted as a cross in the PDF. Remember to always consider this defect!\\n\")\noptions(repr.plot.width=10, repr.plot.height=4)\npar(mfrow=c(1,2)) \nplot(accumulated_rewards, pdf)\npoints(0,defect(right_graph),pch=4)\ntitle(\"Probability density function\")\nplot(accumulated_rewards, cdf,ylim=c(0,1))\ntitle(\"Cumulative density function\")\n\n\nExpectation: 0.09439 \nVariance:  0.04635 \nFirst three moments: 0.09439 0.05526 0.05233 \nDefect:  0.66667 \nPDF and CDF of distribution. Notice how we have a *defect*\ni.e. a probability of obtaining *no* rewards\nThe *defect* is plotted as a cross in the PDF. Remember to always consider this defect!\n\n\n\n\n\n\n\n\n\n\n# There are also utility methods to get the stop probability\n# i.e. at a certain time, what is the probability of standing\n# in each vertex. We can also get the accumulated visiting time\ncat(\"The stopping probability at times 0, 0.2, 0.4, ..., 1.0:\")\nt(data.frame(stop=sapply(seq(0,1,by=0.2),\n                   function (i) {stop_probability(graph, i)})))\n\n# Can can use this to e.g. find the expected number of rabbits left at a time\ntimes &lt;- seq(0,2,by=0.05)\nexpected_rabbits_left &lt;- sapply(times, function (i) {sum(stop_probability(graph, i)*rowSums(states(graph)))})\n\noptions(repr.plot.width=10, repr.plot.height=4)\npar(mfrow=c(1,2)) \nplot(times, expected_rabbits_left)\ntitle(\"Expected number of rabbits at certain times\")\n\n# We can e.g. find the accumulated time where there was at least one rabbit on the right island\nrewards &lt;- as.integer(states(graph)[,2]&gt;0)\ncat(paste(\"Total time where there was a rabbit on the right island, before time t=0.5:\\n\\t\",\n          sum(accumulated_visiting_time(graph, time=0.5) * rewards),\"\\n\"))\n\nThe stopping probability at times 0, 0.2, 0.4, ..., 1.0:\n\n\n\nA matrix: 6 × 7 of type dbl\n\n\nstop.1\n0\n1.00000000\n0.00000000\n0\n0.000000000\n0.00000000\n0.00000000\n\n\nstop.2\n0\n0.55615316\n0.07040542\n0\n0.007095726\n0.01634811\n0.03374891\n\n\nstop.3\n0\n0.31431361\n0.05442623\n0\n0.010549137\n0.02839463\n0.06027159\n\n\nstop.4\n0\n0.17871327\n0.03421840\n0\n0.009222178\n0.02916357\n0.06334177\n\n\nstop.5\n0\n0.10186655\n0.02032847\n0\n0.006629385\n0.02462984\n0.05448747\n\n\nstop.6\n0\n0.05829086\n0.01187000\n0\n0.004346414\n0.01888474\n0.04238625\n\n\n\n\n\nTotal time where there was a rabbit on the right island, before time t=0.5:\n     0.0405323179604757"
  },
  {
    "objectID": "examples/R/full_r_api_example.html#discrete-phase-type-distributions",
    "href": "examples/R/full_r_api_example.html#discrete-phase-type-distributions",
    "title": "Full R API example of ptdalgorithms",
    "section": "Discrete phase-type distributions",
    "text": "Discrete phase-type distributions\n\n# We can also work with discrete phase-type distributions. This is\n# the number of jumps in a Markov Chain before absorption\n# We will model that any rabbit can find a carrot at each time with rate 0.1\n# and see how many carrots the rabbits will have found\n# We could of course just make a new state-space creation function, but we can\n# also manipulate existing\ncarrot_graph &lt;- clone_graph(graph)\n\nvlength &lt;- vertices_length(carrot_graph)\ncarrot_vertices &lt;- rep(F, vlength*2)\n\nfor (i in 1:vlength) {\n    vertex &lt;- vertex_at(carrot_graph,i)\n    rabbits &lt;- sum(vertex$state)\n    \n    if (rabbits &gt; 0) {\n        obtained_carrot_vertex &lt;- create_vertex(carrot_graph, 0)\n        # Go directly back to the state we came from\n        add_edge(obtained_carrot_vertex, vertex, 1)\n        # Rate of finding carrot\n        add_edge(vertex, obtained_carrot_vertex, rabbits * 0.1)\n        carrot_vertices[obtained_carrot_vertex$index] &lt;- T\n    }    \n}\n\ncarrot_vertices &lt;- carrot_vertices[1:vertices_length(carrot_graph)]\n\n# We now want to make the graph discrete. We do this by 'normalizing' the edges\n# This is imply scaling the vertices such that the total out-going rate is 1\n# As it is now the probability of transitions\nweights_were_multiplied_with &lt;- normalize_graph(carrot_graph)\n\ncat(\"This is the discrete state space as a sub-transition matrix:\")\ngraph_as_dph_matrix(carrot_graph)$STM\n\nThis is the discrete state space as a sub-transition matrix:\n\n\n\nA matrix: 10 × 10 of type dbl\n\n\n0.0000\n0.00000000\n0.00000000\n0.000000e+00\n0.0000000\n1.0000000\n0.00000000\n0.00000000\n0.0000000\n0.0000000\n\n\n0.0000\n0.00000000\n0.00000000\n0.000000e+00\n1.0000000\n0.0000000\n0.00000000\n0.00000000\n0.0000000\n0.0000000\n\n\n0.0000\n0.00000000\n0.00000000\n1.000000e+00\n0.0000000\n0.0000000\n0.00000000\n0.00000000\n0.0000000\n0.0000000\n\n\n0.0000\n0.00000000\n0.03846154\n1.110223e-16\n0.1923077\n0.0000000\n0.00000000\n0.00000000\n0.0000000\n0.0000000\n\n\n0.0000\n0.02439024\n0.00000000\n1.219512e-01\n0.0000000\n0.1219512\n0.00000000\n0.00000000\n0.4878049\n0.2439024\n\n\n0.0625\n0.00000000\n0.00000000\n0.000000e+00\n0.3125000\n0.0000000\n0.00000000\n0.00000000\n0.0000000\n0.0000000\n\n\n0.0000\n0.00000000\n0.00000000\n0.000000e+00\n0.0000000\n0.0000000\n0.00000000\n0.00000000\n0.0000000\n1.0000000\n\n\n0.0000\n0.00000000\n0.00000000\n0.000000e+00\n0.0000000\n0.0000000\n0.00000000\n0.00000000\n1.0000000\n0.0000000\n\n\n0.0000\n0.00000000\n0.00000000\n0.000000e+00\n0.0000000\n0.0000000\n0.00000000\n0.03225806\n0.0000000\n0.3225806\n\n\n0.0000\n0.00000000\n0.00000000\n0.000000e+00\n0.0000000\n0.0000000\n0.01960784\n0.00000000\n0.1960784\n0.0000000\n\n\n\n\n\n\n# We now want to find the expected number of eaten carrots\n# We set the reward such that the carrot vertex has a reward of '1'\nrewards &lt;- as.integer(carrot_vertices)\n\ncat(paste(\"DPH expectation:\", dph_expectation(carrot_graph, rewards)))\n\n# We can verify that the number of carrots correspond to scaling the continuous graph\ncat(paste(\"\\nScaled continuous expectation:\", expectation(graph, rowSums(states(graph))) * 0.1))\n\n# Of course we cannot do this for other moments!\ncat(paste(\"\\nDPH variance: \", dph_variance(carrot_graph, rewards)))\nsamples &lt;- rdph(1000000, carrot_graph, rewards)\n\ncat(paste(\"\\nVerified by sampling: \", sum(samples^2)/1000000-((sum(samples))/1000000)^2))\n\nDPH expectation: 0.0905612244897959\nScaled continuous expectation: 0.0905612244897959\nDPH variance:  0.0972314270095794\nVerified by sampling:  0.097206853744\n\n\n\n# We can find the distribution function for the the total number of carrots found\ncarrots &lt;- seq(0, 10)\n# Notice that with this reward transformation the graph is no longer sparse, as all paths through\n# the graph are represented!!\nfound_carrots_graph &lt;- dph_reward_transform(carrot_graph, rewards)\npmf &lt;- ddph(carrots, found_carrots_graph)\ncdf &lt;- pdph(carrots, found_carrots_graph)\noptions(repr.plot.width=10, repr.plot.height=4)\npar(mfrow=c(1,2)) \nplot(carrots, pmf)\ntitle(\"Probability mass function\")\nplot(carrots, cdf,ylim=c(0,1))\ntitle(\"Cumulative density function\")"
  },
  {
    "objectID": "examples/R/full_r_api_example.html#parameterized-edges",
    "href": "examples/R/full_r_api_example.html#parameterized-edges",
    "title": "Full R API example of ptdalgorithms",
    "section": "Parameterized edges",
    "text": "Parameterized edges\n\n# We can *parameterize* the edges to easily update the weights of the edge\n# We do this by assigning a *state* to the *edge*.\n# We will now also say that the rate of rabbits jumping is proportional to the\n# number of rabbits on the island.\n# Our state is [rabbits able to jump, left flooding, right flooding]\n\nconstruct_rabbit_graph_params &lt;- function(number_of_rabbits) {\n    # We represent the vector as two integers, the number of rabbits on the left and right island\n    state_vector_length &lt;- 2\n    graph &lt;- create_graph(state_vector_length)\n    initial_state &lt;- c(number_of_rabbits, 0)\n    # The initial state is the only starting state, with 100% starting probability\n    add_edge(\n      starting_vertex(graph),\n      find_or_create_vertex(graph, initial_state),\n      1\n    )\n    index &lt;- 2\n    # Iterate over all unvisited vertices\n    while (index &lt;= vertices_length(graph)) {\n      vertex &lt;- vertex_at(graph, index)\n      state &lt;- vertex$state\n      if (state[1] &gt; 0) {\n        # Rabbit jump left to right\n        child_state &lt;- c(state[1] - 1, state[2] + 1)\n        add_edge(\n          vertex,\n          find_or_create_vertex(graph, child_state),\n          0,\n          parameterized_edge_state=c(state[1],0,0)\n        )\n        # Left island flooding\n        child_state &lt;- c(0, state[2])\n        add_edge(\n          vertex,\n          find_or_create_vertex(graph, child_state),\n          0,\n          parameterized_edge_state=c(0,1,0)\n        )\n      }\n      if (state[2] &gt; 0) {\n        # Rabbit jump right to left\n        child_state &lt;- c(state[1] + 1, state[2] - 1)\n        add_edge(\n          vertex,\n          find_or_create_vertex(graph, child_state),\n          0, \n          parameterized_edge_state=c(state[2],0,0)\n        )\n        # Right island flooding with rate of 4\n        child_state &lt;- c(state[1], 0)\n        add_edge(\n          vertex,\n          find_or_create_vertex(graph, child_state),\n          0,\n          parameterized_edge_state=c(0,0,1)\n        )\n      }\n      index &lt;- index + 1\n    }\n    return(graph)\n}\n\n\n# The parameterized edges have what ever weight is assigned to them,\n# and the state does not by itself mean anything.\nparam_graph &lt;- construct_rabbit_graph_params(2)\n\n# If we let the edge have a state, this gives us an easy way of changing the weights\n# based on some model parameters. In this case, it is the rate of jumping\n# left rate of flooding and right rate of flooding.\n# The update simply takes the inner product of the state vector and\n# the model parameters, e.g. if the state is x1, x2 and the parameters are p1, p2, then\n# the weight of the edge becomed x1*p1+x2*p2\ngraph_update_weights_parameterized(param_graph, c(1, 2, 4))\ncat(paste(\"Expectation (1,2,4):\", expectation(param_graph)))\ngraph_update_weights_parameterized(param_graph, c(2, 2, 4))\ncat(paste(\"\\nExpectation (2,2,4):\", expectation(param_graph)))\ngraph_update_weights_parameterized(param_graph, c(2, 4, 4))\ncat(paste(\"\\nExpectation (2,4,4):\", expectation(param_graph)))\ngraph_update_weights_parameterized(param_graph, c(2, 4, 18))\ncat(paste(\"\\nExpectation (2,4,18):\", expectation(param_graph)))\ngraph_update_weights_parameterized(param_graph, c(8, 4, 18))\ncat(paste(\"\\nExpectation (8,4,18):\", expectation(param_graph)))\n\n# Note that the moment graph *has* to be recalculated after updating weights\n\ncat(\"\\n\\nSIM at 1,2,4:\\n\")\ngraph_update_weights_parameterized(param_graph, c(1, 2, 4))\nprint(graph_as_matrix(param_graph)$SIM)\ncat(\"\\n\\nSIM at 8,4,18:\\n\")\ngraph_update_weights_parameterized(param_graph, c(8, 4, 18))\nprint(graph_as_matrix(param_graph)$SIM)\n\nExpectation (1,2,4): 0.508305647840532\nExpectation (2,2,4): 0.495652173913043\nExpectation (2,4,4): 0.3\nExpectation (2,4,18): 0.227096322687365\nExpectation (8,4,18): 0.177194393695634\n\nSIM at 1,2,4:\n     [,1] [,2] [,3] [,4] [,5]\n[1,]   -6    2    0    0    0\n[2,]    1   -8    1    4    2\n[3,]    0    2   -4    0    0\n[4,]    0    0    0   -3    1\n[5,]    0    0    0    1   -5\n\n\nSIM at 8,4,18:\n     [,1] [,2] [,3] [,4] [,5]\n[1,]  -34   16    0    0    0\n[2,]    8  -38    8   18    4\n[3,]    0   16  -20    0    0\n[4,]    0    0    0  -12    8\n[5,]    0    0    0    8  -26"
  },
  {
    "objectID": "examples/R/full_r_api_example.html#time-inhomogeneity",
    "href": "examples/R/full_r_api_example.html#time-inhomogeneity",
    "title": "Full R API example of ptdalgorithms",
    "section": "Time inhomogeneity",
    "text": "Time inhomogeneity\n\n# If the weights change over time - or new edges are added!\n# Then the distribution is time inhomogeneous. The api also\n# supports such distributions, but in limited manner.\n\n# Like the pph, dph, etc. functions, it is a (very good) approximation based\n# on very small steps. If the rates change dramatically, set the granularity\n# as an argument to the functions!! E.g. set it to a high enough value.\n\n# If we pick a time far into the future, we can integrate under the pdf to find the expectation!\ncat(paste(\"Integrating over accumulated visiting time:\",sum(accumulated_visiting_time(graph, 10))))\ncat(paste(\"\\nThe first moment (expectation):\", expectation(graph)))\n\n# Say at a certain point in time, the flooding starts!\n# In the beginning, there is *no* flooding\ngraph_update_weights_parameterized(param_graph, c(1, 0, 0))\n\n# We can build a context to step over the distribution.\n# Weights can be freely changed and edges added in such a context\nctx = distribution_context(param_graph)\ncdfs &lt;- c()\ntimes &lt;- c()\n\nwhile (distribution_context_state(ctx)$time &lt; 1.5) {\n    cdfs &lt;- c(cdfs, distribution_context_state(ctx)$cdf)\n    times &lt;- c(times, distribution_context_state(ctx)$time)\n    distribution_context_step(ctx)\n}\n\n# At time 1.5, the flooding starts! It increases by every time step!\ngraph_update_weights_parameterized(param_graph, c(1, 0, 0))\n\nwhile (distribution_context_state(ctx)$cdf &lt; 0.999) {\n    cdfs &lt;- c(cdfs, distribution_context_state(ctx)$cdf)\n    times &lt;- c(times, distribution_context_state(ctx)$time)\n    graph_update_weights_parameterized(\n        param_graph, c(1,\n                       (distribution_context_state(ctx)$time - 1.5), \n                       2*(distribution_context_state(ctx)$time - 1.5)\n                      )\n    )\n    distribution_context_step(ctx)\n}\n\nplot(times, cdfs)\ntitle(\"Time until all rabbits are dead. Flooding increases linearly after 1.5 time units\")\n\nIntegrating over accumulated visiting time: 0.503826530601454\nThe first moment (expectation): 0.503826530612245\n\n\n\n\n\n\n\n\n\n\n# If we pick a time far into the future, we can integrate under it to find the expectation!\n# This means that we can scale by a reward, and thereby find the marginal expectation\ncat(paste(\"Summing over accumulated visiting time (with reward):\",\n            sum(accumulated_visiting_time(graph, 10)*states(graph)[,2])))\ncat(paste(\"\\nThe first moment (expectation) (with reward):\", expectation(graph,states(graph)[,2])))\n\n# But if the time is *not* far into the future, we get the expectation up to a certain\n# point in time!\n\ncat(paste(\"\\nExpectation (rewarded) when truncating at 0.05 time:\",\n            sum(accumulated_visiting_time(graph, 0.05)*states(graph)[,2])))\ncat(paste(\"\\nUntruncated expectation:\", expectation(graph,states(graph)[,2])))\n\ncat(paste(\"\\nExpectation (rewarded) when *starting* at 0.05 time:\",\n            sum(stop_probability(graph, 0.05)*expected_waiting_time(graph, states(graph)[,2]))))\n\ncat(paste(\"\\nSubtracting these gives the *same* value:\",\n            expectation(graph,states(graph)[,2])-\n           sum(stop_probability(graph, 0.05)*expected_waiting_time(graph, states(graph)[,2]))))\n\ncat(paste(\"\\nWe can increase granularity for better performance:\",\n           sum(accumulated_visiting_time(graph, 0.05, granularity=1000000)*states(graph)[,2])))\n# However, if there are sudden, single, large changes,\n# we can also just get the chunked expectation by subtracting\n\nSumming over accumulated visiting time (with reward): 0.0943877550988707\nThe first moment (expectation) (with reward): 0.0943877551020408\nExpectation (rewarded) when truncating at 0.05 time: 0.00117132349857445\nUntruncated expectation: 0.0943877551020408\nExpectation (rewarded) when *starting* at 0.05 time: 0.0932581146642645\nSubtracting these gives the *same* value: 0.00112964043777626\nWe can increase granularity for better performance: 0.00111383178979534"
  },
  {
    "objectID": "examples/R/full_r_api_example.html#fast-state-space-construction-through-c-api",
    "href": "examples/R/full_r_api_example.html#fast-state-space-construction-through-c-api",
    "title": "Full R API example of ptdalgorithms",
    "section": "Fast state-space construction through C api",
    "text": "Fast state-space construction through C api\n\n# While the R api can create graphs, this is *slow* as the C++ binding layer\n# through Rcpp is slow when invoking many functions, and since R is a slow,\n# interpreted language\n# Clone or download the code, and include these files in the repository!\n# Make SURE that the version of the downloaded code is the same as the\n# installed R library!! Otherwise it may crash randomly\n# The file has comments and is easy to understand, so you should be able\n# to defined you own cool construction functions\n\nRcpp::sourceCpp(\"./rabbit_construction_c.cpp\")\n\n\n# The included file (open it for youself and see!) defined a function construct_rabbit_graph\ngraph &lt;- construct_rabbit_graph(2, 2, 4)\n\ncat(\"See how the graph is identical to the R construction?\\n\")\ngraph_as_matrix(graph)$SIM\n\n# We can very fast build large state spaces!!\nlarge &lt;- construct_rabbit_graph(500, 2, 4)\ncat(paste(\"Vertices:\", vertices_length(large)))\n\n# Don't worry about speed when invoking the other api functions\n# they are not slower as we invoke one C function once and wait\n# for it to return!\ncat(paste(\"\\nExpectation:\", expectation(large)))\n\nSee how the graph is identical to the R construction?\n\n\n\nA matrix: 5 × 5 of type dbl\n\n\n-5\n1\n0\n0\n0\n\n\n1\n-8\n1\n4\n2\n\n\n0\n1\n-3\n0\n0\n\n\n0\n0\n0\n-3\n1\n\n\n0\n0\n0\n1\n-5\n\n\n\n\n\nVertices: 125752\nExpectation: 0.536563856879033"
  },
  {
    "objectID": "examples/R/full_r_api_example.html#numerical-accuracy",
    "href": "examples/R/full_r_api_example.html#numerical-accuracy",
    "title": "Full R API example of ptdalgorithms",
    "section": "Numerical accuracy",
    "text": "Numerical accuracy\n\n# To prove that the algorithms are numerically accuracy, we will compare against\n# a baseline by matrix equations.\n# We build an 100% dense graph, and compare the results\nset.seed(1234)\nVERTICES &lt;- 1000\n\ng &lt;- create_graph(0)\nvertices &lt;- list()\nfor (i in 1:VERTICES) {\n    vertices[[i]] &lt;- create_vertex(g, 0)\n}\n\nadd_edge(starting_vertex(g), vertices[[1]], 1)\nfor (i in 1:(VERTICES-1)) {\n    for (j in 1:VERTICES) {\n        if (i==j) {\n            next();\n        }\n        \n        weight &lt;- runif(1)\n        add_edge(vertices[[i]],vertices[[j]], weight)\n        }\n    }\n\n# Matrix equations for 3rd moment\nGAM &lt;- graph_as_matrix(g)\nU &lt;- -solve(GAM$SIM)\nS &lt;- GAM$SIM\ns &lt;- -rowSums(S)\nalpha &lt;- GAM$IPV\ne &lt;- rep(1, length(GAM$IPV))\n\ndf &lt;- data.frame()\nMAT &lt;- U\nfor (k in 1:10) {\n    v &lt;- factorial(k)*alpha %*% MAT %*% e \n    #integrating_under_curve &lt;- sum(\n     #   dph(seq(0,100,by=0.01), g)*(seq(0,100,by=0.01)^k)\n     #   /10000)\n    df &lt;- rbind(df, list(moment=k, matrix_based=round(v,10),\n                         ptdalgorithms_moment=round(moments(g, k)[k],10)\n                #ptdalgorithms_integrating_under_curve=integrating_under_curve\n               ))\n    MAT &lt;- U %*% MAT\n}\ndf\n\n\nA data.frame: 10 × 3\n\n\nmoment\nmatrix_based\nptdalgorithms_moment\n\n\n&lt;int&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n1\n2.033952e+00\n2.033952e+00\n\n\n2\n8.281555e+00\n8.281555e+00\n\n\n3\n5.057951e+01\n5.057951e+01\n\n\n4\n4.118851e+02\n4.118851e+02\n\n\n5\n4.192640e+03\n4.192640e+03\n\n\n6\n5.121301e+04\n5.121301e+04\n\n\n7\n7.298269e+05\n7.298269e+05\n\n\n8\n1.188643e+07\n1.188643e+07\n\n\n9\n2.177887e+08\n2.177887e+08\n\n\n10\n4.433808e+09\n4.433808e+09\n\n\n\n\n\n\ninstall.packages(\"expm\")\nlibrary(expm)\n\nInstalling package into ‘/home/tobias/R/x86_64-pc-linux-gnu-library/4.1’\n(as ‘lib’ is unspecified)\n\nWarning message in install.packages(\"expm\"):\n“installation of package ‘expm’ had non-zero exit status”\n\n\n\nt &lt;- seq(0,1,by=0.01)\ny1 &lt;- pph(t,g,granularity=10000)\nplot(t, y1)\ny2 &lt;- sapply(t, function(t) {1-alpha%*%expm(S*t)%*%e})\nplot(t, y2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmean(abs((y2-y1)/y1)*100, na.rm=T)\nmax(abs((y2-y1)/y1)*100, na.rm=T)\n\n0.00274811498916354\n\n\n0.0209295716027006\n\n\n0.5\n\n\n\nstop1 &lt;- alpha%*%expm(S)\nstop2 &lt;- stop_probability(g, 1, 10000)\n\n\nstop11 &lt;- c(0, rev(stop1),0)\nmean(abs(stop11-stop2)/stop11*100, na.rm=T)\nmax(abs(stop11-stop2)/stop11*100, na.rm=T)\n\n0.00120642027320843\n\n\n0.00120642027591513"
  },
  {
    "objectID": "api/Graph.html",
    "href": "api/Graph.html",
    "title": "Graph",
    "section": "",
    "text": "ptdalgorithms.Graph(\n    self,\n    state_length=None,\n    callback=None,\n    initial=None,\n    trans_as_dict=False,\n)\n\n\n\n\n\nName\nDescription\n\n\n\n\naccumulated_visiting_time\naccumulated_visiting_time(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, time: float, granularity: int = 0) -&gt; list[float]\n\n\naccumulated_visits_discrete\naccumulated_visits_discrete(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, jumps: int) -&gt; list[float]\n\n\nas_matrices\nas_matrices(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph) -&gt; ptdalgorithms.ptdalgorithmscpp_pybind.MatrixRepresentation\n\n\ncdf\ncdf(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, time: numpy.ndarray[numpy.float32], granularity: numpy.ndarray[numpy.int32] = 0) -&gt; object\n\n\ncdf_discrete\ncdf_discrete(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, jumps: numpy.ndarray[numpy.int32]) -&gt; object\n\n\nclone\nclone(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph) -&gt; ptdalgorithms.ptdalgorithmscpp_pybind.Graph\n\n\ncovariance\ncovariance(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, rewards1: list[float], rewards2: list[float]) -&gt; float\n\n\ncovariance_discrete\ncovariance_discrete(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, rewards1: list[float], rewards2: list[float]) -&gt; float\n\n\ncreate_vertex\ncreate_vertex(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, state: list[int]) -&gt; ptdalgorithms::Vertex\n\n\ndefect\ndefect(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph) -&gt; float\n\n\ndistribution_context\ndistribution_context(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, granularity: int = 0) -&gt; ptdalgorithms::ProbabilityDistributionContext\n\n\ndistribution_context_discrete\ndistribution_context_discrete(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph) -&gt; ptdalgorithms::DPHProbabilityDistributionContext\n\n\nexpectation\nexpectation(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, rewards: list[float] = []) -&gt; float\n\n\nexpectation_dag\nexpectation_dag(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, rewards: list[float]) -&gt; ptdalgorithms.ptdalgorithmscpp_pybind.Graph\n\n\nexpectation_discrete\nexpectation_discrete(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, arg0: list[float]) -&gt; float\n\n\nexpected_residence_time\nexpected_residence_time(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, rewards: list[float] = []) -&gt; list[float]\n\n\nexpected_visits_discrete\nexpected_visits_discrete(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, jumps: int) -&gt; list[float]\n\n\nexpected_waiting_time\nexpected_waiting_time(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, rewards: list[float] = []) -&gt; list[float]\n\n\nfind_or_create_vertex\nfind_or_create_vertex(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, state: list[int]) -&gt; ptdalgorithms::Vertex\n\n\nfind_vertex\nfind_vertex(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, state: list[int]) -&gt; ptdalgorithms::Vertex\n\n\nfocv\nfocv(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, state: list[int]) -&gt; ptdalgorithms::Vertex\n\n\nis_acyclic\nis_acyclic(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph) -&gt; bool\n\n\nmoments\nmoments(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, power: int, rewards: list[float] = []) -&gt; list[float]\n\n\nnormalize\nnormalize(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph) -&gt; list[float]\n\n\nnormalize_discrete\nnormalize_discrete(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph) -&gt; list[float]\n\n\nnotify_change\nnotify_change(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph) -&gt; None\n\n\npdf\npdf(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, time: numpy.ndarray[numpy.float32], granularity: numpy.ndarray[numpy.int32] = 0) -&gt; object\n\n\npmf_discrete\npmf_discrete(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, jumps: numpy.ndarray[numpy.int32]) -&gt; object\n\n\nrandom_sample_discrete_stop_vertex\nrandom_sample_discrete_stop_vertex(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, jumps: int) -&gt; int\n\n\nrandom_sample_stop_vertex\nrandom_sample_stop_vertex(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, time: float) -&gt; int\n\n\nreward_transform\nreward_transform(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, rewards: list[float]) -&gt; ptdalgorithms.ptdalgorithmscpp_pybind.Graph\n\n\nreward_transform_discrete\nreward_transform_discrete(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, rewards: list[int]) -&gt; ptdalgorithms.ptdalgorithmscpp_pybind.Graph\n\n\nsample\nsample(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, n: int = 1, rewards: list[float] = []) -&gt; list[float]\n\n\nsample_discrete\nsample_discrete(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, n: int = 1, rewards: list[float] = []) -&gt; list[float]\n\n\nsample_multivariate\nsample_multivariate(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, n: int = 1, rewards: numpy.ndarray[numpy.float64[m, n]] = []) -&gt; numpy.ndarray[numpy.float64[m, n]]\n\n\nsample_multivariate_discrete\nsample_multivariate_discrete(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, n: int = 1, rewards: numpy.ndarray[numpy.float64[m, n]] = []) -&gt; numpy.ndarray[numpy.float64[m, n]]\n\n\nstarting_vertex\nstarting_vertex(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph) -&gt; ptdalgorithms::Vertex\n\n\nstate_length\nstate_length(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph) -&gt; int\n\n\nstates\nstates(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph) -&gt; numpy.ndarray[numpy.int32[m, n]]\n\n\nstop_probability\nstop_probability(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, time: float, granularity: int = 0) -&gt; list[float]\n\n\nstop_probability_discrete\nstop_probability_discrete(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, jumps: int) -&gt; list[float]\n\n\nupdate_parameterized_weights\nupdate_parameterized_weights(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, rewards: list[float]) -&gt; None\n\n\nvalidate\nvalidate(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph) -&gt; None\n\n\nvariance\nvariance(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, rewards: list[float] = []) -&gt; float\n\n\nvariance_discrete\nvariance_discrete(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, arg0: list[float]) -&gt; float\n\n\nvertex_at\nvertex_at(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, index: int) -&gt; ptdalgorithms::Vertex\n\n\nvertex_exists\nvertex_exists(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, state: list[int]) -&gt; bool\n\n\nvertices\nvertices(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph) -&gt; list[ptdalgorithms::Vertex]\n\n\nvertices_length\nvertices_length(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph) -&gt; int\n\n\n\n\n\nptdalgorithms.Graph.accumulated_visiting_time()\naccumulated_visiting_time(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, time: float, granularity: int = 0) -&gt; list[float]\n\n\n\nptdalgorithms.Graph.accumulated_visits_discrete()\naccumulated_visits_discrete(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, jumps: int) -&gt; list[float]\n\n\n\nptdalgorithms.Graph.as_matrices()\nas_matrices(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph) -&gt; ptdalgorithms.ptdalgorithmscpp_pybind.MatrixRepresentation\n\n\n\nptdalgorithms.Graph.cdf()\ncdf(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, time: numpy.ndarray[numpy.float32], granularity: numpy.ndarray[numpy.int32] = 0) -&gt; object\n\n\n\nptdalgorithms.Graph.cdf_discrete()\ncdf_discrete(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, jumps: numpy.ndarray[numpy.int32]) -&gt; object\n\n\n\nptdalgorithms.Graph.clone()\nclone(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph) -&gt; ptdalgorithms.ptdalgorithmscpp_pybind.Graph\n\n\n\nptdalgorithms.Graph.covariance()\ncovariance(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, rewards1: list[float], rewards2: list[float]) -&gt; float\n\n\n\nptdalgorithms.Graph.covariance_discrete()\ncovariance_discrete(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, rewards1: list[float], rewards2: list[float]) -&gt; float\n\n\n\nptdalgorithms.Graph.create_vertex()\ncreate_vertex(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, state: list[int]) -&gt; ptdalgorithms::Vertex\n\n\n\nptdalgorithms.Graph.defect()\ndefect(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph) -&gt; float\n\n\n\nptdalgorithms.Graph.distribution_context()\ndistribution_context(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, granularity: int = 0) -&gt; ptdalgorithms::ProbabilityDistributionContext\n\n\n\nptdalgorithms.Graph.distribution_context_discrete()\ndistribution_context_discrete(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph) -&gt; ptdalgorithms::DPHProbabilityDistributionContext\n\n\n\nptdalgorithms.Graph.expectation()\nexpectation(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, rewards: list[float] = []) -&gt; float\n//’ Computes the expectation (mean) of the phase-type distribution //’ //’ @description //’ This function invokes [ptdalgorithms::expected_waiting_times()] //’ and takes the first entry (from starting vertex) //’ //’ @return The expectation of the distribution //’ //’ @param phase_type_graph A reference to the graph created by [ptdalgorithms::create_graph()] //’ @param rewards Optional rewards, which should be applied to the phase-type distribution. Must have length equal to [ptdalgorithms::vertices_length()] //’ //’ @seealso [ptdalgorithms::expected_waiting_time()] //’ @seealso [ptdalgorithms::moments()] //’ @seealso [ptdalgorithms::variance()] //’ @seealso [ptdalgorithms::covariance()] //’ //’ @examples //’ graph &lt;- ptdalgorithms::create_graph(4) //’ v1 &lt;- ptdalgorithms::create_vertex(graph, c(1,2,3,4)) //’ v2 &lt;- ptdalgorithms::create_vertex(graph, c(4,0,3,3)) //’ a &lt;- ptdalgorithms::create_vertex(graph, c(0,0,0,0)) //’ ptdalgorithms::add_edge(ptdalgorithms::starting_vertex(graph), v1, 1) //’ ptdalgorithms::add_edge(v1, v2, 4) //’ ptdalgorithms::add_edge(v2, a, 10) //’ ptdalgorithms::expectation(graph) # =&gt; //’ 0.35 //’ ptdalgorithms::expectation(graph, c(0,2,1,0)) # =&gt; //’ 0.6 //’ ph &lt;- ptdalgorithms::graph_as_matrix(graph) //’ # This is a much faster version of //’ ph\\(IPV%*%solve(-ph\\)SIM) %% rep(1, length(ph\\(IPV)) # =&gt;\n//'   0.35\n//' ph\\)IPV%%solve(-ph\\(SIM) %*% diag(c(2,1))%*% rep(1, length(ph\\)IPV)) # =&gt; //’ 0.35\n\n\n\nptdalgorithms.Graph.expectation_dag()\nexpectation_dag(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, rewards: list[float]) -&gt; ptdalgorithms.ptdalgorithmscpp_pybind.Graph\n\n\n\nptdalgorithms.Graph.expectation_discrete()\nexpectation_discrete(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, arg0: list[float]) -&gt; float\n\n\n\nptdalgorithms.Graph.expected_residence_time()\nexpected_residence_time(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, rewards: list[float] = []) -&gt; list[float]\n\n\n\nptdalgorithms.Graph.expected_visits_discrete()\nexpected_visits_discrete(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, jumps: int) -&gt; list[float]\n\n\n\nptdalgorithms.Graph.expected_waiting_time()\nexpected_waiting_time(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, rewards: list[float] = []) -&gt; list[float]\n\n\n\nptdalgorithms.Graph.find_or_create_vertex()\nfind_or_create_vertex(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, state: list[int]) -&gt; ptdalgorithms::Vertex\n//’ Find or create a vertex matching state //’ //’ @description //’ Finds a vertex by the state parameter. If no such //’ vertex exists, it creates the vertex and adds it to //’ the graph object instead. //’ //’ @details //’ A faster and simpler version of calling [ptdalgorithms::find_vertex()] and [ptdalgorithms::create_vertex()] //’ //’ @return The newly found or inserted vertex in the graph //’ //’ @param phase_type_graph A reference to the graph created by [ptdalgorithms::create_graph()] //’ @param state An integer vector of what vertex to look for. Has length as given by state_length in [ptdalgorithms::create_graph()] //’ //’ @examples //’ graph &lt;- create_graph(4) //’ find_or_create_vertex(graph, c(1,2,1,0)) # Adds and returns the vertex //’ find_or_create_vertex(graph, c(1,2,1,0)) # Only returns the vertex //’ # graph is now changed permanently\n\n\n\nptdalgorithms.Graph.find_vertex()\nfind_vertex(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, state: list[int]) -&gt; ptdalgorithms::Vertex\n\n\n\nptdalgorithms.Graph.focv()\nfocv(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, state: list[int]) -&gt; ptdalgorithms::Vertex\nAlias for find_or_create_vertex\n\n\n\nptdalgorithms.Graph.is_acyclic()\nis_acyclic(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph) -&gt; bool\n\n\n\nptdalgorithms.Graph.moments()\nmoments(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, power: int, rewards: list[float] = []) -&gt; list[float]\n//’ Computes the first k moments of the phase-type distribution //’ //’ @description //’ This function invokes [ptdalgorithms::expected_waiting_times()] consequtively to find the first moments, //’ given by the power argument //’ //’ @return A numeric vector of the first k moments. The first entry is the first moment (mean) //’ //’ @param phase_type_graph A reference to the graph created by [ptdalgorithms::create_graph()] //’ @param power An integer of the first k moments. //’ @param rewards Optional rewards, which should be applied to the phase-type distribution. Must have length equal to [ptdalgorithms::vertices_length()] //’ //’ @seealso [ptdalgorithms::expected_waiting_time()] //’ @seealso [ptdalgorithms::expectation()] //’ @seealso [ptdalgorithms::variance()] //’ @seealso [ptdalgorithms::covariance()] //’ //’ @examples //’ graph &lt;- ptdalgorithms::create_graph(4) //’ v1 &lt;- ptdalgorithms::create_vertex(graph, c(1,2,3,4)) //’ v2 &lt;- ptdalgorithms::create_vertex(graph, c(4,0,3,3)) //’ a &lt;- ptdalgorithms::create_vertex(graph, c(0,0,0,0)) //’ ptdalgorithms::add_edge(ptdalgorithms::starting_vertex(graph), v1, 1) //’ ptdalgorithms::add_edge(v1, v2, 4) //’ ptdalgorithms::add_edge(v2, a, 10) //’ ptdalgorithms::moments(graph, 3) # =&gt; //’ (0.350000 0.097500 0.025375) //’ ptdalgorithms::moments(graph, 3, c(0,2,1,0)) # =&gt; //’ (0.600 0.160 0.041)\n\n\n\nptdalgorithms.Graph.normalize()\nnormalize(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph) -&gt; list[float]\n\n\n\nptdalgorithms.Graph.normalize_discrete()\nnormalize_discrete(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph) -&gt; list[float]\n\n\n\nptdalgorithms.Graph.notify_change()\nnotify_change(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph) -&gt; None\n\n\n\nptdalgorithms.Graph.pdf()\npdf(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, time: numpy.ndarray[numpy.float32], granularity: numpy.ndarray[numpy.int32] = 0) -&gt; object\n\n\n\nptdalgorithms.Graph.pmf_discrete()\npmf_discrete(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, jumps: numpy.ndarray[numpy.int32]) -&gt; object\n\n\n\nptdalgorithms.Graph.random_sample_discrete_stop_vertex()\nrandom_sample_discrete_stop_vertex(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, jumps: int) -&gt; int\n\n\n\nptdalgorithms.Graph.random_sample_stop_vertex()\nrandom_sample_stop_vertex(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, time: float) -&gt; int\n\n\n\nptdalgorithms.Graph.reward_transform()\nreward_transform(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, rewards: list[float]) -&gt; ptdalgorithms.ptdalgorithmscpp_pybind.Graph\n\n\n\nptdalgorithms.Graph.reward_transform_discrete()\nreward_transform_discrete(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, rewards: list[int]) -&gt; ptdalgorithms.ptdalgorithmscpp_pybind.Graph\n\n\n\nptdalgorithms.Graph.sample()\nsample(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, n: int = 1, rewards: list[float] = []) -&gt; list[float]\n\n\n\nptdalgorithms.Graph.sample_discrete()\nsample_discrete(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, n: int = 1, rewards: list[float] = []) -&gt; list[float]\n\n\n\nptdalgorithms.Graph.sample_multivariate()\nsample_multivariate(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, n: int = 1, rewards: numpy.ndarray[numpy.float64[m, n]] = []) -&gt; numpy.ndarray[numpy.float64[m, n]]\n\n\n\nptdalgorithms.Graph.sample_multivariate_discrete()\nsample_multivariate_discrete(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, n: int = 1, rewards: numpy.ndarray[numpy.float64[m, n]] = []) -&gt; numpy.ndarray[numpy.float64[m, n]]\n\n\n\nptdalgorithms.Graph.starting_vertex()\nstarting_vertex(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph) -&gt; ptdalgorithms::Vertex\n\n\n\nptdalgorithms.Graph.state_length()\nstate_length(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph) -&gt; int\n\n\n\nptdalgorithms.Graph.states()\nstates(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph) -&gt; numpy.ndarray[numpy.int32[m, n]]\n//’ Returns a matrix where each row is the state of the vertex at that index //’ //’ @return A matrix of size [ptdalgorithms::vertices_length()] where the rows match the state of the vertex at that index //’ //’ @param phase_type_graph A reference to the graph created by [ptdalgorithms::create_graph()] //’ //’ @examples //’ graph &lt;- ptdalgorithms::create_graph(4) //’ ptdalgorithms::create_vertex(graph, c(1,2,3,4)) //’ ptdalgorithms::create_vertex(graph, c(4,3,3,3)) //’ ptdalgorithms::states(graph) # =&gt; //’ # 0 0 0 0 //’ # 1 2 3 4 //’ # 4 3 3 3\n\n\n\nptdalgorithms.Graph.stop_probability()\nstop_probability(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, time: float, granularity: int = 0) -&gt; list[float]\n\n\n\nptdalgorithms.Graph.stop_probability_discrete()\nstop_probability_discrete(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, jumps: int) -&gt; list[float]\n\n\n\nptdalgorithms.Graph.update_parameterized_weights()\nupdate_parameterized_weights(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, rewards: list[float]) -&gt; None\n//’ Updates all parameterized edges of the graph by given scalars. //’ //’ @description //’ Given a vector of scalars, computes a new weight of //’ the parameterized edges in the graph by a simple inner //’ product of the edge state vector and the scalar vector. //’ //’ @details //’ A faster and simpler version to compute new moments, when //’ the user wants to try multiple different weights. //’ //’ //’ @param phase_type_graph A reference to the graph created by [ptdalgorithms::create_graph()] //’ @param scalars A numeric vector of multiplies for the edge states. //’ //’ @seealso [ptdalgorithms::expected_waiting_time()] //’ @seealso [ptdalgorithms::add_edge()] //’ //’ @examples //’ graph &lt;- create_graph(4) //’ v1 &lt;- find_or_create_vertex(graph, c(1,2,1,0)) //’ v2 &lt;- find_or_create_vertex(graph, c(2,0,1,0)) //’ add_edge(starting_vertex(graph), v1, 5) //’ add_edge(v1, v2, 0, c(5,2)) //’ edges(starting_vertex(graph))[[1]]\\(weight # =&gt; 5\n//' edges(v1)[[1]]\\)weight # =&gt; 0 //’ graph_update_weights_parameterized(graph, c(9,7)) //’ edges(starting_vertex(graph))[[1]]\\(weight # =&gt; 5\n//' edges(v1)[[1]]\\)weight # =&gt; 59\n\n\n\nptdalgorithms.Graph.validate()\nvalidate(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph) -&gt; None\n\n\n\nptdalgorithms.Graph.variance()\nvariance(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, rewards: list[float] = []) -&gt; float\n//’ Computes the variance of the phase-type distribution //’ //’ @description //’ This function invokes [ptdalgorithms::expected_waiting_times()] //’ twice to find the first and second moment //’ //’ @return The variance of the distribution //’ //’ @param phase_type_graph A reference to the graph created by [ptdalgorithms::create_graph()] //’ @param rewards Optional rewards, which should be applied to the phase-type distribution. Must have length equal to [ptdalgorithms::vertices_length()] //’ //’ @seealso [ptdalgorithms::expected_waiting_time()] //’ @seealso [ptdalgorithms::expectation()] //’ @seealso [ptdalgorithms::moments()] //’ @seealso [ptdalgorithms::covariance()] //’ //’ @examples //’ graph &lt;- ptdalgorithms::create_graph(4) //’ v1 &lt;- ptdalgorithms::create_vertex(graph, c(1,2,3,4)) //’ v2 &lt;- ptdalgorithms::create_vertex(graph, c(4,0,3,3)) //’ a &lt;- ptdalgorithms::create_vertex(graph, c(0,0,0,0)) //’ ptdalgorithms::add_edge(ptdalgorithms::starting_vertex(graph), v1, 1) //’ ptdalgorithms::add_edge(v1, v2, 4) //’ ptdalgorithms::add_edge(v2, a, 10) //’ ptdalgorithms::variance(graph) # =&gt; //’ 0.0725 //’ ptdalgorithms::variance(graph, c(0,2,1,0)) # =&gt; //’ 0.26 //’ ph &lt;- ptdalgorithms::graph_as_matrix(graph) //’ # This is a much faster version of //’ 2ph\\(IPV%*%solve(-ph\\)SIM)%%solve(-ph\\(SIM) %*% rep(1, length(ph\\)IPV)) - ph\\(IPV%*%solve(-ph\\)SIM) %% rep(1, length(ph\\(IPV)) %*% ph\\)IPV%%solve(-ph\\(SIM) %*% rep(1, length(ph\\)IPV)) # =&gt; //’ 0.0725 //’ 2ph\\(IPV%*%solve(-ph\\)SIM)%%diag(c(2,1))%%solve(-ph\\(SIM)%*%diag(c(2,1)) %*% rep(1, length(ph\\)IPV)) - ph\\(IPV%*%solve(-ph\\)SIM)%%diag(c(2,1)) %% rep(1, length(ph\\(IPV)) %*% ph\\)IPV%%solve(-ph\\(SIM)%*%diag(c(2,1)) %*% rep(1, length(ph\\)IPV)) # =&gt; //’ 0.26\n\n\n\nptdalgorithms.Graph.variance_discrete()\nvariance_discrete(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, arg0: list[float]) -&gt; float\n\n\n\nptdalgorithms.Graph.vertex_at()\nvertex_at(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, index: int) -&gt; ptdalgorithms::Vertex\n\n\n\nptdalgorithms.Graph.vertex_exists()\nvertex_exists(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, state: list[int]) -&gt; bool\n\n\n\nptdalgorithms.Graph.vertices()\nvertices(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph) -&gt; list[ptdalgorithms::Vertex]\n//’ Obtain a list of all vertices in the graph //’ //’ @description //’ Returns all vertices that have been added to the //’ graph from either calling find_or_create_vertex or //’ create_vertex. The first vertex in the list is //’ always the starting vertex [ptdalgorithms::starting_vertex()]. //’ Importantly, for speed, use [ptdalgorithms::vertices_length()] to get the number //’ of added vertices, and use [ptdalgorithms::vertex_at()] to //’ get a vertex at a particular index. //’ //’ @details //’ The list of vertices contains any added vertex, even //’ if it does not have any in-going / out-going edges. //’ //’ @param phase_type_graph A reference to the graph created by [ptdalgorithms::create_graph()] //’ //’ @seealso [ptdalgorithms::starting_vertex()] //’ @seealso [ptdalgorithms::vertices_length()] //’ @seealso [ptdalgorithms::vertex_at()] //’ //’ @examples //’ graph &lt;- create_graph(4) //’ vertex_a &lt;- find_or_create_vertex(graph, c(1,2,1,0)) //’ vertex_b &lt;- find_or_create_vertex(graph, c(2,0,1,0)) //’ vertices(graph)[[1]] == starting_vertex(graph) //’ vertices(graph)[[2]] == vertex_at(graph, 2) //’ vertices_length(graph) == 3\n\n\n\nptdalgorithms.Graph.vertices_length()\nvertices_length(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph) -&gt; int",
    "crumbs": [
      "Some section",
      "Graph"
    ]
  },
  {
    "objectID": "api/Graph.html#methods",
    "href": "api/Graph.html#methods",
    "title": "Graph",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\naccumulated_visiting_time\naccumulated_visiting_time(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, time: float, granularity: int = 0) -&gt; list[float]\n\n\naccumulated_visits_discrete\naccumulated_visits_discrete(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, jumps: int) -&gt; list[float]\n\n\nas_matrices\nas_matrices(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph) -&gt; ptdalgorithms.ptdalgorithmscpp_pybind.MatrixRepresentation\n\n\ncdf\ncdf(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, time: numpy.ndarray[numpy.float32], granularity: numpy.ndarray[numpy.int32] = 0) -&gt; object\n\n\ncdf_discrete\ncdf_discrete(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, jumps: numpy.ndarray[numpy.int32]) -&gt; object\n\n\nclone\nclone(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph) -&gt; ptdalgorithms.ptdalgorithmscpp_pybind.Graph\n\n\ncovariance\ncovariance(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, rewards1: list[float], rewards2: list[float]) -&gt; float\n\n\ncovariance_discrete\ncovariance_discrete(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, rewards1: list[float], rewards2: list[float]) -&gt; float\n\n\ncreate_vertex\ncreate_vertex(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, state: list[int]) -&gt; ptdalgorithms::Vertex\n\n\ndefect\ndefect(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph) -&gt; float\n\n\ndistribution_context\ndistribution_context(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, granularity: int = 0) -&gt; ptdalgorithms::ProbabilityDistributionContext\n\n\ndistribution_context_discrete\ndistribution_context_discrete(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph) -&gt; ptdalgorithms::DPHProbabilityDistributionContext\n\n\nexpectation\nexpectation(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, rewards: list[float] = []) -&gt; float\n\n\nexpectation_dag\nexpectation_dag(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, rewards: list[float]) -&gt; ptdalgorithms.ptdalgorithmscpp_pybind.Graph\n\n\nexpectation_discrete\nexpectation_discrete(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, arg0: list[float]) -&gt; float\n\n\nexpected_residence_time\nexpected_residence_time(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, rewards: list[float] = []) -&gt; list[float]\n\n\nexpected_visits_discrete\nexpected_visits_discrete(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, jumps: int) -&gt; list[float]\n\n\nexpected_waiting_time\nexpected_waiting_time(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, rewards: list[float] = []) -&gt; list[float]\n\n\nfind_or_create_vertex\nfind_or_create_vertex(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, state: list[int]) -&gt; ptdalgorithms::Vertex\n\n\nfind_vertex\nfind_vertex(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, state: list[int]) -&gt; ptdalgorithms::Vertex\n\n\nfocv\nfocv(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, state: list[int]) -&gt; ptdalgorithms::Vertex\n\n\nis_acyclic\nis_acyclic(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph) -&gt; bool\n\n\nmoments\nmoments(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, power: int, rewards: list[float] = []) -&gt; list[float]\n\n\nnormalize\nnormalize(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph) -&gt; list[float]\n\n\nnormalize_discrete\nnormalize_discrete(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph) -&gt; list[float]\n\n\nnotify_change\nnotify_change(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph) -&gt; None\n\n\npdf\npdf(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, time: numpy.ndarray[numpy.float32], granularity: numpy.ndarray[numpy.int32] = 0) -&gt; object\n\n\npmf_discrete\npmf_discrete(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, jumps: numpy.ndarray[numpy.int32]) -&gt; object\n\n\nrandom_sample_discrete_stop_vertex\nrandom_sample_discrete_stop_vertex(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, jumps: int) -&gt; int\n\n\nrandom_sample_stop_vertex\nrandom_sample_stop_vertex(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, time: float) -&gt; int\n\n\nreward_transform\nreward_transform(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, rewards: list[float]) -&gt; ptdalgorithms.ptdalgorithmscpp_pybind.Graph\n\n\nreward_transform_discrete\nreward_transform_discrete(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, rewards: list[int]) -&gt; ptdalgorithms.ptdalgorithmscpp_pybind.Graph\n\n\nsample\nsample(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, n: int = 1, rewards: list[float] = []) -&gt; list[float]\n\n\nsample_discrete\nsample_discrete(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, n: int = 1, rewards: list[float] = []) -&gt; list[float]\n\n\nsample_multivariate\nsample_multivariate(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, n: int = 1, rewards: numpy.ndarray[numpy.float64[m, n]] = []) -&gt; numpy.ndarray[numpy.float64[m, n]]\n\n\nsample_multivariate_discrete\nsample_multivariate_discrete(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, n: int = 1, rewards: numpy.ndarray[numpy.float64[m, n]] = []) -&gt; numpy.ndarray[numpy.float64[m, n]]\n\n\nstarting_vertex\nstarting_vertex(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph) -&gt; ptdalgorithms::Vertex\n\n\nstate_length\nstate_length(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph) -&gt; int\n\n\nstates\nstates(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph) -&gt; numpy.ndarray[numpy.int32[m, n]]\n\n\nstop_probability\nstop_probability(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, time: float, granularity: int = 0) -&gt; list[float]\n\n\nstop_probability_discrete\nstop_probability_discrete(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, jumps: int) -&gt; list[float]\n\n\nupdate_parameterized_weights\nupdate_parameterized_weights(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, rewards: list[float]) -&gt; None\n\n\nvalidate\nvalidate(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph) -&gt; None\n\n\nvariance\nvariance(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, rewards: list[float] = []) -&gt; float\n\n\nvariance_discrete\nvariance_discrete(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, arg0: list[float]) -&gt; float\n\n\nvertex_at\nvertex_at(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, index: int) -&gt; ptdalgorithms::Vertex\n\n\nvertex_exists\nvertex_exists(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, state: list[int]) -&gt; bool\n\n\nvertices\nvertices(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph) -&gt; list[ptdalgorithms::Vertex]\n\n\nvertices_length\nvertices_length(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph) -&gt; int\n\n\n\n\n\nptdalgorithms.Graph.accumulated_visiting_time()\naccumulated_visiting_time(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, time: float, granularity: int = 0) -&gt; list[float]\n\n\n\nptdalgorithms.Graph.accumulated_visits_discrete()\naccumulated_visits_discrete(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, jumps: int) -&gt; list[float]\n\n\n\nptdalgorithms.Graph.as_matrices()\nas_matrices(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph) -&gt; ptdalgorithms.ptdalgorithmscpp_pybind.MatrixRepresentation\n\n\n\nptdalgorithms.Graph.cdf()\ncdf(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, time: numpy.ndarray[numpy.float32], granularity: numpy.ndarray[numpy.int32] = 0) -&gt; object\n\n\n\nptdalgorithms.Graph.cdf_discrete()\ncdf_discrete(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, jumps: numpy.ndarray[numpy.int32]) -&gt; object\n\n\n\nptdalgorithms.Graph.clone()\nclone(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph) -&gt; ptdalgorithms.ptdalgorithmscpp_pybind.Graph\n\n\n\nptdalgorithms.Graph.covariance()\ncovariance(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, rewards1: list[float], rewards2: list[float]) -&gt; float\n\n\n\nptdalgorithms.Graph.covariance_discrete()\ncovariance_discrete(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, rewards1: list[float], rewards2: list[float]) -&gt; float\n\n\n\nptdalgorithms.Graph.create_vertex()\ncreate_vertex(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, state: list[int]) -&gt; ptdalgorithms::Vertex\n\n\n\nptdalgorithms.Graph.defect()\ndefect(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph) -&gt; float\n\n\n\nptdalgorithms.Graph.distribution_context()\ndistribution_context(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, granularity: int = 0) -&gt; ptdalgorithms::ProbabilityDistributionContext\n\n\n\nptdalgorithms.Graph.distribution_context_discrete()\ndistribution_context_discrete(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph) -&gt; ptdalgorithms::DPHProbabilityDistributionContext\n\n\n\nptdalgorithms.Graph.expectation()\nexpectation(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, rewards: list[float] = []) -&gt; float\n//’ Computes the expectation (mean) of the phase-type distribution //’ //’ @description //’ This function invokes [ptdalgorithms::expected_waiting_times()] //’ and takes the first entry (from starting vertex) //’ //’ @return The expectation of the distribution //’ //’ @param phase_type_graph A reference to the graph created by [ptdalgorithms::create_graph()] //’ @param rewards Optional rewards, which should be applied to the phase-type distribution. Must have length equal to [ptdalgorithms::vertices_length()] //’ //’ @seealso [ptdalgorithms::expected_waiting_time()] //’ @seealso [ptdalgorithms::moments()] //’ @seealso [ptdalgorithms::variance()] //’ @seealso [ptdalgorithms::covariance()] //’ //’ @examples //’ graph &lt;- ptdalgorithms::create_graph(4) //’ v1 &lt;- ptdalgorithms::create_vertex(graph, c(1,2,3,4)) //’ v2 &lt;- ptdalgorithms::create_vertex(graph, c(4,0,3,3)) //’ a &lt;- ptdalgorithms::create_vertex(graph, c(0,0,0,0)) //’ ptdalgorithms::add_edge(ptdalgorithms::starting_vertex(graph), v1, 1) //’ ptdalgorithms::add_edge(v1, v2, 4) //’ ptdalgorithms::add_edge(v2, a, 10) //’ ptdalgorithms::expectation(graph) # =&gt; //’ 0.35 //’ ptdalgorithms::expectation(graph, c(0,2,1,0)) # =&gt; //’ 0.6 //’ ph &lt;- ptdalgorithms::graph_as_matrix(graph) //’ # This is a much faster version of //’ ph\\(IPV%*%solve(-ph\\)SIM) %% rep(1, length(ph\\(IPV)) # =&gt;\n//'   0.35\n//' ph\\)IPV%%solve(-ph\\(SIM) %*% diag(c(2,1))%*% rep(1, length(ph\\)IPV)) # =&gt; //’ 0.35\n\n\n\nptdalgorithms.Graph.expectation_dag()\nexpectation_dag(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, rewards: list[float]) -&gt; ptdalgorithms.ptdalgorithmscpp_pybind.Graph\n\n\n\nptdalgorithms.Graph.expectation_discrete()\nexpectation_discrete(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, arg0: list[float]) -&gt; float\n\n\n\nptdalgorithms.Graph.expected_residence_time()\nexpected_residence_time(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, rewards: list[float] = []) -&gt; list[float]\n\n\n\nptdalgorithms.Graph.expected_visits_discrete()\nexpected_visits_discrete(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, jumps: int) -&gt; list[float]\n\n\n\nptdalgorithms.Graph.expected_waiting_time()\nexpected_waiting_time(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, rewards: list[float] = []) -&gt; list[float]\n\n\n\nptdalgorithms.Graph.find_or_create_vertex()\nfind_or_create_vertex(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, state: list[int]) -&gt; ptdalgorithms::Vertex\n//’ Find or create a vertex matching state //’ //’ @description //’ Finds a vertex by the state parameter. If no such //’ vertex exists, it creates the vertex and adds it to //’ the graph object instead. //’ //’ @details //’ A faster and simpler version of calling [ptdalgorithms::find_vertex()] and [ptdalgorithms::create_vertex()] //’ //’ @return The newly found or inserted vertex in the graph //’ //’ @param phase_type_graph A reference to the graph created by [ptdalgorithms::create_graph()] //’ @param state An integer vector of what vertex to look for. Has length as given by state_length in [ptdalgorithms::create_graph()] //’ //’ @examples //’ graph &lt;- create_graph(4) //’ find_or_create_vertex(graph, c(1,2,1,0)) # Adds and returns the vertex //’ find_or_create_vertex(graph, c(1,2,1,0)) # Only returns the vertex //’ # graph is now changed permanently\n\n\n\nptdalgorithms.Graph.find_vertex()\nfind_vertex(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, state: list[int]) -&gt; ptdalgorithms::Vertex\n\n\n\nptdalgorithms.Graph.focv()\nfocv(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, state: list[int]) -&gt; ptdalgorithms::Vertex\nAlias for find_or_create_vertex\n\n\n\nptdalgorithms.Graph.is_acyclic()\nis_acyclic(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph) -&gt; bool\n\n\n\nptdalgorithms.Graph.moments()\nmoments(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, power: int, rewards: list[float] = []) -&gt; list[float]\n//’ Computes the first k moments of the phase-type distribution //’ //’ @description //’ This function invokes [ptdalgorithms::expected_waiting_times()] consequtively to find the first moments, //’ given by the power argument //’ //’ @return A numeric vector of the first k moments. The first entry is the first moment (mean) //’ //’ @param phase_type_graph A reference to the graph created by [ptdalgorithms::create_graph()] //’ @param power An integer of the first k moments. //’ @param rewards Optional rewards, which should be applied to the phase-type distribution. Must have length equal to [ptdalgorithms::vertices_length()] //’ //’ @seealso [ptdalgorithms::expected_waiting_time()] //’ @seealso [ptdalgorithms::expectation()] //’ @seealso [ptdalgorithms::variance()] //’ @seealso [ptdalgorithms::covariance()] //’ //’ @examples //’ graph &lt;- ptdalgorithms::create_graph(4) //’ v1 &lt;- ptdalgorithms::create_vertex(graph, c(1,2,3,4)) //’ v2 &lt;- ptdalgorithms::create_vertex(graph, c(4,0,3,3)) //’ a &lt;- ptdalgorithms::create_vertex(graph, c(0,0,0,0)) //’ ptdalgorithms::add_edge(ptdalgorithms::starting_vertex(graph), v1, 1) //’ ptdalgorithms::add_edge(v1, v2, 4) //’ ptdalgorithms::add_edge(v2, a, 10) //’ ptdalgorithms::moments(graph, 3) # =&gt; //’ (0.350000 0.097500 0.025375) //’ ptdalgorithms::moments(graph, 3, c(0,2,1,0)) # =&gt; //’ (0.600 0.160 0.041)\n\n\n\nptdalgorithms.Graph.normalize()\nnormalize(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph) -&gt; list[float]\n\n\n\nptdalgorithms.Graph.normalize_discrete()\nnormalize_discrete(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph) -&gt; list[float]\n\n\n\nptdalgorithms.Graph.notify_change()\nnotify_change(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph) -&gt; None\n\n\n\nptdalgorithms.Graph.pdf()\npdf(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, time: numpy.ndarray[numpy.float32], granularity: numpy.ndarray[numpy.int32] = 0) -&gt; object\n\n\n\nptdalgorithms.Graph.pmf_discrete()\npmf_discrete(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, jumps: numpy.ndarray[numpy.int32]) -&gt; object\n\n\n\nptdalgorithms.Graph.random_sample_discrete_stop_vertex()\nrandom_sample_discrete_stop_vertex(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, jumps: int) -&gt; int\n\n\n\nptdalgorithms.Graph.random_sample_stop_vertex()\nrandom_sample_stop_vertex(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, time: float) -&gt; int\n\n\n\nptdalgorithms.Graph.reward_transform()\nreward_transform(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, rewards: list[float]) -&gt; ptdalgorithms.ptdalgorithmscpp_pybind.Graph\n\n\n\nptdalgorithms.Graph.reward_transform_discrete()\nreward_transform_discrete(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, rewards: list[int]) -&gt; ptdalgorithms.ptdalgorithmscpp_pybind.Graph\n\n\n\nptdalgorithms.Graph.sample()\nsample(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, n: int = 1, rewards: list[float] = []) -&gt; list[float]\n\n\n\nptdalgorithms.Graph.sample_discrete()\nsample_discrete(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, n: int = 1, rewards: list[float] = []) -&gt; list[float]\n\n\n\nptdalgorithms.Graph.sample_multivariate()\nsample_multivariate(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, n: int = 1, rewards: numpy.ndarray[numpy.float64[m, n]] = []) -&gt; numpy.ndarray[numpy.float64[m, n]]\n\n\n\nptdalgorithms.Graph.sample_multivariate_discrete()\nsample_multivariate_discrete(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, n: int = 1, rewards: numpy.ndarray[numpy.float64[m, n]] = []) -&gt; numpy.ndarray[numpy.float64[m, n]]\n\n\n\nptdalgorithms.Graph.starting_vertex()\nstarting_vertex(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph) -&gt; ptdalgorithms::Vertex\n\n\n\nptdalgorithms.Graph.state_length()\nstate_length(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph) -&gt; int\n\n\n\nptdalgorithms.Graph.states()\nstates(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph) -&gt; numpy.ndarray[numpy.int32[m, n]]\n//’ Returns a matrix where each row is the state of the vertex at that index //’ //’ @return A matrix of size [ptdalgorithms::vertices_length()] where the rows match the state of the vertex at that index //’ //’ @param phase_type_graph A reference to the graph created by [ptdalgorithms::create_graph()] //’ //’ @examples //’ graph &lt;- ptdalgorithms::create_graph(4) //’ ptdalgorithms::create_vertex(graph, c(1,2,3,4)) //’ ptdalgorithms::create_vertex(graph, c(4,3,3,3)) //’ ptdalgorithms::states(graph) # =&gt; //’ # 0 0 0 0 //’ # 1 2 3 4 //’ # 4 3 3 3\n\n\n\nptdalgorithms.Graph.stop_probability()\nstop_probability(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, time: float, granularity: int = 0) -&gt; list[float]\n\n\n\nptdalgorithms.Graph.stop_probability_discrete()\nstop_probability_discrete(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, jumps: int) -&gt; list[float]\n\n\n\nptdalgorithms.Graph.update_parameterized_weights()\nupdate_parameterized_weights(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, rewards: list[float]) -&gt; None\n//’ Updates all parameterized edges of the graph by given scalars. //’ //’ @description //’ Given a vector of scalars, computes a new weight of //’ the parameterized edges in the graph by a simple inner //’ product of the edge state vector and the scalar vector. //’ //’ @details //’ A faster and simpler version to compute new moments, when //’ the user wants to try multiple different weights. //’ //’ //’ @param phase_type_graph A reference to the graph created by [ptdalgorithms::create_graph()] //’ @param scalars A numeric vector of multiplies for the edge states. //’ //’ @seealso [ptdalgorithms::expected_waiting_time()] //’ @seealso [ptdalgorithms::add_edge()] //’ //’ @examples //’ graph &lt;- create_graph(4) //’ v1 &lt;- find_or_create_vertex(graph, c(1,2,1,0)) //’ v2 &lt;- find_or_create_vertex(graph, c(2,0,1,0)) //’ add_edge(starting_vertex(graph), v1, 5) //’ add_edge(v1, v2, 0, c(5,2)) //’ edges(starting_vertex(graph))[[1]]\\(weight # =&gt; 5\n//' edges(v1)[[1]]\\)weight # =&gt; 0 //’ graph_update_weights_parameterized(graph, c(9,7)) //’ edges(starting_vertex(graph))[[1]]\\(weight # =&gt; 5\n//' edges(v1)[[1]]\\)weight # =&gt; 59\n\n\n\nptdalgorithms.Graph.validate()\nvalidate(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph) -&gt; None\n\n\n\nptdalgorithms.Graph.variance()\nvariance(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, rewards: list[float] = []) -&gt; float\n//’ Computes the variance of the phase-type distribution //’ //’ @description //’ This function invokes [ptdalgorithms::expected_waiting_times()] //’ twice to find the first and second moment //’ //’ @return The variance of the distribution //’ //’ @param phase_type_graph A reference to the graph created by [ptdalgorithms::create_graph()] //’ @param rewards Optional rewards, which should be applied to the phase-type distribution. Must have length equal to [ptdalgorithms::vertices_length()] //’ //’ @seealso [ptdalgorithms::expected_waiting_time()] //’ @seealso [ptdalgorithms::expectation()] //’ @seealso [ptdalgorithms::moments()] //’ @seealso [ptdalgorithms::covariance()] //’ //’ @examples //’ graph &lt;- ptdalgorithms::create_graph(4) //’ v1 &lt;- ptdalgorithms::create_vertex(graph, c(1,2,3,4)) //’ v2 &lt;- ptdalgorithms::create_vertex(graph, c(4,0,3,3)) //’ a &lt;- ptdalgorithms::create_vertex(graph, c(0,0,0,0)) //’ ptdalgorithms::add_edge(ptdalgorithms::starting_vertex(graph), v1, 1) //’ ptdalgorithms::add_edge(v1, v2, 4) //’ ptdalgorithms::add_edge(v2, a, 10) //’ ptdalgorithms::variance(graph) # =&gt; //’ 0.0725 //’ ptdalgorithms::variance(graph, c(0,2,1,0)) # =&gt; //’ 0.26 //’ ph &lt;- ptdalgorithms::graph_as_matrix(graph) //’ # This is a much faster version of //’ 2ph\\(IPV%*%solve(-ph\\)SIM)%%solve(-ph\\(SIM) %*% rep(1, length(ph\\)IPV)) - ph\\(IPV%*%solve(-ph\\)SIM) %% rep(1, length(ph\\(IPV)) %*% ph\\)IPV%%solve(-ph\\(SIM) %*% rep(1, length(ph\\)IPV)) # =&gt; //’ 0.0725 //’ 2ph\\(IPV%*%solve(-ph\\)SIM)%%diag(c(2,1))%%solve(-ph\\(SIM)%*%diag(c(2,1)) %*% rep(1, length(ph\\)IPV)) - ph\\(IPV%*%solve(-ph\\)SIM)%%diag(c(2,1)) %% rep(1, length(ph\\(IPV)) %*% ph\\)IPV%%solve(-ph\\(SIM)%*%diag(c(2,1)) %*% rep(1, length(ph\\)IPV)) # =&gt; //’ 0.26\n\n\n\nptdalgorithms.Graph.variance_discrete()\nvariance_discrete(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, arg0: list[float]) -&gt; float\n\n\n\nptdalgorithms.Graph.vertex_at()\nvertex_at(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, index: int) -&gt; ptdalgorithms::Vertex\n\n\n\nptdalgorithms.Graph.vertex_exists()\nvertex_exists(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph, state: list[int]) -&gt; bool\n\n\n\nptdalgorithms.Graph.vertices()\nvertices(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph) -&gt; list[ptdalgorithms::Vertex]\n//’ Obtain a list of all vertices in the graph //’ //’ @description //’ Returns all vertices that have been added to the //’ graph from either calling find_or_create_vertex or //’ create_vertex. The first vertex in the list is //’ always the starting vertex [ptdalgorithms::starting_vertex()]. //’ Importantly, for speed, use [ptdalgorithms::vertices_length()] to get the number //’ of added vertices, and use [ptdalgorithms::vertex_at()] to //’ get a vertex at a particular index. //’ //’ @details //’ The list of vertices contains any added vertex, even //’ if it does not have any in-going / out-going edges. //’ //’ @param phase_type_graph A reference to the graph created by [ptdalgorithms::create_graph()] //’ //’ @seealso [ptdalgorithms::starting_vertex()] //’ @seealso [ptdalgorithms::vertices_length()] //’ @seealso [ptdalgorithms::vertex_at()] //’ //’ @examples //’ graph &lt;- create_graph(4) //’ vertex_a &lt;- find_or_create_vertex(graph, c(1,2,1,0)) //’ vertex_b &lt;- find_or_create_vertex(graph, c(2,0,1,0)) //’ vertices(graph)[[1]] == starting_vertex(graph) //’ vertices(graph)[[2]] == vertex_at(graph, 2) //’ vertices_length(graph) == 3\n\n\n\nptdalgorithms.Graph.vertices_length()\nvertices_length(self: ptdalgorithms.ptdalgorithmscpp_pybind.Graph) -&gt; int",
    "crumbs": [
      "Some section",
      "Graph"
    ]
  },
  {
    "objectID": "api/Edge.html",
    "href": "api/Edge.html",
    "title": "Edge",
    "section": "",
    "text": "ptdalgorithms.Edge()\n\n\n\n\n\nName\nDescription\n\n\n\n\nto\nto(self: ptdalgorithms.ptdalgorithmscpp_pybind.Edge) -&gt; ptdalgorithms.ptdalgorithmscpp_pybind.Vertex\n\n\nupdate_weight\nupdate_weight(self: ptdalgorithms.ptdalgorithmscpp_pybind.Edge, arg0: float) -&gt; None\n\n\nweight\nweight(self: ptdalgorithms.ptdalgorithmscpp_pybind.Edge) -&gt; float\n\n\n\n\n\nptdalgorithms.Edge.to()\nto(self: ptdalgorithms.ptdalgorithmscpp_pybind.Edge) -&gt; ptdalgorithms.ptdalgorithmscpp_pybind.Vertex\n\n\n\nptdalgorithms.Edge.update_weight()\nupdate_weight(self: ptdalgorithms.ptdalgorithmscpp_pybind.Edge, arg0: float) -&gt; None\n\n\n\nptdalgorithms.Edge.weight()\nweight(self: ptdalgorithms.ptdalgorithmscpp_pybind.Edge) -&gt; float",
    "crumbs": [
      "Some section",
      "Edge"
    ]
  },
  {
    "objectID": "api/Edge.html#methods",
    "href": "api/Edge.html#methods",
    "title": "Edge",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nto\nto(self: ptdalgorithms.ptdalgorithmscpp_pybind.Edge) -&gt; ptdalgorithms.ptdalgorithmscpp_pybind.Vertex\n\n\nupdate_weight\nupdate_weight(self: ptdalgorithms.ptdalgorithmscpp_pybind.Edge, arg0: float) -&gt; None\n\n\nweight\nweight(self: ptdalgorithms.ptdalgorithmscpp_pybind.Edge) -&gt; float\n\n\n\n\n\nptdalgorithms.Edge.to()\nto(self: ptdalgorithms.ptdalgorithmscpp_pybind.Edge) -&gt; ptdalgorithms.ptdalgorithmscpp_pybind.Vertex\n\n\n\nptdalgorithms.Edge.update_weight()\nupdate_weight(self: ptdalgorithms.ptdalgorithmscpp_pybind.Edge, arg0: float) -&gt; None\n\n\n\nptdalgorithms.Edge.weight()\nweight(self: ptdalgorithms.ptdalgorithmscpp_pybind.Edge) -&gt; float",
    "crumbs": [
      "Some section",
      "Edge"
    ]
  },
  {
    "objectID": "api/index.html",
    "href": "api/index.html",
    "title": "Function reference",
    "section": "",
    "text": "Some description…\n\n\n\nGraph\n\n\n\nVertex\n\n\n\nEdge",
    "crumbs": [
      "Function reference"
    ]
  },
  {
    "objectID": "api/index.html#some-section",
    "href": "api/index.html#some-section",
    "title": "Function reference",
    "section": "",
    "text": "Some description…\n\n\n\nGraph\n\n\n\nVertex\n\n\n\nEdge",
    "crumbs": [
      "Function reference"
    ]
  },
  {
    "objectID": "api/Vertex.html",
    "href": "api/Vertex.html",
    "title": "Vertex",
    "section": "",
    "text": "ptdalgorithms.Vertex()\n\n\n\n\n\nName\nDescription\n\n\n\n\nadd_edge\nadd_edge(self: ptdalgorithms.ptdalgorithmscpp_pybind.Vertex, to: ptdalgorithms.ptdalgorithmscpp_pybind.Vertex, weight: float) -&gt; None\n\n\nadd_edge_parameterized\nadd_edge_parameterized(self: ptdalgorithms.ptdalgorithmscpp_pybind.Vertex, to: ptdalgorithms.ptdalgorithmscpp_pybind.Vertex, weight: float, edge_state: list[float]) -&gt; None\n\n\nae\nae(self: ptdalgorithms.ptdalgorithmscpp_pybind.Vertex, to: ptdalgorithms.ptdalgorithmscpp_pybind.Vertex, weight: float) -&gt; None\n\n\nedges\nedges(self: ptdalgorithms.ptdalgorithmscpp_pybind.Vertex) -&gt; list[ptdalgorithms::Edge]\n\n\nindex\nindex(self: ptdalgorithms.ptdalgorithmscpp_pybind.Vertex) -&gt; int\n\n\nrate\nrate(self: ptdalgorithms.ptdalgorithmscpp_pybind.Vertex) -&gt; float\n\n\nstate\nstate(self: ptdalgorithms.ptdalgorithmscpp_pybind.Vertex) -&gt; list[int]\n\n\n\n\n\nptdalgorithms.Vertex.add_edge()\nadd_edge(self: ptdalgorithms.ptdalgorithmscpp_pybind.Vertex, to: ptdalgorithms.ptdalgorithmscpp_pybind.Vertex, weight: float) -&gt; None\n//’ Adds an edge between two vertices in the graph //’ //’ @description //’ The graph represents transitions between states as //’ a weighted direction edge between two vertices. //’ //’ @seealso [ptdalgorithms::expected_waiting_time()] //’ @seealso [ptdalgorithms::moments()] //’ @seealso [ptdalgorithms::variance()] //’ @seealso [ptdalgorithms::covariance()] //’ @seealso [ptdalgorithms::graph_update_weights_parameterized()] //’ //’ @param phase_type_vertex_from The vertex that transitions from //’ @param phase_type_vertex_to The vertex that transitions to //’ @param weight The weight of the edge, i.e. the transition rate //’ @param parameterized_edge_state Optional. Associate a numeric vector to an edge, for faster computations of moments when weights are changed. //’ //’ @examples //’ graph &lt;- create_graph(4) //’ vertex_a &lt;- find_or_create_vertex(graph, c(1,2,1,0)) //’ vertex_b &lt;- find_or_create_vertex(graph, c(2,0,1,0)) //’ add_edge(vertex_a, vertex_b, 1.5)\n\n\n\nptdalgorithms.Vertex.add_edge_parameterized()\nadd_edge_parameterized(self: ptdalgorithms.ptdalgorithmscpp_pybind.Vertex, to: ptdalgorithms.ptdalgorithmscpp_pybind.Vertex, weight: float, edge_state: list[float]) -&gt; None\n\n\n\nptdalgorithms.Vertex.ae()\nae(self: ptdalgorithms.ptdalgorithmscpp_pybind.Vertex, to: ptdalgorithms.ptdalgorithmscpp_pybind.Vertex, weight: float) -&gt; None\nAlias for add_edge\n\n\n\nptdalgorithms.Vertex.edges()\nedges(self: ptdalgorithms.ptdalgorithmscpp_pybind.Vertex) -&gt; list[ptdalgorithms::Edge]\n\n\n\nptdalgorithms.Vertex.index()\nindex(self: ptdalgorithms.ptdalgorithmscpp_pybind.Vertex) -&gt; int\n\n\n\nptdalgorithms.Vertex.rate()\nrate(self: ptdalgorithms.ptdalgorithmscpp_pybind.Vertex) -&gt; float\n\n\n\nptdalgorithms.Vertex.state()\nstate(self: ptdalgorithms.ptdalgorithmscpp_pybind.Vertex) -&gt; list[int]",
    "crumbs": [
      "Some section",
      "Vertex"
    ]
  },
  {
    "objectID": "api/Vertex.html#methods",
    "href": "api/Vertex.html#methods",
    "title": "Vertex",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nadd_edge\nadd_edge(self: ptdalgorithms.ptdalgorithmscpp_pybind.Vertex, to: ptdalgorithms.ptdalgorithmscpp_pybind.Vertex, weight: float) -&gt; None\n\n\nadd_edge_parameterized\nadd_edge_parameterized(self: ptdalgorithms.ptdalgorithmscpp_pybind.Vertex, to: ptdalgorithms.ptdalgorithmscpp_pybind.Vertex, weight: float, edge_state: list[float]) -&gt; None\n\n\nae\nae(self: ptdalgorithms.ptdalgorithmscpp_pybind.Vertex, to: ptdalgorithms.ptdalgorithmscpp_pybind.Vertex, weight: float) -&gt; None\n\n\nedges\nedges(self: ptdalgorithms.ptdalgorithmscpp_pybind.Vertex) -&gt; list[ptdalgorithms::Edge]\n\n\nindex\nindex(self: ptdalgorithms.ptdalgorithmscpp_pybind.Vertex) -&gt; int\n\n\nrate\nrate(self: ptdalgorithms.ptdalgorithmscpp_pybind.Vertex) -&gt; float\n\n\nstate\nstate(self: ptdalgorithms.ptdalgorithmscpp_pybind.Vertex) -&gt; list[int]\n\n\n\n\n\nptdalgorithms.Vertex.add_edge()\nadd_edge(self: ptdalgorithms.ptdalgorithmscpp_pybind.Vertex, to: ptdalgorithms.ptdalgorithmscpp_pybind.Vertex, weight: float) -&gt; None\n//’ Adds an edge between two vertices in the graph //’ //’ @description //’ The graph represents transitions between states as //’ a weighted direction edge between two vertices. //’ //’ @seealso [ptdalgorithms::expected_waiting_time()] //’ @seealso [ptdalgorithms::moments()] //’ @seealso [ptdalgorithms::variance()] //’ @seealso [ptdalgorithms::covariance()] //’ @seealso [ptdalgorithms::graph_update_weights_parameterized()] //’ //’ @param phase_type_vertex_from The vertex that transitions from //’ @param phase_type_vertex_to The vertex that transitions to //’ @param weight The weight of the edge, i.e. the transition rate //’ @param parameterized_edge_state Optional. Associate a numeric vector to an edge, for faster computations of moments when weights are changed. //’ //’ @examples //’ graph &lt;- create_graph(4) //’ vertex_a &lt;- find_or_create_vertex(graph, c(1,2,1,0)) //’ vertex_b &lt;- find_or_create_vertex(graph, c(2,0,1,0)) //’ add_edge(vertex_a, vertex_b, 1.5)\n\n\n\nptdalgorithms.Vertex.add_edge_parameterized()\nadd_edge_parameterized(self: ptdalgorithms.ptdalgorithmscpp_pybind.Vertex, to: ptdalgorithms.ptdalgorithmscpp_pybind.Vertex, weight: float, edge_state: list[float]) -&gt; None\n\n\n\nptdalgorithms.Vertex.ae()\nae(self: ptdalgorithms.ptdalgorithmscpp_pybind.Vertex, to: ptdalgorithms.ptdalgorithmscpp_pybind.Vertex, weight: float) -&gt; None\nAlias for add_edge\n\n\n\nptdalgorithms.Vertex.edges()\nedges(self: ptdalgorithms.ptdalgorithmscpp_pybind.Vertex) -&gt; list[ptdalgorithms::Edge]\n\n\n\nptdalgorithms.Vertex.index()\nindex(self: ptdalgorithms.ptdalgorithmscpp_pybind.Vertex) -&gt; int\n\n\n\nptdalgorithms.Vertex.rate()\nrate(self: ptdalgorithms.ptdalgorithmscpp_pybind.Vertex) -&gt; float\n\n\n\nptdalgorithms.Vertex.state()\nstate(self: ptdalgorithms.ptdalgorithmscpp_pybind.Vertex) -&gt; list[int]",
    "crumbs": [
      "Some section",
      "Vertex"
    ]
  },
  {
    "objectID": "examples/R/coalescent-jointprob-R.html",
    "href": "examples/R/coalescent-jointprob-R.html",
    "title": "Joint probability experiment",
    "section": "",
    "text": "library(ggplot2)\nlibrary(viridis)\nlibrary(grid)\nlibrary(gridExtra)\nlibrary(\"IRdisplay\")\nlibrary(repr)\noptions(repr.plot.width=7, repr.plot.height=5)\nR header:\nlibrary(tidyverse)\nlibrary(devtools)\n#remove.packages(\"ptdalgorithms\")\n# devtools::install_github(\"TobiasRoikjer/PtDAlgorithms\")\ndevtools::install_local('../../../PtDAlgorithms', quiet=FALSE)\nlibrary(ptdalgorithms)\n\nSkipping install of 'ptdalgorithms' from a local remote, the SHA1 (1.0.0) has not changed since last install.\n  Use `force = TRUE` to force installation\n#install.packages(\"sets\")\n# library(sets)\n# remove.packages(\"ptdalgorithms\")\n# install.packages(\"remotes\")\n# remotes::install_github(\"Thell/RcppMP\")\n# # GNUMPLIB\n# ./configure --prefix=$CONDA_PREFIX --enable-cxx\n# !export LIBS=\"-L/Users/kmt/miniconda3/envs/phasetype/lib\"\n# !export CPPFLAGS=\"-I/Users/kmt/miniconda3/envs/phasetype/include\"\nRcpp::sourceCpp(\"./cpp/coalescent.cpp\")\n\nusing C++ compiler: ‘clang version 18.1.8’\nusing SDK: ‘MacOSX15.0.sdk’\narm64-apple-darwin20.0.0-clang++ -std=gnu++17 -I\"/Users/kmt/miniconda3/envs/ptd/lib/R/include\" -DNDEBUG   -I\"/Users/kmt/miniconda3/envs/ptd/lib/R/library/Rcpp/include\" -I\"/Users/kmt/PtDAlgorithms/docs/examples/cpp\" -D_FORTIFY_SOURCE=2 -isystem /Users/kmt/miniconda3/envs/ptd/include -mmacosx-version-min=11.0 -mmacosx-version-min=11.0 -I/Users/kmt/miniconda3/envs/ptd/include    -fPIC  -ftree-vectorize -fPIC -fstack-protector-strong -O2 -pipe -stdlib=libc++ -fvisibility-inlines-hidden -fmessage-length=0 -isystem /Users/kmt/miniconda3/envs/ptd/include -fdebug-prefix-map=/Users/runner/miniforge3/conda-bld/r-base-split_1723488724675/work=/usr/local/src/conda/r-base-4.4.1 -fdebug-prefix-map=/Users/kmt/miniconda3/envs/ptd=/usr/local/src/conda-prefix   -c coalescent.cpp -o coalescent.o\nIn file included from coalescent.cpp:2:\nIn file included from /Users/kmt/miniconda3/envs/ptd/include/pybind11/pybind11.h:12:\nIn file included from /Users/kmt/miniconda3/envs/ptd/include/pybind11/detail/class.h:12:\nIn file included from /Users/kmt/miniconda3/envs/ptd/include/pybind11/attr.h:13:\n/Users/kmt/miniconda3/envs/ptd/include/pybind11/detail/common.h:274:10: fatal error: 'Python.h' file not found\n  274 | #include &lt;Python.h&gt;\n      |          ^~~~~~~~~~\n1 error generated.\nmake: *** [/Users/kmt/miniconda3/envs/ptd/lib/R/etc/Makeconf:204: coalescent.o] Error 1\n\n\nERROR: Error in Rcpp::sourceCpp(\"./cpp/coalescent.cpp\"): Error 1 occurred building shared library.\n\nError in Rcpp::sourceCpp(\"./cpp/coalescent.cpp\"): Error 1 occurred building shared library.\nTraceback:\n\n1. Rcpp::sourceCpp(\"./cpp/coalescent.cpp\")\n2. stop(\"Error \", status, \" occurred building shared library.\")\nsource(\"plot_functions.R\")\n# p &lt;- ggplot(data=iris, aes(x = Sepal.Length, y = Sepal.Width)) +\n#       geom_point(aes(color=Species, shape=Species)) + despine\n\n# ggplotly(width=600, height=400)\ntheme_set(theme_bw())\n\ndespine &lt;- theme(panel.border = element_blank(), panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(), axis.line = element_line(colour = \"black\"),\n                text=element_text(size=17)) \n\noptions(repr.plot.width=7, repr.plot.height=5)"
  },
  {
    "objectID": "examples/R/coalescent-jointprob-R.html#make-discrete",
    "href": "examples/R/coalescent-jointprob-R.html#make-discrete",
    "title": "Joint probability experiment",
    "section": "Make discrete",
    "text": "Make discrete\n\nmake_discrete &lt;- function(mutation_graph, mutation_rate) {\n    # Takes a graph for a continuous distribution and turns\n    # it into a descrete one (inplace). Returns a matrix of\n    # rewards for computing marginal moments\n\n    # current nr of states in graph\n    vlength &lt;- vertices_length(mutation_graph)\n\n    # number of fields in state vector (assumes all are the same length)\n    state_vector_length &lt;- length(vertex_at(mutation_graph, 1)$state)\n\n    # list state vector fields to reward at each auxiliary node\n    rewarded_state_vector_indexes &lt;- vector(mode = \"list\", length = state_vector_length)\n\n    # loop all but starting node\n    for (i in 2:vlength) {\n        vertex &lt;- vertex_at(mutation_graph,i)\n        if (vertex$rate &gt; 0) { # not absorbing\n            for (j in 1:length(vertex$state)) {\n                val &lt;- vertex$state[j]\n                if (val &gt; 0) { # only ones we may reward\n                    # add auxilliary node\n                    mutation_vertex &lt;- create_vertex(mutation_graph, rep(0, state_vector_length))\n                    add_edge(mutation_vertex, vertex, 1)\n                    add_edge(vertex, mutation_vertex, mutation_rate*val)\n\n                    rewarded_state_vector_indexes[[mutation_vertex$index]] &lt;- c(rewarded_state_vector_indexes[[j]], j)\n                }\n            }\n        }\n    }\n    # normalize graph\n    weights_were_multiplied_with &lt;- normalize_graph(mutation_graph)\n    print(rewarded_state_vector_indexes)\n\n    # build reward matrix\n    rewards &lt;- matrix(nrow=vertices_length(mutation_graph),ncol=state_vector_length, 0)\n    for (state in seq_along(rewarded_state_vector_indexes)) {\n        for (i in rewarded_state_vector_indexes[[state]]) {\n            rewards[state, i] &lt;- 1\n        }\n    }\n    rewards = t(rewards)\n    return(rewards)\n}\n\n# self-transition rate:\nmutation_rate &lt;- 1e-8\n\ngraph  &lt;- standard_coalescent(4)\n\n# clone graph to get one to modify:\nmutation_graph &lt;- clone_graph(graph)\n\n# add auxilliary states, normalize and return reward matrix:\nrewards &lt;- make_discrete(mutation_graph, mutation_rate)\nrewards\n# # for plotting the new graph\n# gam &lt;- graph_as_matrix(mutation_graph)\n\n[[1]]\nNULL\n\n[[2]]\nNULL\n\n[[3]]\nNULL\n\n[[4]]\nNULL\n\n[[5]]\nNULL\n\n[[6]]\nNULL\n\n[[7]]\n[1] 1\n\n[[8]]\n[1] 1\n\n[[9]]\n[1] 2\n\n[[10]]\n[1] 2\n\n[[11]]\n[1] 1\n\n[[12]]\n[1] 3\n\n\n\n\nA matrix: 4 × 12 of type dbl\n\n\n0\n0\n0\n0\n0\n0\n1\n1\n0\n0\n1\n0\n\n\n0\n0\n0\n0\n0\n0\n0\n0\n1\n1\n0\n0\n\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0"
  },
  {
    "objectID": "examples/R/coalescent-jointprob-R.html#coalescent",
    "href": "examples/R/coalescent-jointprob-R.html#coalescent",
    "title": "Joint probability experiment",
    "section": "Coalescent",
    "text": "Coalescent\n\nstandard_coalescent &lt;- function(n) {\n    \n    # n &lt;- 4\n      \n    # state_vector_length &lt;- n + 1    ## + 1 needed to keep it from dumping ##################\n    state_vector_length &lt;- n \n\n    graph &lt;- create_graph(state_vector_length)\n    starting_vertex &lt;- vertex_at(graph, 1)\n\n    # initial_state &lt;- c(rep(0, n), 0)\n    initial_state &lt;- rep(0, state_vector_length)\n\n    initial_state[1] &lt;- n\n    \n    add_edge(\n      starting_vertex,\n      find_or_create_vertex(graph, initial_state),\n      1\n    )\n    index &lt;- 2\n    \n    while (index &lt;= vertices_length(graph)) {\n      vertex &lt;- vertex_at(graph, index)\n      \n      # loop over all classes of lineages\n      for (i in 1:n) {\n        for (j in i:n) {\n          state &lt;- vertex$state\n          \n          # if same class, there need to be at least two to coalesce\n          if (i == j) {\n            if (state[i] &lt; 2) {\n              next;\n            }\n            # coal rate\n            rate &lt;- state[i] * (state[i] - 1) / 2\n          } else {\n            # else at least one in each class to coalesce\n            if (state[i] &lt; 1 || state[j] &lt; 1) {\n              next;\n            }\n            # number of combinations\n            rate &lt;- state[i] * state[j]\n          }\n          \n          # copy state\n          child_state &lt;- state\n          # update child state\n          child_state[i] &lt;- child_state[i] - 1\n          child_state[j] &lt;- child_state[j] - 1\n          child_state[i+j] &lt;- child_state[i+j] + 1\n\n          add_edge(\n              vertex,\n              find_or_create_vertex(graph, child_state),\n              rate, c(rate)\n            )\n        }\n      }\n          \n      index &lt;- index + 1\n    }\n    return(graph)\n}\n# sample_size &lt;- 4\n# graph &lt;- standard_coalescent(sample_size)\n\n# for (i in 1:vertices_length(graph)) {\n#     state &lt;- vertex_at(graph, i)$state\n#     print(state)\n#     print(find_vertex(graph, state))\n# }\n\n# expectation(graph)\n\n# states &lt;- t(sapply(1:vertices_length(graph), function(index) vertex_at(graph, index)$state ))\n# ipv &lt;- graph_as_matrix(graph)$IPV\n# sim &lt;- graph_as_matrix(graph)$SIM\n\n\nsample_size &lt;- 4\ngraph &lt;- standard_coalescent(sample_size)\n\n\ngam &lt;- graph_as_matrix(graph)\ngam\n\n\n    $states\n        \n\nA matrix: 4 × 4 of type dbl\n\n\n4\n0\n0\n0\n\n\n2\n1\n0\n0\n\n\n0\n2\n0\n0\n\n\n1\n0\n1\n0\n\n\n\n\n\n    $SIM\n        \n\nA matrix: 4 × 4 of type dbl\n\n\n-6\n6\n0\n0\n\n\n0\n-3\n1\n2\n\n\n0\n0\n-1\n0\n\n\n0\n0\n0\n-1\n\n\n\n\n\n    $IPV\n        \n1000\n\n    $indices\n        \n2345\n\n\n\n\n\nif (vertices_length(graph) &lt; 30) {    \n    plot_graph(gam, size=c(10, 10), align=TRUE, #rainbow=TRUE,\n               fontsize=16, ranksep=2, nodesep=0.5, rankdir=\"LR\",\n               subgraphs=TRUE, subgraphfun=function(state, index) paste(state[1:sample_size], collapse=\"\"),\n               splines='line'\n    )\n}\n\nERROR: Error in plot_graph(gam, size = c(10, 10), align = TRUE, fontsize = 16, : could not find function \"plot_graph\"\n\nError in plot_graph(gam, size = c(10, 10), align = TRUE, fontsize = 16, : could not find function \"plot_graph\"\nTraceback:\n\n\n\ncoalescent_reward_rates &lt;- function(new_state, current_rewards, mutation_rate, reward_limit, tot_reward_limit)\n{    \n    reward_limits &lt;- c(rep(reward_limit, length(new_state)-1), 0)\n    \n    reward_dims &lt;- length(reward_limits)\n    if (is.null(current_rewards))\n        current_rewards &lt;- rep(0, reward_dims)\n\n    result &lt;- rep(0, reward_dims)\n    trash_rate &lt;- 0\n    \n    for (i in 1:reward_dims) {\n        rate &lt;- new_state[i] * mutation_rate \n        r &lt;- rep(0, reward_dims)\n        r[i] &lt;- 1\n        if ( all(current_rewards + r &lt;= reward_limits) && sum(current_rewards + r) &lt;= tot_reward_limit) {\n            result[i] &lt;- rate\n        } else {\n            trash_rate &lt;- trash_rate + rate\n        }\n    }     \n    return(c(result, trash_rate))\n}\n\nreward_rates &lt;- partial(coalescent_reward_rates, mutation_rate=1, reward_limit=1, tot_reward_limit=2)\n# reward_rates &lt;- partial(coalescent_reward_rates, mutation_rate=1, reward_limit=20, tot_reward_limit=Inf)\n\nstart &lt;- proc.time()[3]\njoint_probs &lt;- discrete_joint_prob(graph, reward_rates)\nproc.time()[3] - start\n\nhead(joint_probs)\n\n[1]  6.000000 28.000000  4.666667\n\n\nelapsed: 0.0799999999999272\n\n\n\nA data.frame: 6 × 5\n\n\n\nV1\nV2\nV3\nV4\naccum_time\n\n\n\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;dbl&gt;\n\n\n\n\n1\n0\n0\n0\n0\n0.10000000\n\n\n2\n0\n1\n0\n0\n0.03888889\n\n\n3\n1\n0\n0\n0\n0.09555556\n\n\n4\n0\n0\n1\n0\n0.02222222\n\n\n5\n1\n0\n1\n0\n0.03111111\n\n\n6\n1\n1\n0\n0\n0.03777778\n\n\n\n\n\n\nwith_deficit &lt;- c(sum(joint_probs$V1 * joint_probs$accum_time), \n  sum(joint_probs$V2 * joint_probs$accum_time), \n  sum(joint_probs$V3 * joint_probs$accum_time))\nwith_deficit\n(c(2, 1, 2/3) - with_deficit) / c(2, 1, 2/3)\n\n\n0.1644444444444340.08037037037036430.0570370370370341\n\n\n\n0.9177777777777830.9196296296296360.914444444444449\n\n\n\nnew_graph &lt;- discrete_joint_prob(graph, reward_rates, return_graph=TRUE)\nnew_gam &lt;- graph_as_matrix(new_graph)\n\nif (vertices_length(new_graph) &lt; 30) {    \n    plot_graph(new_gam, size=c(10, 10), align=TRUE, #rainbow=TRUE,\n               fontsize=16, ranksep=2, nodesep=0.5, rankdir=\"LR\",\n               subgraphs=TRUE, subgraphfun=function(state, index) paste(state[1:sample_size], collapse=\"\"),\n               splines='line'\n    )\n}\n\nERROR: Error in plot_graph(new_gam, size = c(10, 10), align = TRUE, fontsize = 16, : could not find function \"plot_graph\"\n\nError in plot_graph(new_gam, size = c(10, 10), align = TRUE, fontsize = 16, : could not find function \"plot_graph\"\nTraceback:\n\n\n\n# new_graph &lt;- discrete_joint_prob(graph, reward_rates, return_graph=TRUE)\n# start &lt;- proc.time()[3]\n# prev &lt;- 0\n# for (i in 1:10) {\n#     accum_time &lt;- accumulated_visiting_time(new_graph, 10*i)\n    \n#     if (all(abs(accum_time-prev)[1:10] &lt; 10e-15))\n#         break\n\n#     prev &lt;- accum_time\n# }\n# proc.time()[3] - start\n\n\njoint_probs %&gt;% filter(V1==1, V2==0, V3==1) \n\n\nA data.frame: 1 × 5\n\n\nV1\nV2\nV3\nV4\naccum_time\n\n\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;dbl&gt;\n\n\n\n\n1\n0\n1\n0\n0.03111111\n\n\n\n\n\nWith sample_size &lt;- 4, mutation_rate &lt;- 1, reward_limits &lt;- rep(20, sample_size-1), and tot_reward_limit &lt;- Inf, tothe marginal probabilities match the SFS:\nc(sum(joint_probs$V1 * joint_probs$accum_time), \n  sum(joint_probs$V2 * joint_probs$accum_time), \n  sum(joint_probs$V3 * joint_probs$accum_time))\n1.99981743759578 0.998152771395828 0.666638375487117\nand the joint prob of a singleton and a trippleton is:\n1   0   1   0.03111111\nwhich is exactly what we also get with reward_limits &lt;- rep(1, sample_size-1).\nSetting tot_reward_limit &lt;- 2 also produces 0.03111111.\n\njoint_probs %&gt;% rename_with(gsub, pattern=\"V\", replacement=\"ton\") %&gt;% group_by(ton1, ton2) %&gt;% summarize(prob=sum(accum_time), .groups=\"keep\")\n\n\nA grouped_df: 4 × 3\n\n\nton1\nton2\nprob\n\n\n&lt;int&gt;\n&lt;int&gt;\n&lt;dbl&gt;\n\n\n\n\n0\n0\n0.12222222\n\n\n0\n1\n0.04259259\n\n\n1\n0\n0.12666667\n\n\n1\n1\n0.03777778\n\n\n\n\n\n\nplot_df &lt;- joint_probs %&gt;% \n    rename_with(gsub, pattern=\"V\", replacement=\"ton\") %&gt;% \n    group_by(ton1, ton2) %&gt;% \n    summarize(prob=sum(accum_time), .groups=\"keep\")\n\nfor (colname in colnames(plot_df)) {\n    if (startsWith(colname, 'ton')) {\n        plot_df[[colname]] &lt;- as.factor(plot_df[[colname]])\n    }\n}\n\nggplot(plot_df, aes(x=ton1, y=ton2)) +\n    geom_tile(aes(fill = prob)) + \n    geom_text(aes(label = round(prob, 3))) +\n    scale_fill_viridis() +\n    # scale_fill_distiller(palette = 'PiYG',direction = 1,\n    #                 limit=max(abs(plot_df$prob)) * c(-1, 1)\n    #                 ) +\n    theme_minimal() +\n     theme(panel.grid.major = element_blank(), \n            panel.grid.minor = element_blank(), \n            text=element_text(size=17))\n\n\n\n\n\n\n\n\n\n# map_state &lt;- function(state) {\n#         lumped_state &lt;- c(sum(state[1:sample_size]), head(state, sample_size) * (reward_limits - tail(state, sample_size)))\n#         lumped_state &lt;- as.integer(lumped_state)\n#         return(lumped_state)\n# }\n# label_fun &lt;- function(state, index) {\n#     return(paste(map_state(state), collapse=\"\"))\n# }\n\n# if (vertices_length(graph) &lt; 30) {    \n#     new_graph &lt;- discrete_joint_prob(graph, reward_rates, return_graph=TRUE)\n\n#     plot_graph(graph_as_matrix(new_graph), size=c(10, 10), align=TRUE, #rainbow=TRUE,\n#                    fontsize=26, ranksep=4, nodesep=0.9, rankdir=\"LR\",\n#               subgraphs=TRUE, subgraphfun=label_fun,\n#               # subgraphs=TRUE, subgraphfun=function(state, index) sum(head(state, sample_size)),\n#             splines='line'\n#               )  \n# }           \n\n\ngraph_vec &lt;- c()\nnew_graph_vec &lt;- c()\nsample_sizes &lt;- 4:15\nfor (sample_size in sample_sizes) {\n    graph &lt;- standard_coalescent(sample_size)\n    graph_vec &lt;- c(graph_vec, vertices_length(graph))\n    reward_limits &lt;- c(rep(1, sample_size-1), 0)\n    tot_reward_limit &lt;- Inf\n    new_graph &lt;- discrete_joint_prob(graph, reward_rates, return_graph=TRUE)\n    # new_graph &lt;- discrete_joint_prob(graph, reward_limits, mutation_rate, reward_possible, tot_reward_limit=tot_reward_limit, return_graph=TRUE)\n    new_graph_vec &lt;- c(new_graph_vec, vertices_length(new_graph))\n    # new_graph_vec &lt;- c(new_graph_vec, length(unique(apply(apply(states(new_graph), 1, map_state), 2, paste, collapse=\"\"))))\n}\n\n1000 1311 \n1000 1443 \n2000 2178 \n1000 1579 \n2000 2687 \n3000 3185 \n1000 1656 \n2000 2979 \n3000 3930 \n4000 4451 \n\n\n\ntheme_set(theme_bw() + theme(axis.line = element_line(colour = \"black\"),\n                 text=element_text(size=17),\n                 axis.text = element_text(size=15),\n                 plot.margin = unit(c(0.3,0.1,0.1,0.1), \"inch\")))\npalette &lt;- c(\"#888888\", \"#E69F00\", \"#56B4E9\", \"#009E73\", \"#F0E442\", \"#0072B2\", \"#D55E00\", \"#CC79A7\")\nopt &lt;- options(repr.plot.width=7, repr.plot.height=5,\n               ggplot2.discrete.colour=palette, ggplot2.discrete.fill=palette) ;\ndespine &lt;-  theme(panel.border = element_blank(), \n                 panel.grid.major = element_blank(),\n                 panel.grid.minor = element_blank())\n\nlibrary(gridExtra)\ndf &lt;- data.frame(\n  samples = sample_sizes,\n  graph_states = graph_vec,\n  new_graph_states =new_graph_vec\n)\ndf_long &lt;- pivot_longer(df, c(graph_states, new_graph_states))\np1 &lt;- ggplot(df_long, aes(x=samples, y=value, color=name)) +\n    geom_line(linewidth=1) + geom_point(size=3) + \n    despine +\n    xlim(0, NA) + ylim(0, NA) +\n    labs(x=\"Sample size\", y=\"Vertices\", color=\"Graph\") +\n    scale_color_discrete(labels = c(\"Original\", \"Augmented\"))\np2 &lt;- ggplot(df, aes(x=samples, y=new_graph_vec / graph_vec)) + \n    geom_line(linewidth=1) + geom_point(size=3) + \n    geom_abline(slope=1, intercept=0) +\n    # geom_abline(slope=0.25, intercept=1.5) +\n    despine +\n    xlim(0, NA) + ylim(0, NA) +\n    labs(x=\"Sample size\", y=\"Augmented / original vertices\", color=\"Graph\")\n\nopt &lt;- options(repr.plot.width=12, repr.plot.height=5.5)\ngrid.arrange(p1, p2, nrow = 1, widths = 3:2)\noptions(opt) ;\n\n\n\n\n\n\n\n\n\n# nr_states_vec &lt;- c()\n# nr_lumped_states_vec &lt;- c()\n# sample_sizes &lt;- 4:10\n# for (sample_size in sample_sizes) {\n#     graph &lt;- standard_coalescent(sample_size)\n#     state_length &lt;- length(vertex_at(graph, 1)$state)\n#     # last state index is absorbing where no rewards can be earned\n#     reward_limits &lt;- c(rep(1, state_length-1), 0)    \n#     new_graph &lt;- discrete_joint_prob(graph, reward_rates, return_graph=TRUE)\n#     # new_graph &lt;- discrete_joint_prob(graph, reward_limits, mutation_rate, reward_possible, return_graph=TRUE)\n#     nr_states_vec &lt;- c(nr_states_vec, vertices_length(new_graph))\n#     nr_lumped_states_vec &lt;- c(nr_lumped_states_vec, length(unique(apply(apply(states(new_graph), 1, map_state), 2, paste, collapse=\"\"))))\n# }\n# df &lt;- data.frame(\n#   samples = sample_sizes,\n#   nr_states = nr_states_vec,\n#   nr_lumped_states =nr_lumped_states_vec\n# )\n# df_long &lt;- pivot_longer(df, c(nr_states, nr_lumped_states))\n# ggplot(df_long, aes(x=samples, y=value, hue=name)) + geom_line() + geom_point()"
  },
  {
    "objectID": "examples/R/coalescent-jointprob-R.html#two-locus-arg",
    "href": "examples/R/coalescent-jointprob-R.html#two-locus-arg",
    "title": "Joint probability experiment",
    "section": "Two-locus ARG",
    "text": "Two-locus ARG\n\nRcpp::sourceCpp(\"./cpp/index_prop_mapping.cpp\")\n\ntwo_locus_arg &lt;- function(s, N, R) {\n\n    # state vector length\n    n &lt;- (s+1)**2\n\n    graph &lt;- create_graph(n)\n    index &lt;- 1\n    # first_vertex &lt;- create_vertex(graph, c(rep(0, s+2), s, rep(0, n-s-3))) # assumes that p=2\n    state &lt;- rep(0, n)\n    state[props_to_index_two_locus(s, 1, 1, 1)] &lt;- s\n    first_vertex &lt;- find_or_create_vertex(graph, state) # assumes that p=2\n    add_edge(starting_vertex(graph), first_vertex, 1)\n\n    index &lt;- 2\n    while (index &lt;= vertices_length(graph)) {\n\n      vertex &lt;- vertex_at(graph, index)\n      state &lt;- vertex$state\n\n      count &lt;- 0\n      for (i in 1:n) {\n          count &lt;- count + state[i]\n      }\n      if (count &lt;= 1) {\n          # Only one lineage, stop\n          index &lt;- index + 1\n          next\n      }    \n\n      for (i in 1:n) {\n        if (state[i] == 0) next\n\n        conf_i &lt;- index_to_props_two_locus(s, i)\n\n        # coalescence #########################\n        for (j in i:n) {\n          if (state[j] == 0) next\n            \n          conf_j &lt;- index_to_props_two_locus(s, j)\n\n          if (i == j) {\n            if (state[i] &lt; 2) {\n              next;\n            }\n            rate &lt;- state[i] * (state[i] - 1) / 2 / N\n          } else {\n            if (state[i] &lt; 1 || state[j] &lt; 1) {\n              next;\n            }\n            rate &lt;- state[i] * state[j] / N\n          }\n\n          child_state &lt;- state\n        \n          # lineages with index i and j coalesce:  \n          child_state[i] &lt;- child_state[i] - 1\n          child_state[j] &lt;- child_state[j] - 1\n          stopifnot(conf_i$descendants_l1+conf_j$descendants_l1 &lt;= s)\n          stopifnot(conf_i$descendants_l2+conf_j$descendants_l2 &lt;= s)\n\n          # coalescene into lineage with index k\n          k = props_to_index_two_locus(s, conf_i$descendants_l1+conf_j$descendants_l1, conf_i$descendants_l2+conf_j$descendants_l2)\n          child_state[k] &lt;- child_state[k] + 1\n\n          child_vertex &lt;- find_or_create_vertex(graph, child_state)\n          add_edge(vertex, child_vertex, rate)\n\n        }\n        \n\n        # recombination #######################\n        if (state[i] &gt; 0 && conf_i$descendants_l1 &gt; 0 && conf_i$descendants_l2 &gt; 0) {\n\n          # TODO: make sure this should not be R * state[i]\n          rate &lt;- R #* state[i] \n          child_state &lt;- state\n\n          # a lineage with index i recombines to produce lineages with index k and l\n          k = props_to_index_two_locus(s, conf_i$descendants_l1, 0)\n          l = props_to_index_two_locus(s, 0, conf_i$descendants_l2)\n          child_state[i] &lt;- child_state[i] - 1\n          child_state[k] &lt;- child_state[k] + 1\n          child_state[l] &lt;- child_state[l] + 1\n            \n          child_vertex &lt;- find_or_create_vertex(graph, child_state)\n          add_edge(vertex, child_vertex, rate)\n        }\n\n      }\n\n      index &lt;- index + 1\n\n      # if ((index %% 50) == 0) {\n      #   cat(index, vertices_length(graph), \"\\n\")\n      # }\n\n    }\n    \n    return(graph)\n}\n\n\narg_reward_rates &lt;- function(new_state, current_rewards, mutation_rate, reward_limit, locus_ton_reward_limit)\n{    \n    reward_limits &lt;- c(rep(reward_limit, length(new_state)-1), 0)\n    reward_limits &lt;- c(reward_limits, reward_limits) # duplicate to account for separate mutations at each locus\n\n    reward_dims &lt;- length(reward_limits)\n    if (is.null(current_rewards))\n        current_rewards &lt;- rep(0, reward_dims)\n\n# allowed_l1 &lt;- sapply(1:(reward_dims %/% 2), function(i) index_to_props_two_locus(sample_size, i)$descendants_l1 &gt; 0)\n# allowed_l2 &lt;- sapply((reward_dims %/% 2 + 1):reward_dims, function(i) index_to_props_two_locus(sample_size, i)$descendants_l2 &gt; 0)                   \n# allowed_mask &lt;- as.integer(c(allowed_l1, allowed_l2))\n    \n    result &lt;- rep(0, reward_dims)\n    trash_rate &lt;- 0\n                           \n    for (i in 1:reward_dims) {\n        rate &lt;- new_state[(i-1) %% (reward_dims %/% 2) + 1] * mutation_rate # fancy index to map state index to duplicted reward index\n        r &lt;- rep(0, reward_dims)\n        r[i] &lt;- 1\n        proposed_rewards &lt;- current_rewards + r\n        \n        if ( all(proposed_rewards &lt;= reward_limits) && \n            sum(head(proposed_rewards, reward_dims %/% 2)) &lt;= locus_ton_reward_limit && \n            sum(tail(proposed_rewards, reward_dims %/% 2)) &lt;= locus_ton_reward_limit ) {\n            result[i] &lt;- rate\n        } else {\n            trash_rate &lt;- trash_rate + rate\n        }\n    }     \n    return(c(result, trash_rate))\n}\n\nsample_size &lt;- 4\ngraph &lt;- two_locus_arg(sample_size, 1, 1)\nvertices_length(graph)\n\n110\n\n\n\nreward_rates &lt;- partial(arg_reward_rates, mutation_rate=1, reward_limit=1, locus_ton_reward_limit=1)\n\nstart &lt;- proc.time()[3]\njoint_probs &lt;- discrete_joint_prob(graph, reward_rates)\nproc.time()[3] - start\n\ntail(joint_probs)\n\n1000 3020 \n2000 4887 \n3000 6721 \n4000 8038 \n5000 9302 \n6000 10563 \n7000 11123 \n8000 11872 \n9000 12493 \n10000 13150 \n11000 13551 \n12000 13976 \n13000 14322 \n14000 14526 \n[1]   110.0000 14593.0000   132.6636\n\n\nelapsed: 30.2719999999999\n\n\n\nA data.frame: 6 × 51\n\n\n\nV1\nV2\nV3\nV4\nV5\nV6\nV7\nV8\nV9\nV10\n⋯\nV42\nV43\nV44\nV45\nV46\nV47\nV48\nV49\nV50\naccum_time\n\n\n\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n⋯\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;dbl&gt;\n\n\n\n\n539\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n⋯\n0\n0\n0\n0\n0\n0\n0\n0\n0\n5.350590e-08\n\n\n540\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n⋯\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1.670565e-07\n\n\n541\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n⋯\n0\n0\n0\n0\n0\n0\n0\n0\n0\n5.778167e-09\n\n\n542\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n⋯\n0\n0\n0\n0\n0\n0\n0\n0\n0\n5.778167e-09\n\n\n543\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n⋯\n0\n0\n0\n0\n0\n0\n0\n0\n0\n5.778167e-09\n\n\n544\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n⋯\n0\n0\n0\n0\n0\n0\n1\n0\n0\n5.778167e-09\n\n\n\n\n\n\n\n# sample_size &lt;- 3\n# graph &lt;- two_locus_arg(sample_size, 1, 1)\n\n# # plot_graph(graph_as_matrix(graph), size=c(10, 10), align=TRUE, rainbow=TRUE,\n# #                fontsize=16, ranksep=2, nodesep=0.5,\n# #           subgraphs=TRUE,         \n# #            subgraphfun=function(state, index) paste(state[1:sample_size], collapse=\"\"))  \n\n# state_length &lt;- length(vertex_at(graph, 1)$state)\n# reward_limits &lt;- list()\n# for (i in 1:state_length) {\n#     prop_i &lt;- index_to_props_two_locus(sample_size, i)\n#     if (prop_i$descendants_l1 == sample_size && prop_i$descendants_l2 == sample_size) {\n#         # absorbing state has no reward\n#         next\n#     }\n#     if (prop_i$descendants_l1 &gt; 0 && prop_i$descendants_l2 &gt; 0) {\n#         r &lt;- rep(0, state_length)\n#         r[i] &lt;- 1\n#         # cat(prop_i$descendants_l1, \" \", prop_i$descendants_l2, \" \", r, \"\\n\")\n#         reward_limits &lt;- c(reward_limits,  list(r))\n#         next\n#     }\n#     for (j in i:state_length) {\n#         prop_j &lt;- index_to_props_two_locus(sample_size, j)\n#         if (prop_j$descendants_l1 &gt; 0 && prop_j$descendants_l2 &gt; 0) {\n#             next\n#         }        \n#         r &lt;- rep(0, state_length)\n#         if ((prop_i$descendants_l1 &gt; 0 && prop_j$descendants_l2 &gt; 0) || (prop_j$descendants_l1 &gt; 0 && prop_i$descendants_l2 &gt; 0)) {\n#             r[i] &lt;- 1\n#             r[j] &lt;- 1\n#             reward_limits &lt;- c(reward_limits, list(r))\n#             # cat(prop_i$descendants_l1, \" \", prop_i$descendants_l2, \" \", prop_j$descendants_l1, \" \", prop_j$descendants_l2, \" \", r, \"\\n\")            \n#         }\n#     }\n# }\n\n# tot_reward_limit &lt;- Inf\n\n# mutation_rate &lt;- 1\n\n# reward_possible &lt;- function(state, rewards) {\n#     max_nrs_descendants &lt;- function(state) {\n#        l1 &lt;- 0\n#        l2 &lt;- 0\n#        for (i in 1:length(state)) {\n#            if (state[i] &gt; 0) {\n#                props &lt;- index_to_props_two_locus(sample_size, i) # SAMPLE SIZE SHOULD NOT BE A GLOBAL HERE...\n#                l1 &lt;- max(c(l1, props$descendants_l1))\n#                l2 &lt;- max(c(l2, props$descendants_l2))\n#            }\n#         }\n#        return(c(l1, l2))\n#     }\n#     return (all(max_nrs_descendants(rewards) &lt;= max_nrs_descendants(state)))\n# }\n\n\n# #reward_limits\n# #reward_limits &lt;- reward_limits[[1]]\n# state_length &lt;- length(vertex_at(graph, 1)$state)\n# # last state index is absorbing where no rewards can be earned\n# reward_limits &lt;- c(rep(1, state_length-1), 0)\n\n# start &lt;- proc.time()[3]\n# joint_probs &lt;- discrete_joint_prob(graph, reward_limits, mutation_rate, reward_possible, tot_reward_limit=tot_reward_limit)\n# proc.time()[3] - start\n# tail(joint_probs)                                \n\n\nstate_length &lt;- ncol(joint_probs) - 1\n\nmat &lt;- joint_probs %&gt;% select(starts_with('V')) %&gt;% as.matrix\n\nfun &lt;- function(x, marg_ton, sample_size) {\n     any(sapply((1:state_length)[which(x==1)], function(i) index_to_props_two_locus(sample_size, i)$descendants_l1 == marg_ton))\n}\nfor (marg_ton in 1:sample_size) {               \n    mask &lt;- apply(mat, 1, fun, marg_ton=marg_ton, sample_size=sample_size)\n    print( sum(joint_probs$accum_time[mask]) )\n}\n\n[1] 0.04359551\n[1] 0.018509\n[1] 0.009337695\n[1] 0.00101796\n\n\n\nfun &lt;- function(name, sample_size) {\n     f &lt;- function(name, sample_size) {\n        if (!startsWith(name, \"V\"))\n            return(name)\n        idx &lt;- as.integer(gsub('V', '', name))\n        props &lt;- index_to_props_two_locus(sample_size, idx)\n        # new_name &lt;- paste(c(\"(\", props$descendants_l1, \", \", props$descendants_l2, \")\"), collapse=\"\")\n        new_name &lt;- paste(c(\"ton\", props$descendants_l1, \"x\", props$descendants_l2, \"_\", props$population, props$population), collapse=\"\")\n        return(new_name)\n        }\n    sapply(name, f, sample_size=sample_size)\n}    \n\ndf &lt;- joint_probs %&gt;% \n    # rename_with(gsub, pattern=\"V\", replacement=\"ton\") %&gt;% \n    rename_with(fun, sample_size=sample_size)\n\nhead(df)\n\ntonnames &lt;- df %&gt;% select(!accum_time) %&gt;% names() %&gt;% str_extract(\"^ton[:digit:]x[:digit:]\") %&gt;% unique()\nl &lt;- map(tonnames, function (n) rowSums(select(df, ends_with(n))))\nplot_df &lt;- as.data.frame(do.call(cbind, l))\ncolnames(plot_df) &lt;- tonnames\nplot_df['accum_time'] &lt;- df['accum_time']\nhead(plot_df)         \n\n\nA data.frame: 6 × 51\n\n\n\nton0x0_11\nton1x0_11\nton2x0_11\nton3x0_11\nton4x0_11\nton0x1_11\nton1x1_11\nton2x1_11\nton3x1_11\nton4x1_11\n⋯\nton1x3_22\nton2x3_22\nton3x3_22\nton4x3_22\nton0x4_22\nton1x4_22\nton2x4_22\nton3x4_22\nton4x4_22\naccum_time\n\n\n\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n⋯\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;dbl&gt;\n\n\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n⋯\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0.020014967\n\n\n2\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n⋯\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0.004216329\n\n\n3\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n⋯\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0.004216329\n\n\n4\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n⋯\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0.011198623\n\n\n5\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n⋯\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0.001859383\n\n\n6\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n⋯\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0.011198623\n\n\n\n\n\n\nA data.frame: 6 × 26\n\n\n\nton0x0\nton1x0\nton2x0\nton3x0\nton4x0\nton0x1\nton1x1\nton2x1\nton3x1\nton4x1\n⋯\nton1x3\nton2x3\nton3x3\nton4x3\nton0x4\nton1x4\nton2x4\nton3x4\nton4x4\naccum_time\n\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n⋯\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n⋯\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0.020014967\n\n\n2\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n⋯\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0.004216329\n\n\n3\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n⋯\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0.004216329\n\n\n4\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n⋯\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0.011198623\n\n\n5\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n⋯\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0.001859383\n\n\n6\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n⋯\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0.011198623\n\n\n\n\n\n\n# plot_df &lt;- joint_probs %&gt;% \n#     # rename_with(gsub, pattern=\"V\", replacement=\"ton\") %&gt;% \n#     rename_with(fun, sample_size=sample_size) %&gt;%\n#     group_by(ton0x1, ton1x0) %&gt;% \n#     summarize(prob=sum(accum_time), .groups=\"keep\")\n\n# for (colname in colnames(plot_df)) {\n#     # if (startsWith(colname, 'ton')) {\n#     if (colname != 'prob') {\n#         plot_df[[colname]] &lt;- as.factor(plot_df[[colname]])\n#     }\n# }\n# plot_df\n\n\nggplot(plot_df, aes(x=ton0x1, y=ton1x0)) +\n    geom_tile(aes(fill = accum_time)) + \n    geom_text(aes(label = round(accum_time, 3))) +\n    scale_fill_viridis() +\n    # scale_fill_distiller(palette = 'PiYG',direction = 1,\n    #                 limit=max(abs(plot_df$prob)) * c(-1, 1)\n    #                 ) +\n    theme_minimal() +\n     theme(panel.grid.major = element_blank(), \n            panel.grid.minor = element_blank(), \n            text=element_text(size=17))\n\n\n\n\n\n\n\n\n\nget_exp_mat &lt;- function(graph, rewards, s) \n{\n    exp_mat &lt;- matrix(nrow=s+1,ncol=s+1)\n    for (i in 0:s) {\n      for (j in 0:s) {\n        exp_mat[i+1,j+1] &lt;- expectation(graph, rewards[props_to_index_two_locus(s, i, j), ])\n      }\n    } \n    return(exp_mat)\n}\n                 \nplot_exp_mat &lt;- function(exp_mat, title=\"Expectations\") \n{  \n    df &lt;- as.data.frame(exp_mat) #%&gt;% gather()\n    df &lt;- df %&gt;% rownames_to_column('ton1') %&gt;% gather('ton2', 'value', -c(ton1))\n\n    limit &lt;- max(abs(df$value)) * c(-1, 1)\n    \n    ggplot(df, aes(ton1, ton2)) +\n        geom_tile(aes(fill = value)) + \n        geom_text(aes(label = round(value, 2)), size=5) +\n        ggtitle(title) +\n    scale_x_discrete(labels= seq(0, nrow(exp_mat))) + \n    scale_y_discrete(labels= seq(0, nrow(exp_mat))) + \n    scale_fill_distiller(palette = 'PiYG',direction = 1, limit=limit) +\n    theme_minimal() +\n     theme(panel.grid.major = element_blank(), \n            panel.grid.minor = element_blank(), \n            text=element_text(size=17))\n\n} \n\nexp_mat &lt;- get_exp_mat(graph, reward_matrix, sample_size)\nnew_exp_mat &lt;- get_exp_mat(new_graph, rbind(0, new_reward_matrix, 0), sample_size)\n\noptions(repr.plot.width = 20, repr.plot.height = 5, repr.plot.res = 100)\n\np1 &lt;- plot_exp_mat(exp_mat, \"Original graph\")    \np2 &lt;- plot_exp_mat(new_exp_mat, \"Lumped graph\")    \np3 &lt;- plot_exp_mat(exp_mat - new_exp_mat, \"Absolute difference\")    \nrel_diff &lt;- (exp_mat - new_exp_mat)/exp_mat\nrel_diff[is.na(rel_diff)] &lt;- 0\np4 &lt;- plot_exp_mat(rel_diff, \"Relative difference\")    \ngrid.arrange(p1, p2, p3, p4, nrow = 1)\n\nERROR: Error in eval(expr, envir, enclos): objekt 'reward_matrix' blev ikke fundet\n\nError in eval(expr, envir, enclos): objekt 'reward_matrix' blev ikke fundet\nTraceback:\n\n1. get_exp_mat(graph, reward_matrix, sample_size)\n2. expectation(graph, rewards[props_to_index_two_locus(s, i, j), \n .     ])   # at line 6 of file &lt;text&gt;"
  },
  {
    "objectID": "examples/R/coalescent-jointprob-R.html#state-space-for-joint-proability-computation",
    "href": "examples/R/coalescent-jointprob-R.html#state-space-for-joint-proability-computation",
    "title": "Joint probability experiment",
    "section": "State space for joint proability computation",
    "text": "State space for joint proability computation\nGenerate coalescent state space like normal with the following modifications\n\nChange state space from (4, 0, 0, 0) to (4, 0, 0, 0, t1, t2, t3, t4). The last extra “ton” states keep track of the number accumulated mutations of each kind. We simply double the state vector so we keep track of the counts lineages with descendants, but also the counts of mutations happened on such lineages.\nEach state can mutate to accumulate a “ton” in accordance with its state vector. E.g., a (4, 0, 0, 0, 0, 0, 0, 0) state can only make singletons, a (2, 1, 0, 0, 0, 0, 0, 0) state can only make singletons and doubletons.\nA mutation event is a transition to a siter state E.g., (4, 0, 0, 0, 0, 0, 0, 0) -&gt; (4, 0, 0, 0, 1, 0, 0, 0)\nThe ton counts have a maximum value (base-1). If this value is reached, the mutation transition instead leads to a trash state with an infinite self loop. The transitions to trash represents the part of the deficient PDF not covered because we only run up to a max nr of tons."
  },
  {
    "objectID": "examples/R/coalescent-jointprob-R.html#reward-transform",
    "href": "examples/R/coalescent-jointprob-R.html#reward-transform",
    "title": "Joint probability experiment",
    "section": "Reward transform",
    "text": "Reward transform\n\nConvert the last half of each state (with ton counts) to numbers in some base.\nUse these for reward transformation.\nCompute PDF for t &lt;- 1:sample_size^(base-1)\nConvert each time t back to the corresponding ton vector and associate it with the probability\ngroup by two tons and sum probs in groups to get all pairwise combinations for a joint probability matrix."
  },
  {
    "objectID": "examples/R/coalescent-jointprob-R.html#figure-out-why-you-get-nas-in-multi_rewards-with-max_tons---1",
    "href": "examples/R/coalescent-jointprob-R.html#figure-out-why-you-get-nas-in-multi_rewards-with-max_tons---1",
    "title": "Joint probability experiment",
    "section": "Figure out why you get NAs in multi_rewards with max_tons <- 1",
    "text": "Figure out why you get NAs in multi_rewards with max_tons &lt;- 1\n\n# joint_prob_coalescent &lt;- function(n, mutation_rate, max_tons, total_tons=Inf) {\n    \n#     state_vector_length &lt;- n + n + 1\n#     graph &lt;- create_graph(state_vector_length)\n#     starting_vertex &lt;- vertex_at(graph, 1)\n#     initial_state &lt;- c(rep(0, n), 0)\n#     initial_state[1] &lt;- n\n    \n#     add_edge(\n#       starting_vertex,\n#       create_vertex(graph, initial_state),\n#       1\n#     )\n#     index &lt;- 2\n\n#     while (index &lt;= vertices_length(graph)) {\n#       vertex &lt;- vertex_at(graph, index)\n\n#       # skip if we only have one lineage left or if this is a trash state\n#       if (sum(vertex$state[1:n]) &lt;= 1) {\n#         index &lt;- index + 1\n#         next\n#       }\n\n#       # mutations\n#       trash_rate &lt;- 0 \n#       for (i in 1:n)  {\n#         state &lt;- vertex$state          \n#         rate &lt;- vertex$state[i] * mutation_rate\n#         nr_tons &lt;- state[n+i]\n#         if (rate &gt; 0) {\n#             if (nr_tons &lt; max_tons && sum(vertex$state[(n+1):(2*n)]) &lt; total_tons) {\n#               child_state &lt;- state\n\n#               mutation_vertex &lt;- create_vertex(graph, rep(0, state_vector_length))\n#               add_edge(vertex, mutation_vertex, rate)\n#               child_state[n+i] &lt;- child_state[i+n] + 1\n#               add_edge(mutation_vertex, find_or_create_vertex(graph, child_state), 1)\n                \n#               # child_state[n+i] &lt;- child_state[i+n] + 1\n#               # add_edge(vertex, find_or_create_vertex(graph, child_state), rate)\n#             } else {\n#               trash_rate &lt;- trash_rate + rate\n#             }\n#         }          \n#       }\n#       if (trash_rate &gt; 0) {\n#         add_edge(vertex, find_or_create_vertex(graph, rep(0, state_vector_length)), trash_rate)\n#       }\n\n#       # loop over all classes of lineages\n#       for (i in 1:n) {\n#         for (j in i:n) {\n#           state &lt;- vertex$state\n          \n#           # if same class, there need to be at least two to coalesce\n#           if (i == j) {\n#             if (state[i] &lt; 2) {\n#               next;\n#             }\n#             # coal rate\n#             rate &lt;- state[i] * (state[i] - 1) / 2\n#           } else {\n#             # else at least one in each class to coalesce\n#             if (state[i] &lt; 1 || state[j] &lt; 1) {\n#               next;\n#             }\n#             # number of combinations\n#             rate &lt;- state[i] * state[j]\n#           }\n          \n#           # copy state\n#           child_state &lt;- state\n#           # update child state\n#           child_state[i] &lt;- child_state[i] - 1\n#           child_state[j] &lt;- child_state[j] - 1\n#           child_state[i+j] &lt;- child_state[i+j] + 1\n\n#           add_edge(\n#               vertex,\n#               find_or_create_vertex(graph, child_state),\n#               rate\n#             )\n#         }\n#       }\n\n#       index &lt;- index + 1\n#     }\n#     trash_vertex &lt;- find_or_create_vertex(graph, rep(0, state_vector_length))\n#     trash_loop_vertex &lt;- create_vertex(graph, rep(0, state_vector_length))\n#     add_edge(trash_vertex, trash_loop_vertex, 1)\n#     add_edge(trash_loop_vertex, trash_vertex, 1)\n    \n#     return(graph)\n# }\n# # states &lt;- t(sapply(1:vertices_length(graph), function(index) vertex_at(graph, index)$state ))\n# # ipv &lt;- graph_as_matrix(graph)$IPV\n# # sim &lt;- graph_as_matrix(graph)$SIM\n\n# # sample_size &lt;- 4\n# # # mutation_rate &lt;- 20000 * 31 * 5e-10 # 0.00031\n# # mutation_rate &lt;- 1\n# # max_tons &lt;- 3\n# # base &lt;- max_tons + 1\n# # # graph &lt;- joint_prob_coalescent(sample_size, mutation_rate, max_tons)\n# # # gam &lt;- graph_as_matrix(graph)\n# # # #gam\n\n# # graph &lt;- joint_prob_coalescent(sample_size, mutation_rate, max_tons, total_tons)\n# # gam &lt;- graph_as_matrix(graph)\n# # plot_graph(gam, #subgraphs=TRUE, \n# #            rainbow=TRUE,\n# #            size=c(10, 8), \n# #            align=TRUE,\n# #            fontsize=16, ranksep=1, nodesep=0.25,          \n# #            # subgraphfun=function(state) paste(state[-length(state)], collapse=\"\")\n# #            )\n\n\n\njoint_prob_coalescent &lt;- function(n, mutation_rate, max_tons, total_tons=Inf) {\n\n    stopifnot(total_tons == Inf)\n    \n    state_vector_length &lt;- n + n + 1\n    graph &lt;- create_graph(state_vector_length)\n    starting_vertex &lt;- vertex_at(graph, 1)\n    initial_state &lt;- c(rep(0, n), 0)\n    initial_state[1] &lt;- n\n    \n    add_edge(\n      starting_vertex,\n      create_vertex(graph, initial_state),\n      1\n    )\n    index &lt;- 2\n\n    while (index &lt;= vertices_length(graph)) {\n      vertex &lt;- vertex_at(graph, index)\n\n      # skip if we only have one lineage left or if this is a trash state\n      if (sum(vertex$state[1:n]) &lt;= 1) {\n        index &lt;- index + 1\n        next\n      }\n        \n      # loop over all classes of lineages\n      for (i in 1:n) {\n        for (j in i:n) {\n          state &lt;- vertex$state\n          \n          # if same class, there need to be at least two to coalesce\n          if (i == j) {\n            if (state[i] &lt; 2) {\n              next;\n            }\n            # coal rate\n            rate &lt;- state[i] * (state[i] - 1) / 2\n          } else {\n            # else at least one in each class to coalesce\n            if (state[i] &lt; 1 || state[j] &lt; 1) {\n              next;\n            }\n            # number of combinations\n            rate &lt;- state[i] * state[j]\n          }\n          \n          # copy state\n          child_state &lt;- state\n          # update child state\n          child_state[i] &lt;- child_state[i] - 1\n          child_state[j] &lt;- child_state[j] - 1\n          child_state[i+j] &lt;- child_state[i+j] + 1\n\n          add_edge(\n              vertex,\n              find_or_create_vertex(graph, child_state),\n              rate\n            )\n        }\n      }\n\n      # mutations\n      trash_rate &lt;- 0 \n      for (i in 1:n)  {\n        rate &lt;- vertex$state[i] * mutation_rate\n        nr_tons &lt;- child_state[n+i]\n        if (rate &gt; 0) {\n            if (nr_tons &lt; max_tons && sum(vertex$state[(n+1):(2*n)]) &lt; total_tons) {\n              child_state &lt;- state\n              child_state[n+i] &lt;- child_state[i+n] + 1\n              add_edge(vertex, find_or_create_vertex(graph, child_state), rate)\n            } else {\n              trash_rate &lt;- trash_rate + rate\n            }\n        }\n      }\n      if (trash_rate &gt; 0) {\n        add_edge(vertex, find_or_create_vertex(graph, rep(0, state_vector_length)), trash_rate)\n      }\n\n      index &lt;- index + 1\n    }\n    trash_vertex &lt;- find_or_create_vertex(graph, rep(0, state_vector_length))\n    trash_loop_vertex &lt;- create_vertex(graph, rep(0, state_vector_length))\n    add_edge(trash_vertex, trash_loop_vertex, 1)\n    add_edge(trash_loop_vertex, trash_vertex, 1)\n    \n    return(graph)\n}\n\n\nndigits &lt;- function(x){\n  y &lt;- floor(abs(x))\n  if(y != 0){\n    floor(log10(y)) + 1\n  } else {\n    1\n  }\n}\nrev_number=function(n){\n    m=as.integer(rev(strsplit(as.character(n),\"\")))\n    if (m==rev(m)) print(\"reversed number\")\n}\nforth &lt;- function(vec, base) {\n    # return( as.integer( c(vec %*%  (base ^ rev(seq_along(vec)) / base)) ) )\n    # return( as.integer( c(vec %*%  (base ^ (seq_along(vec)) / base)) ) )\n    # return( c(vec %*%  (base ^ (rev(seq_along(vec))) / base)) ) \n    return( c(vec %*%  (base ^ (seq_along(vec)) / base)) ) \n}\nback &lt;- function(x, base, state_length) {\n    # x &lt;- as.integer(rev(paste(x, collapse='')))\n    # x &lt;- floor(as.numeric(rev(paste(x, collapse=''))))\n    vec &lt;- c()\n\n    for (i in 1:state_length) {\n        # if (x &gt; 0) {\n            vec &lt;- c(x %% (base), vec)\n            x &lt;- x %/% (base)\n        # }\n    }\n\n    # while (x &gt; 0) {\n    #     vec &lt;- c(x %% (base), vec)\n    #     x &lt;- x %/% (base)\n    # }\n    \n    # for (i in 1:ndigits(x)) {\n    #     if (x &gt; 0) {\n    #         vec &lt;- c(x %% (base), vec)\n    #         x &lt;- x %/% (base)\n    #     }\n    # }\n    vec &lt;- as.integer(vec)\n    return( rev(c(rep(0, state_length-length(vec)), vec) ))\n    # return( c(rep(0, state_length-length(vec)), vec) )\n}\n# vec &lt;- c(1, 2, 0)\n# base &lt;- max(vec)+1\n# state_length &lt;- length(vec)\n# print(vec)\n# f &lt;- forth(vec, base)\n# print(f)\n# b &lt;- back(f, base, state_length)\n# print(b)\n# b &lt;- c(rep(0, length(vec)-length(b)), b)\n# print(b)\n\n\ngraph &lt;- standard_coalescent(sample_size)\ngraph_as_matrix(graph)\n\n\n    $states\n        \n\nA matrix: 4 × 4 of type dbl\n\n\n4\n0\n0\n0\n\n\n2\n1\n0\n0\n\n\n0\n2\n0\n0\n\n\n1\n0\n1\n0\n\n\n\n\n\n    $SIM\n        \n\nA matrix: 4 × 4 of type dbl\n\n\n-6\n6\n0\n0\n\n\n0\n-3\n1\n2\n\n\n0\n0\n-1\n0\n\n\n0\n0\n0\n-1\n\n\n\n\n\n    $IPV\n        \n1000\n\n    $indices\n        \n2345\n\n\n\n\n\nplot_graph(graph_as_matrix(graph), size=c(10, 8), align=TRUE, # rainbow=TRUE,\n               fontsize=16, ranksep=1, nodesep=0.25)\n\n\n\n\n\n\n\n\n\nexpectation(graph)\n\n1.5\n\n\n\nrewards &lt;- make_discrete(graph, 1)\ngraph_as_matrix(graph)\n\n\n    $states\n        \n\nA matrix: 10 × 4 of type dbl\n\n\n0\n0\n0\n0\n\n\n4\n0\n0\n0\n\n\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n\n\n2\n1\n0\n0\n\n\n0\n0\n0\n0\n\n\n0\n2\n0\n0\n\n\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n\n\n1\n0\n1\n0\n\n\n\n\n\n    $SIM\n        \n\nA matrix: 10 × 10 of type dbl\n\n\n-1.0\n1\n0.0000000\n0.0000000\n0.0\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n\n\n0.4\n-1\n0.0000000\n0.0000000\n0.6\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n\n\n0.0\n0\n-1.0000000\n0.0000000\n1.0\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n\n\n0.0\n0\n0.0000000\n-1.0000000\n1.0\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n\n\n0.0\n0\n0.1666667\n0.3333333\n-1.0\n0.0000000\n0.1666667\n0.0000000\n0.0000000\n0.3333333\n\n\n0.0\n0\n0.0000000\n0.0000000\n0.0\n-1.0000000\n1.0000000\n0.0000000\n0.0000000\n0.0000000\n\n\n0.0\n0\n0.0000000\n0.0000000\n0.0\n0.6666667\n-1.0000000\n0.0000000\n0.0000000\n0.0000000\n\n\n0.0\n0\n0.0000000\n0.0000000\n0.0\n0.0000000\n0.0000000\n-1.0000000\n0.0000000\n1.0000000\n\n\n0.0\n0\n0.0000000\n0.0000000\n0.0\n0.0000000\n0.0000000\n0.0000000\n-1.0000000\n1.0000000\n\n\n0.0\n0\n0.0000000\n0.0000000\n0.0\n0.0000000\n0.0000000\n0.3333333\n0.3333333\n-1.0000000\n\n\n\n\n\n    $IPV\n        \n0100000000\n\n    $indices\n        \n7298310412115\n\n\n\n\n\nplot_graph(graph_as_matrix(graph), #rainbow=TRUE, \n           size=c(10, 8), #align=TRUE,\n               fontsize=16, ranksep=1, nodesep=0.25,\n             # subgraph=TRUE, subgraphfun=function(state, index) as.character((index+1) %/% 2)\n)\n\n\n\n\n\n\n\n\n\napply(rewards[1:3,], 1, function(x) expectation(graph, x))\n\n\n210.666666666666667\n\n\n\nrev_graph &lt;- reward_transform(graph, rewards[1,])\nplot_graph(graph_as_matrix(rev_graph), #rainbow=TRUE, \n           size=c(10, 8), #align=TRUE,\n               fontsize=16, ranksep=1, nodesep=0.25,\n             # subgraph=TRUE, subgraphfun=function(state, index) as.character((index+1) %/% 2)\n)\n\n\n\n\n\n\n\n\n\npdph(1:10, rev_graph)\n\n\n0.4920.68520.814440.894420.94147560.968198280.9829850280.99100754760.99529405860.997556851764"
  },
  {
    "objectID": "examples/R/coalescent-jointprob-R.html#compute-joint-prob",
    "href": "examples/R/coalescent-jointprob-R.html#compute-joint-prob",
    "title": "Joint probability experiment",
    "section": "Compute joint prob",
    "text": "Compute joint prob\n\nConstraining the total number of mutations does not work\nThe deficit is computed correctly as long as all max rewards so that all r scalar values in the CDF represents a reward combination in the MDF\nJust like we can limit the number of each king of tons in the state space contruction, we might also limit the total number of mutations so that we, for example, can have at most one instance of two different tons (total_tons=2). E.g., a singleton and a tripleton.\nHowever, this gives a a deficit problem I am not sure I can solve with this approach. In principle, the deficit should be taken care of, and I should just discard all joint probs for total numbers of tons larger than total_tons - but that does not seem to be the case…\n\nmaybe I don’t need loops if they are not selff-loops anyway. If aux-&gt;C has rate 1 then A-&gt;aux-&gt;C is the same as A-&gt;C. Below I just changed two things\n\nnormalize the graph\nuse pdph instead of pph\n\nBUT if I normalize I need to represent the residual prob as reward, which means I need to reward transform, which I cannot if I want to do everying in one go with the scalar trick.\n\nsample_size &lt;- 4\n\ngraph &lt;- standard_coalescent(sample_size)\nplot_graph(graph_as_matrix(graph), size=c(10, 8), align=TRUE, rainbow=TRUE,\n               fontsize=16, ranksep=1, nodesep=0.25,\n            subgraphs=TRUE,         \n           subgraphfun=function(state, index) paste(state[1:sample_size], collapse=\"\"))\n\n\n\n\n\n\n\n\n\n# mutation_rate &lt;- 20000 * 31 * 5e-10 # 0.00031\nmutation_rate &lt;- 1\nmax_tons &lt;- 20\ntotal_tons &lt;- Inf\nbase &lt;- max_tons + 1\ngraph &lt;- joint_prob_coalescent(sample_size, mutation_rate, max_tons, total_tons=total_tons)\n\nweights_were_multiplied_with &lt;- normalize_graph(graph)\n\n# gam &lt;- graph_as_matrix(graph)\n#gam\n\n\nif (vertices_length(graph) &lt; 50)\n    plot_graph(graph_as_matrix(graph), size=c(10, 8), align=TRUE, rainbow=TRUE,\n               fontsize=16, ranksep=2, nodesep=0.5,\n             subgraphs=TRUE,         \n           subgraphfun=function(state, index) paste(state[1:sample_size], collapse=\"\"))\n\nGet last halves of states that server as mutation rewards:\n\nrewards &lt;- states(graph)[, (sample_size+1):(2*sample_size)]\n\nTurn reward vectors into scalars (with the appropriate base):\n\nmulti_rewards &lt;- apply(rewards, 1, forth, base=base)\nmulti_rewards\n\n\n00010012120211441122221423214212442441882222323224346242634426323443442883882132322432334242344463436446290348363845638434444443884883132413231764436423442445252445464446546390448464859031344483924504841056841054544544488588413251324176517642205648544652445255626254646545664649054856586904134548492550585106134417859241365504945525105126710512656446445886885132613251766176522062205264685106658645662546266727264746646674659064866687905134648592650686107134517869251366505946526⋯78538294743378747013745465937034617366149133871391548293873478738314745378947033747466137054915387339174831387547893833474737914705374949173875391948333877479138354749379349193877392148353879479338374921387939234837388149233881392549253913487149155829487357874831574547895703474756614705591548734917583148755789483357474791570547495917487549195833487757914835574947935919487749215835487957934837592148794923583748815923488149255925491558735917683158756789583367475791670557496917587559196833587767915835674957936919587759216835587967935837692158795923683758816923588159256925591768756919783368777791683577496793791968776921783568797793683779216879692378376881792368816925792569197877792188357879879378378921787979238837788189237881792589257921887989239837888199238881892599258923988199260925992600\n\n\nLoop over states except starting to find trash vertices and give them a reward so they won’t dissapear in the reward transformation. They will not contribute this reward because they are dead ends:\n\ntrash_states &lt;- c()\nfor (i in 2:vertices_length(graph)) {\n  vertex &lt;- vertex_at(graph, i)\n  if (sum(vertex$state) == 0) {\n    multi_rewards[i] &lt;- 1\n    trash_states &lt;- c(trash_states, i)\n  }\n}\ntrash_states\n\n\n333419428\n\n\n\nmulti_rewards\n\n\n00010012120211441122221423214212442441882222323224346242634426323443442883882132322432334242344463436446290348363845638434444443884883132413231764436423442445252445464446546390448464859031344483924504841056841054544544488588413251324176517642205648544652445255626254646545664649054856586904134548492550585106134417859241365504945525105126710512656446445886885132613251766176522062205264685106658645662546266727264746646674659064866687905134648592650686107134517869251366505946526⋯78538294743378747013745465937034617366149133871391548293873478738314745378947033747466137054915387339174831387547893833474737914705374949173875391948333877479138354749379349193877392148353879479338374921387939234837388149233881392549253913487149155829487357874831574547895703474756614705591548734917583148755789483357474791570547495917487549195833487757914835574947935919487749215835487957934837592148794923583748815923488149255925491558735917683158756789583367475791670557496917587559196833587767915835674957936919587759216835587967935837692158795923683758816923588159256925591768756919783368777791683577496793791968776921783568797793683779216879692378376881792368816925792569197877792188357879879378378921787979238837788189237881792589257921887989239837888199238881892599258923988199260925992601\n\n\nReward transform graph using scalar rewards:\n\nrew_graph &lt;- reward_transform(graph, multi_rewards)\n\n\nif (vertices_length(graph) &lt; 50)\n    plot_graph(graph_as_matrix(rew_graph),\n           rainbow=TRUE,\n           size=c(8, 8), \n           align=TRUE,\n           fontsize=14, ranksep=1, nodesep=0.5, \n           # subgraphs=TRUE, subgraphfun=function(state, index) as.character((index+1) %/% 2)\n           )\n\nCompute CDF assming no mutation count exceeds max_tons:\n\ncdf_df &lt;- data.frame(t=seq(0, base^(sample_size-1) - 1, 1))\ncdf_df['cdf'] &lt;- sapply(cdf_df$t, function (t) pdph(t, rew_graph))\n# cdf_df['cdf'] &lt;- sapply(cdf_df$t, function (t) pph(t, rew_graph))\ntail(cdf_df)\n\n\nA data.frame: 6 × 2\n\n\n\nt\ncdf\n\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n9256\n9255\n0.9796789\n\n\n9257\n9256\n0.9796824\n\n\n9258\n9257\n0.9796860\n\n\n9259\n9258\n0.9796896\n\n\n9260\n9259\n0.9796932\n\n\n9261\n9260\n0.9796968\n\n\n\n\n\nConvert reward scalars back into state vectors representing ton counts:\n\nx &lt;- lapply(cdf_df$t, back, base=base, state_length=sample_size)\nm &lt;- do.call(rbind, x)\n\n\n# is_additional_deficit &lt;- as.integer(rowSums(m) &gt; total_tons)\n# p &lt;- df$cdf\n# pdf_from_cdf &lt;- c(p[1], p[2:length(p)] - p[-length(p)])\n# additional_deficit &lt;- cumsum(pdf_from_cdf * is_additional_deficit)\n# additional_deficit\n\n\ndf &lt;- cbind(cdf_df, data.frame(m))\ntail(df)\n\n\nA data.frame: 6 × 6\n\n\n\nt\ncdf\nX1\nX2\nX3\nX4\n\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n9256\n9255\n0.9796789\n15\n20\n20\n0\n\n\n9257\n9256\n0.9796824\n16\n20\n20\n0\n\n\n9258\n9257\n0.9796860\n17\n20\n20\n0\n\n\n9259\n9258\n0.9796896\n18\n20\n20\n0\n\n\n9260\n9259\n0.9796932\n19\n20\n20\n0\n\n\n9261\n9260\n0.9796968\n20\n20\n20\n0\n\n\n\n\n\nThe deficit is taken care of, so you should discard all joint probs for total numbers of tons larger than total_tons:\n\n# df &lt;- df[!is_additional_deficit, ]\n# df\n\n\ndf %&gt;% ggplot(aes(x=t, y=cdf)) + \n    geom_bar(stat=\"identity\") +\n    labs(x='scaled time', y='probability') + \n    despine + ylim(0, 1)\n\n\n\n\n\n\n\n\nCompute probability of standing in on of the trash states for each time t in our CDF. These represent the deficit of the computed CDF:\n\nMake sure the stop_probability is the discrete version of that is what we are doing\n\n\ntrash_prob &lt;- c()\nfor (t in df$t) {\n    # s &lt;- stop_probability(graph, t)\n    s &lt;- dph_stop_probability(graph, t)\n    trash_prob &lt;- c(trash_prob, sum(s[trash_states]))\n}\ndf['cdf_deficit'] &lt;- trash_prob\nhead(df)\n\n\nA data.frame: 6 × 7\n\n\n\nt\ncdf\nX1\nX2\nX3\nX4\ncdf_deficit\n\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n1\n0\n0.1000000\n0\n0\n0\n0\n0\n\n\n2\n1\n0.1233308\n1\n0\n0\n0\n0\n\n\n3\n2\n0.1614973\n2\n0\n0\n0\n0\n\n\n4\n3\n0.2117425\n3\n0\n0\n0\n0\n\n\n5\n4\n0.2303889\n4\n0\n0\n0\n0\n\n\n6\n5\n0.2476603\n5\n0\n0\n0\n0\n\n\n\n\n\nCDF deficit:\n\ndf %&gt;% ggplot(aes(x=t, y=cdf_deficit)) + \n    geom_bar(stat=\"identity\") +\n    labs(x='scaled time', y='probability') + \n    despine + ylim(0, 1)\n\n\n\n\n\n\n\n\nSanity check: adding CDF and deficit should produce a CDF that goes to 1:\n\ndf['cdf_incl_deficit'] &lt;- df$cdf + df$cdf_deficit\n\n\ndf %&gt;% ggplot(aes(x=t, y=cdf_incl_deficit)) + \n    geom_bar(stat=\"identity\") +\n    labs(x='scaled time', y='probability') + \n    despine + \n    ylim(0, 1) + \n    geom_hline(yintercept=1, linetype=\"dashed\")\n\n\n\n\n\n\n\n\nI.e., and a PDF that sum to one:\n\np &lt;- df$cdf_incl_deficit\ndf['pdf_from_cdf_incl_deficit'] &lt;- c(p[1], p[2:length(p)] - p[-length(p)])\n\n\ndf %&gt;% ggplot(aes(x=t, y=pdf_from_cdf_incl_deficit)) + \n    geom_bar(stat=\"identity\") +\n    labs(x='scaled time', y='probability') + \n    despine\n\n\n\n\n\n\n\n\n\nsum(df$pdf_from_cdf_incl_deficit)\n\n0.979780061019623\n\n\nIt almost does… Maybe a numerical issue\nCompute PDF from the CDF (this is the one we are after):\n\np &lt;- df$cdf\ndf['pdf_from_cdf'] &lt;- c(p[1], p[2:length(p)] - p[-length(p)])\ndf['prob'] = df$pdf_from_cdf\n\n\ndf %&gt;% ggplot(aes(x=t, y=pdf_from_cdf)) + \n    geom_bar(stat=\"identity\") +\n    labs(x='scaled time', y='probability') + \n    despine\n\n\n\n\n\n\n\n\nThe reason we need to go through the CDF to get the PDF is that the PDF function in PtD computes the distribution of times when the absorbing state is reached. It this cannot take the deficit in trash_states into account. The PDF commputed directly looks like this:\n\nMake sure I ues the discrete version here if I also use the dicscrete CDF above\n\n\n# df['pdf'] &lt;- sapply(df$t, function (t) dph(t, rew_graph))\ndf['pdf'] &lt;- sapply(df$t, function (t) ddph(t, rew_graph))\n\n\ndf %&gt;% ggplot(aes(x=t, y=pdf)) + \n    geom_bar(stat=\"identity\") +\n    labs(x='scaled time', y='probability') + \n    despine"
  },
  {
    "objectID": "examples/R/coalescent-jointprob-R.html#when-we-do-the-discrete-version-we-dont-need-to-go-through-the-cdf-to-get-the-pdf.-we-can-just-use-the-ddph-directly",
    "href": "examples/R/coalescent-jointprob-R.html#when-we-do-the-discrete-version-we-dont-need-to-go-through-the-cdf-to-get-the-pdf.-we-can-just-use-the-ddph-directly",
    "title": "Joint probability experiment",
    "section": "When we do the discrete version, we don’t need to go through the CDF to get the PDF. We can just use the ddph directly",
    "text": "When we do the discrete version, we don’t need to go through the CDF to get the PDF. We can just use the ddph directly\n\ndf['diff'] &lt;- df['pdf_from_cdf'] - df['pdf']\ndf %&gt;% ggplot(aes(x=t, y=diff)) + \n    geom_bar(stat=\"identity\") +\n    labs(x='scaled time', y='probability') + \n    despine \n\n\n\n\n\n\n\n\nThe marginal expectations does not match the SFS proportions, because paths that accumulate more than max_tons singletons will end in the trash state and not have the opportunity to also accumulate doubletons etc. That reflects that the the joint prob of a singleton and a doubleton is be a subset of the singleton probability. That way the total marginal singleton prob will be roughly sfs expectation, but the total marginal doubleton prob will be much too small:\n\nsfs &lt;- c(1, 1/2, 1/3)\nsfs / sum(sfs)\n\n\n0.5454545454545460.2727272727272730.181818181818182\n\n\n\ndf[df$X1==1 & df$X2==0 & df$X3==1, ]\n\n\nA data.frame: 1 × 13\n\n\n\nt\ncdf\nX1\nX2\nX3\nX4\ncdf_deficit\ncdf_incl_deficit\npdf_from_cdf_incl_deficit\npdf_from_cdf\nprob\npdf\ndiff\n\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n443\n442\n0.7136648\n1\n0\n1\n0\n8.327853e-05\n0.7137481\n0.0002646858\n0.0002646858\n0.0002646858\n0.0002646858\n-2.238877e-17\n\n\n\n\n\n\ndf\n\n\nA data.frame: 9261 × 13\n\n\nt\ncdf\nX1\nX2\nX3\nX4\ncdf_deficit\ncdf_incl_deficit\npdf_from_cdf_incl_deficit\npdf_from_cdf\nprob\npdf\ndiff\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n0\n0.1000000\n0\n0\n0\n0\n0.000000e+00\n0.1000000\n0.100000000\n0.100000000\n0.100000000\n0.100000000\n0.000000e+00\n\n\n1\n0.1233308\n1\n0\n0\n0\n0.000000e+00\n0.1233308\n0.023330814\n0.023330814\n0.023330814\n0.023330814\n-6.938894e-18\n\n\n2\n0.1614973\n2\n0\n0\n0\n0.000000e+00\n0.1614973\n0.038166529\n0.038166529\n0.038166529\n0.038166529\n-6.938894e-18\n\n\n3\n0.2117425\n3\n0\n0\n0\n0.000000e+00\n0.2117425\n0.050245196\n0.050245196\n0.050245196\n0.050245196\n6.938894e-18\n\n\n4\n0.2303889\n4\n0\n0\n0\n0.000000e+00\n0.2303889\n0.018646386\n0.018646386\n0.018646386\n0.018646386\n-3.469447e-18\n\n\n5\n0.2476603\n5\n0\n0\n0\n0.000000e+00\n0.2476603\n0.017271404\n0.017271404\n0.017271404\n0.017271404\n-1.387779e-17\n\n\n6\n0.2629493\n6\n0\n0\n0\n0.000000e+00\n0.2629493\n0.015288932\n0.015288932\n0.015288932\n0.015288932\n2.428613e-17\n\n\n7\n0.2762541\n7\n0\n0\n0\n0.000000e+00\n0.2762541\n0.013304841\n0.013304841\n0.013304841\n0.013304841\n5.204170e-18\n\n\n8\n0.2878150\n8\n0\n0\n0\n0.000000e+00\n0.2878150\n0.011560939\n0.011560939\n0.011560939\n0.011560939\n-1.040834e-17\n\n\n9\n0.2979278\n9\n0\n0\n0\n0.000000e+00\n0.2979278\n0.010112710\n0.010112710\n0.010112710\n0.010112710\n-2.255141e-17\n\n\n10\n0.3068648\n10\n0\n0\n0\n0.000000e+00\n0.3068648\n0.008937019\n0.008937019\n0.008937019\n0.008937019\n-2.081668e-17\n\n\n11\n0.3148516\n11\n0\n0\n0\n0.000000e+00\n0.3148516\n0.007986783\n0.007986783\n0.007986783\n0.007986783\n-1.734723e-17\n\n\n12\n0.3220662\n12\n0\n0\n0\n0.000000e+00\n0.3220662\n0.007214610\n0.007214610\n0.007214610\n0.007214610\n-1.127570e-17\n\n\n13\n0.3286470\n13\n0\n0\n0\n0.000000e+00\n0.3286470\n0.006580816\n0.006580816\n0.006580816\n0.006580816\n8.673617e-19\n\n\n14\n0.3347016\n14\n0\n0\n0\n0.000000e+00\n0.3347016\n0.006054616\n0.006054616\n0.006054616\n0.006054616\n2.428613e-17\n\n\n15\n0.3403145\n15\n0\n0\n0\n0.000000e+00\n0.3403145\n0.005612866\n0.005612866\n0.005612866\n0.005612866\n-1.301043e-17\n\n\n16\n0.3455527\n16\n0\n0\n0\n0.000000e+00\n0.3455527\n0.005238284\n0.005238284\n0.005238284\n0.005238284\n-6.938894e-18\n\n\n17\n0.3504706\n17\n0\n0\n0\n0.000000e+00\n0.3504706\n0.004917865\n0.004917865\n0.004917865\n0.004917865\n1.734723e-18\n\n\n18\n0.3551123\n18\n0\n0\n0\n0.000000e+00\n0.3551123\n0.004641673\n0.004641673\n0.004641673\n0.004641673\n-2.168404e-17\n\n\n19\n0.3595143\n19\n0\n0\n0\n0.000000e+00\n0.3595143\n0.004401981\n0.004401981\n0.004401981\n0.004401981\n-6.938894e-18\n\n\n20\n0.3637069\n20\n0\n0\n0\n0.000000e+00\n0.3637069\n0.004192673\n0.004192673\n0.004192673\n0.004192673\n2.602085e-18\n\n\n21\n0.3677158\n0\n1\n0\n0\n4.398047e-09\n0.3677158\n0.004008840\n0.004008836\n0.004008836\n0.004008836\n2.602085e-18\n\n\n22\n0.3715622\n1\n1\n0\n0\n1.730539e-08\n0.3715623\n0.003846485\n0.003846472\n0.003846472\n0.003846472\n-1.778092e-17\n\n\n23\n0.3752645\n2\n1\n0\n0\n2.678447e-05\n0.3752913\n0.003729069\n0.003702302\n0.003702302\n0.003702302\n-1.301043e-17\n\n\n24\n0.3788382\n3\n1\n0\n0\n4.942828e-05\n0.3788876\n0.003596256\n0.003573612\n0.003573612\n0.003573612\n-1.301043e-17\n\n\n25\n0.3822963\n4\n1\n0\n0\n6.385415e-05\n0.3823602\n0.003472572\n0.003458146\n0.003458146\n0.003458146\n-1.387779e-17\n\n\n26\n0.3856503\n5\n1\n0\n0\n7.209272e-05\n0.3857224\n0.003362254\n0.003354016\n0.003354016\n0.003354016\n6.071532e-18\n\n\n27\n0.3889100\n6\n1\n0\n0\n7.658223e-05\n0.3889865\n0.003264130\n0.003259640\n0.003259640\n0.003259640\n-5.204170e-18\n\n\n28\n0.3920836\n7\n1\n0\n0\n7.901387e-05\n0.3921627\n0.003176117\n0.003173686\n0.003173686\n0.003173686\n-1.040834e-17\n\n\n29\n0.3951787\n8\n1\n0\n0\n8.037496e-05\n0.3952590\n0.003096387\n0.003095026\n0.003095026\n0.003095026\n-2.385245e-17\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n9231\n0.9795925\n12\n19\n20\n0\n8.327853e-05\n0.9796758\n3.607475e-06\n3.607475e-06\n3.607475e-06\n3.607475e-06\n1.581919e-17\n\n\n9232\n0.9795961\n13\n19\n20\n0\n8.327853e-05\n0.9796794\n3.606640e-06\n3.606640e-06\n3.606640e-06\n3.606640e-06\n3.827276e-17\n\n\n9233\n0.9795997\n14\n19\n20\n0\n8.327853e-05\n0.9796830\n3.605805e-06\n3.605805e-06\n3.605805e-06\n3.605805e-06\n-8.857000e-18\n\n\n9234\n0.9796033\n15\n19\n20\n0\n8.327853e-05\n0.9796866\n3.604971e-06\n3.604971e-06\n3.604971e-06\n3.604971e-06\n-3.186792e-17\n\n\n9235\n0.9796069\n16\n19\n20\n0\n8.327853e-05\n0.9796902\n3.604136e-06\n3.604136e-06\n3.604136e-06\n3.604136e-06\n-4.810512e-17\n\n\n9236\n0.9796106\n17\n19\n20\n0\n8.327853e-05\n0.9796938\n3.603302e-06\n3.603302e-06\n3.603302e-06\n3.603302e-06\n3.612087e-17\n\n\n9237\n0.9796142\n18\n19\n20\n0\n8.327853e-05\n0.9796974\n3.602468e-06\n3.602468e-06\n3.602468e-06\n3.602468e-06\n-1.868893e-17\n\n\n9238\n0.9796178\n19\n19\n20\n0\n8.327853e-05\n0.9797010\n3.601635e-06\n3.601635e-06\n3.601635e-06\n3.601635e-06\n-7.936699e-18\n\n\n9239\n0.9796214\n20\n19\n20\n0\n8.327853e-05\n0.9797046\n3.600801e-06\n3.600801e-06\n3.600801e-06\n3.600801e-06\n5.086136e-17\n\n\n9240\n0.9796250\n0\n20\n20\n0\n8.327853e-05\n0.9797082\n3.599968e-06\n3.599968e-06\n3.599968e-06\n3.599968e-06\n2.912480e-17\n\n\n9241\n0.9796286\n1\n20\n20\n0\n8.327853e-05\n0.9797118\n3.599135e-06\n3.599135e-06\n3.599135e-06\n3.599135e-06\n2.031481e-17\n\n\n9242\n0.9796322\n2\n20\n20\n0\n8.327853e-05\n0.9797154\n3.598303e-06\n3.598303e-06\n3.598303e-06\n3.598303e-06\n6.763982e-18\n\n\n9243\n0.9796358\n3\n20\n20\n0\n8.327853e-05\n0.9797190\n3.597470e-06\n3.597470e-06\n3.597470e-06\n3.597470e-06\n-2.921163e-17\n\n\n9244\n0.9796393\n4\n20\n20\n0\n8.327853e-05\n0.9797226\n3.596638e-06\n3.596638e-06\n3.596638e-06\n3.596638e-06\n5.699685e-18\n\n\n9245\n0.9796429\n5\n20\n20\n0\n8.327853e-05\n0.9797262\n3.595806e-06\n3.595806e-06\n3.595806e-06\n3.595806e-06\n-1.727397e-17\n\n\n9246\n0.9796465\n6\n20\n20\n0\n8.327853e-05\n0.9797298\n3.594975e-06\n3.594975e-06\n3.594975e-06\n3.594975e-06\n-4.977589e-18\n\n\n9247\n0.9796501\n7\n20\n20\n0\n8.327853e-05\n0.9797334\n3.594143e-06\n3.594143e-06\n3.594143e-06\n3.594143e-06\n2.477444e-17\n\n\n9248\n0.9796537\n8\n20\n20\n0\n8.327853e-05\n0.9797370\n3.593312e-06\n3.593312e-06\n3.593312e-06\n3.593312e-06\n5.409449e-17\n\n\n9249\n0.9796573\n9\n20\n20\n0\n8.327853e-05\n0.9797406\n3.592481e-06\n3.592481e-06\n3.592481e-06\n3.592481e-06\n-4.600659e-17\n\n\n9250\n0.9796609\n10\n20\n20\n0\n8.327853e-05\n0.9797442\n3.591651e-06\n3.591651e-06\n3.591651e-06\n3.591651e-06\n3.956999e-17\n\n\n9251\n0.9796645\n11\n20\n20\n0\n8.327853e-05\n0.9797478\n3.590820e-06\n3.590820e-06\n3.590820e-06\n3.590820e-06\n-4.026117e-17\n\n\n9252\n0.9796681\n12\n20\n20\n0\n8.327853e-05\n0.9797514\n3.589990e-06\n3.589990e-06\n3.589990e-06\n3.589990e-06\n2.947717e-17\n\n\n9253\n0.9796717\n13\n20\n20\n0\n8.327853e-05\n0.9797550\n3.589160e-06\n3.589160e-06\n3.589160e-06\n3.589160e-06\n8.646512e-18\n\n\n9254\n0.9796753\n14\n20\n20\n0\n8.327853e-05\n0.9797585\n3.588330e-06\n3.588330e-06\n3.588330e-06\n3.588330e-06\n-9.917909e-18\n\n\n9255\n0.9796789\n15\n20\n20\n0\n8.327853e-05\n0.9797621\n3.587501e-06\n3.587501e-06\n3.587501e-06\n3.587501e-06\n-4.435573e-17\n\n\n9256\n0.9796824\n16\n20\n20\n0\n8.327853e-05\n0.9797657\n3.586672e-06\n3.586672e-06\n3.586672e-06\n3.586672e-06\n-1.940129e-18\n\n\n9257\n0.9796860\n17\n20\n20\n0\n8.327853e-05\n0.9797693\n3.585843e-06\n3.585843e-06\n3.585843e-06\n3.585843e-06\n-1.196561e-17\n\n\n9258\n0.9796896\n18\n20\n20\n0\n8.327853e-05\n0.9797729\n3.585014e-06\n3.585014e-06\n3.585014e-06\n3.585014e-06\n1.828617e-17\n\n\n9259\n0.9796932\n19\n20\n20\n0\n8.327853e-05\n0.9797765\n3.584186e-06\n3.584186e-06\n3.584186e-06\n3.584186e-06\n-4.061396e-17\n\n\n9260\n0.9796968\n20\n20\n20\n0\n8.327853e-05\n0.9797801\n3.583358e-06\n3.583358e-06\n3.583358e-06\n3.583358e-06\n1.500222e-17\n\n\n\n\n\n\nc(sum(joint_probs$V1 * joint_probs$accum_time), \n  sum(joint_probs$V2 * joint_probs$accum_time), \n  sum(joint_probs$V3 * joint_probs$accum_time))\n\n\n00.0009615982869341380.00057948368296313\n\n\n\nc(sum(df$X1 * df$prob), sum(df$X2 * df$prob), sum(df$X3 * df$prob))\n\n\n7.731127094402044.694249683567271.19250319602024\n\n\n\nplot_df &lt;- df %&gt;% group_by(X2, X3) %&gt;% summarise(prob = sum(prob))\nplot_df[,-ncol(plot_df)] &lt;- lapply(plot_df[,-ncol(plot_df)], as.factor)\nhead(plot_df)\n\n\n`summarise()` has grouped output by 'X2'. You can override using the `.groups` argument.\n\n\n\n\n\nA grouped_df: 6 × 3\n\n\nX2\nX3\nprob\n\n\n&lt;fct&gt;\n&lt;fct&gt;\n&lt;dbl&gt;\n\n\n\n\n0\n0\n0.3637069369\n\n\n0\n1\n0.0054461936\n\n\n0\n2\n0.0026874034\n\n\n0\n3\n0.0016935722\n\n\n0\n4\n0.0011754205\n\n\n0\n5\n0.0008663035\n\n\n\n\n\n\nggplot(plot_df, aes(x=X2, y=X3)) +\n    geom_tile(aes(fill = prob)) + \n    geom_text(aes(label = round(prob, 3))) +\n    scale_fill_distiller(palette = 'PiYG',direction = 1,\n                    limit=max(abs(plot_df$prob)) * c(-1, 1)\n                    ) +\n    theme_minimal() +\n     theme(panel.grid.major = element_blank(), \n            panel.grid.minor = element_blank(), \n            text=element_text(size=17))\n\n\n\n\n\n\n\n\n\nggplot(plot_df, aes(x=X2, y=X3)) +\n    geom_tile(aes(fill = log10(prob))) + \n    geom_text(aes(label = round(log10(prob), 2))) +\n    scale_fill_distiller(palette = 'PiYG',direction = 1,\n                    limit=max(abs(log10(plot_df$prob))) * c(-1, 1)\n                    ) +\ntheme_minimal() +\n theme(panel.grid.major = element_blank(), \n        panel.grid.minor = element_blank(), \n        text=element_text(size=17))\n\n\n\n\n\n\n\n\n\n\n# plot_graph &lt;- function(gam, constrained=TRUE, \n#                        subgraphs=FALSE, ranksep=2, nodesep=1,\n#                        subgraphfun=function(state, index) paste(state[-length(state)], collapse=\"\"), \n#                        size=c(6, 6), fontsize=10, rankdir=\"LR\", align=FALSE, nodecolor='white', rainbow=FALSE, penwidth=1) {\n\n\n#     format_rate &lt;- function(rate) {\n#         # tol = .Machine$double.eps^0.5\n#         # if (min(abs(c(rate%%1, rate%%1-1))) &lt; tol) {\n#         if (rate == round(rate)) {\n#             return(rate)\n#         } else {\n#             return(formatC(rate, format = \"e\", digits = 2))\n#         }\n#     }\n\n#     random_color &lt;- function() {\n#         if (rainbow) {\n#             return(paste(\"#\", paste0(sample(c(0:9, LETTERS[1:6]), 6, T), collapse = ''), sep=''))\n#         } else {\n#             return('#000000')\n#         }\n#     }\n\n#     sub_graphs = list()\n#     state_classes = list()\n    \n#     if (constrained) {\n#         constrained &lt;- 'true'\n#     } else {\n#         constrained &lt;- 'false'\n#     }\n\n#     states &lt;- c()\n#     for (i in 1:(nrow(gam$states))) {\n#         states &lt;- c(states, paste0(i, ' [label=\"', paste(gam$states[i,], collapse = \",\"), '\"];'))\n#     }\n    \n#     edge_templ &lt;- '\"FROM\" -&gt; \"TO\" [constraint=true, label=\"LABEL\",labelfloat=false,color=\"COLOR\",fontcolor=\"COLOR\"];'\n\n#     subgraph_template &lt;- '\n#     subgraph cluster_FREQBIN {\n#         rank=same;\n#         style=filled;\n#         color=whitesmoke;\n#         node [style=filled];\n#         NODES;\n#         label = \"FREQBIN\";\n#     }\n#     '\n#     start_name &lt;- 'IPV'\n#     absorbing_name &lt;- 'Absorb'\n#     edges &lt;- c()\n#     # IPV edges\n#     for (i in 1:length(gam$IPV)) {\n#         if (gam$IPV[i] &gt; 0) {\n#             edge &lt;- edge_templ\n#             edge &lt;- sub('FROM', start_name, edge)\n#             edge &lt;- sub('TO', i, edge)\n#             edge &lt;- sub('LABEL', gam$IPV[i], edge)\n#             edge &lt;- gsub('COLOR', random_color(), edge)                        \n#             edges &lt;- c(edges, edge)\n#         }\n#     }    \n#     # Matrix edges\n#     for (i in 1:(nrow(gam$states))) {\n#         for (j in 1:nrow(gam$states)) {\n#             if ((i != j) && (gam$SIM[i, j] &gt; 0)) {\n#                 edge &lt;- edge_templ\n#                 edge &lt;- sub('FROM', i, edge)\n#                 edge &lt;- sub('TO', j, edge)\n#                 edge &lt;- sub('LABEL', format_rate(gam$SIM[i, j]), edge)\n#                 edge &lt;- gsub('COLOR', random_color(), edge)\n#                 edges &lt;- c(edges, edge)\n#             }\n#         }\n#     }\n\n#     absorb_rates &lt;- -rowSums(gam$SIM)\n#     for (i in 1:nrow(gam$states)) {\n\n#         # TODO: Avoid the hack below by changing the function to use the graph instead of the matrix\n#         if (absorb_rates[i] &gt; abs(1e-14)) {\n#         # if (absorb_rates[i] &gt; 0) {\n#             edge &lt;- edge_templ\n#             edge &lt;- sub('FROM', i, edge)\n#             edge &lt;- sub('TO', absorbing_name, edge)\n#             edge &lt;- sub('LABEL', absorb_rates[i], edge)\n#             edge &lt;- gsub('COLOR', random_color(), edge)            \n#             edges &lt;- c(edges, edge)\n#         }\n#     }\n\n#     graph_spec &lt;- paste(c(states, edges), collapse = '\\n')\n\n#     rank_same &lt;- ''\n\n#     if (subgraphs) {        \n#         for (i in 1:(nrow(gam$states))) {\n#             sg &lt;- subgraphfun(gam$states[i,], index=i)\n#             sub_graphs[[sg]] &lt;- c(sub_graphs[[sg]], i)\n#         }\n#         for (sg in labels(sub_graphs)) {\n            \n#             nodes &lt;- sub_graphs[[sg]]\n#             tmpl &lt;- subgraph_template\n#             node_str &lt;- ''\n#             for (i in 1:length(nodes)) {\n#                 node_str &lt;- paste(node_str, paste('\"', nodes[i], '\" ', sep=''), sep=' ')\n#             }\n#             tmpl &lt;- sub('NODES', node_str, tmpl)\n#             tmpl &lt;- sub('FREQBIN', sg, tmpl)            \n#             tmpl &lt;- sub('FREQBIN', sg, tmpl)            \n#             graph_spec &lt;- paste(graph_spec, tmpl)\n#         }\n\n\n#         if (align) {\n#             for (i in 1:(nrow(gam$states))) {\n#                 sc &lt;- paste(head(gam$states[i,], -1), collapse = \",\")\n#                 state_classes[[sc]] &lt;- c(state_classes[[sc]], i)\n#             }\n#             for (sc in labels(state_classes)) {\n#                 rank_same &lt;- paste(rank_same, '{rank=same; ', sep='')\n#                 nodes &lt;- state_classes[[sc]]\n#                 for (i in 1:length(nodes)) {\n#                     rank_same &lt;- paste(rank_same, paste('\"', nodes[i], '\" ', sep=''), sep=' ')\n#                 }            \n#                 rank_same &lt;- paste(rank_same, ' }', sep='\\n')\n#             }\n#         }\n    \n#     }\n\n#     style_str &lt;- '\n#         graph [compound=true newrank=true pad=\"0.5\", ranksep=\"RANKSEP\", nodesep=\"NODESEP\"] \n#         rankdir=RANKDIR;\n#         size=\"SIZEX,SIZEY\";\n#         fontname=\"Helvetica,Arial,sans-serif\"\n#       node [fontname=\"Helvetica,Arial,sans-serif\", fontsize=FONTSIZE, style=filled, fillcolor=\"NODECOLOR\"]\n#       edge [fontname=\"Helvetica,Arial,sans-serif\", fontsize=FONTSIZE, penwidth=PENWIDTH]\n#         Absorb [style=filled,color=\"lightgrey\"]\n#         IPV [style=filled,color=\"lightgrey\"]\n#         RANKSAME\n#     '\n#     style_str &lt;- sub('SIZEX', size[1], style_str)\n#     style_str &lt;- sub('SIZEY', size[2], style_str)\n#     style_str &lt;- gsub('FONTSIZE', fontsize, style_str)    \n#     style_str &lt;- gsub('RANKDIR', rankdir, style_str)    \n#     style_str &lt;- gsub('RANKSAME', rank_same, style_str)\n#     style_str &lt;- gsub('RANKSEP', ranksep, style_str)\n#     style_str &lt;- gsub('NODESEP', nodesep, style_str)\n#     graph_string &lt;- paste('digraph G {', style_str, graph_spec, '}', sep='\\n')\n#     graph_string &lt;- gsub('NODECOLOR', nodecolor, graph_string)  \n#     graph_string &lt;- gsub('PENWIDTH', penwidth, graph_string)  \n#     system(\"dot -Tsvg -o tmp.svg\", input=graph_string, intern=TRUE)\n#     return(display_svg(file=\"tmp.svg\"))\n# }\n                  \nsample_size &lt;- 3\nmutation_rate &lt;- 1\nmax_tons &lt;- 1\ntotal_tons &lt;- Inf\nbase &lt;- max_tons + 1\ngraph &lt;- joint_prob_coalescent(sample_size, mutation_rate, max_tons, total_tons=total_tons)\n\nplot_graph(graph_as_matrix(graph), rainbow=TRUE, size=c(10, 8), align=TRUE,\n           fontsize=16, ranksep=1, nodesep=0.25,\n           subgraphs=TRUE,\n           # rankdir=\"TB\",\n           subgraphfun=function(state, index) as.character((index+1) %/% 2)\n           # subgraphfun=function(state, index) paste(state[-length(state)], collapse=\"\")\n)"
  },
  {
    "objectID": "examples/python/isolation_migration.html",
    "href": "examples/python/isolation_migration.html",
    "title": "ptdalgorithms",
    "section": "",
    "text": "# We install the package through devtools::install_github\n# This requires the \"devtools\" package to be installed\ninstall.packages(\"devtools\",  INSTALL_opts = c('--no-lock'))\nlibrary(devtools)\ndevtools::install_github(\"TobiasRoikjer/PtDAlgorithms\")\n\nInstalling package into ‘/home/tobias/R/x86_64-pc-linux-gnu-library/4.1’\n(as ‘lib’ is unspecified)\n\nLoading required package: usethis\n\nDownloading GitHub repo TobiasRoikjer/PtDAlgorithms@HEAD\n\n\n\n\n✔  checking for file ‘/tmp/RtmpThPsM1/remotes53755078a75/TobiasRoikjer-PtDAlgorithms-a4fbecd/DESCRIPTION’ (408ms)\n\n─  preparing ‘ptdalgorithms’:\n\n✔  checking DESCRIPTION meta-information\n\n─  cleaning src\n\n─  checking for LF line-endings in source and make files and shell scripts (426ms)\n\n─  checking for empty or unneeded directories\n\n   Omitted ‘LazyData’ from DESCRIPTION\n\n─  building ‘ptdalgorithms_1.0.0.tar.gz’\n\n   \n\n\n\n\n\n\nInstalling package into ‘/home/tobias/R/x86_64-pc-linux-gnu-library/4.1’\n(as ‘lib’ is unspecified)\n\n\n\n\n# Import the functions in the library\nlibrary(ptdalgorithms)\n\n# The library supports setting seeds for some of its\n# sampling capability, as any other R package\nset.seed(1234)\n\n\n# While the R api can create graphs, this is *slow* as the C++ binding layer\n# through Rcpp is slow when invoking many functions, and since R is a slow,\n# interpreted language\n# Clone or download the code, and include these files in the repository!\n# Make SURE that the version of the downloaded code is the same as the\n# installed R library!! Otherwise it may crash randomly\n# The file has comments and is easy to understand, so you should be able\n# to defined you own cool construction functions\n\nRcpp::sourceCpp(\"./isolation_migration_model.cpp\")\n\n\n# Construction of IM model and computation of expectations\n\nn1 &lt;- 8\nn2 &lt;- 8\n\ntime &lt;- proc.time()[3]\nim_graph &lt;- construct_im_graph(n1,n2,0.1,0.1)\nancestral_graph &lt;- construct_ancestral_graph(n1, n2)\n\ncat(paste(\"Construction took \", proc.time()[3] - time, \"seconds\\n\"))\n\ntime &lt;- proc.time()[3]\n\nancestral_start_probability &lt;-\n    start_prob_from_im(ancestral_graph, im_graph, stop_probability(im_graph, time = 1.5))\n\ncat(paste(\"Finding stopping time took \", proc.time()[3] - time, \"seconds\\n\"))\n\n\nfull_im_expectation &lt;- matrix(nrow=n1+1,ncol=n2+1)\ntruncation_im_expectation &lt;- matrix(nrow=n1+1,ncol=n2+1)\nancestral_expectation &lt;- matrix(nrow=n1+1,ncol=n2+1)\n\ntime &lt;- proc.time()[3]\n# This is just to get the timing, not necessary\nk &lt;- expectation(im_graph)\n\ncat(paste(\"Moment graph took \", proc.time()[3] - time, \"seconds\\n\"))\n\ntime &lt;- proc.time()[3]\nfor (i in 0:n1) {\n  for (j in 0:n2) {\n        full_im_expectation[i+1, j+1]&lt;- expectation(im_graph, rewards_at(im_graph, i,j,n1,n2))\n        truncation_im_expectation[i+1, j+1]&lt;-\n          sum(distribution_context_stop_probability(ctx) *\n              expected_waiting_time(im_graph, rewards_at(im_graph, i,j,n1,n2)))\n        ancestral_expectation[i+1, j+1]&lt;-\n          sum(ancestral_start_probability *\n              expected_waiting_time(ancestral_graph, rewards_at(ancestral_graph, i,j,n1,n2)))\n    }\n}\n\ncat(paste(\"Expectations took \", proc.time()[3] - time, \"seconds\\n\"))\nfull_im_expectation - truncation_im_expectation + ancestral_expectation\n\nConstruction took  8.23700000000002 seconds\nFinding stopping time took  182.073 seconds\nMoment graph took  475.957 seconds\nExpectations took  118.025 seconds\n\n\n\nA matrix: 9 × 9 of type dbl\n\n\n0.0000000\n1.94437055\n0.91728479\n0.57500500\n0.405301445\n0.305973594\n0.244728461\n0.216488684\n0.43214155\n\n\n1.9443705\n0.05601000\n0.03866822\n0.03280713\n0.029739771\n0.027952386\n0.027373938\n0.029861369\n0.08763481\n\n\n0.9172848\n0.03866822\n0.02326801\n0.01852383\n0.016371045\n0.015327841\n0.015176856\n0.017021119\n0.05885976\n\n\n0.5750050\n0.03280713\n0.01852383\n0.01414322\n0.012209738\n0.011305574\n0.011164441\n0.012576153\n0.04919712\n\n\n0.4053014\n0.02973977\n0.01637104\n0.01220974\n0.010368679\n0.009498186\n0.009309170\n0.010399057\n0.04499304\n\n\n0.3059736\n0.02795239\n0.01532784\n0.01130557\n0.009498186\n0.008616454\n0.008355782\n0.009165145\n0.04312298\n\n\n0.2447285\n0.02737394\n0.01517686\n0.01116444\n0.009309170\n0.008355782\n0.007979437\n0.008494327\n0.04254818\n\n\n0.2164887\n0.02986137\n0.01702112\n0.01257615\n0.010399057\n0.009165145\n0.008494327\n0.008554401\n0.04304601\n\n\n0.4321415\n0.08763481\n0.05885976\n0.04919712\n0.044993039\n0.043122980\n0.042548176\n0.043046013\n0.00000000\n\n\n\n\n\n\n# Comparing results to verify implementation/numerical accuracy\nn1 &lt;- 4\nn2 &lt;- 4\n\ng &lt;- construct_im_graph(n1,n2,0.1,0.1)\n\nexpected_visits &lt;- rep(0, vertices_length(g))\nctx &lt;- distribution_context(g,1000)\nwhile (distribution_context_state(ctx)$cdf &lt; 0.9999) {\n  distribution_context_step(ctx)\n}\n\nexpected_visits &lt;- distribution_context_accumulated_visiting_time(ctx)\n\ndistribution_expectation &lt;- matrix(nrow=n1+1,ncol=n2+1)\nalgorithm_expectation &lt;- matrix(nrow=n1+1,ncol=n2+1)\nmatrix_expectation &lt;- matrix(nrow=n1+1,ncol=n2+1)\nsimulation_expectation &lt;- matrix(nrow=n1+1,ncol=n2+1)\nPH &lt;- graph_as_matrix(g)\nU &lt;- solve(-PH$SIM)\nset.seed(1234)\n\nfor (i in 0:n1) {\n  for (j in 0:n2) {\n    distribution_expectation[i+1,j+1] &lt;- sum(expected_visits * rewards_at(g, i,j,n1,n2))\n    algorithm_expectation[i+1, j+1]&lt;- expectation(g, rewards_at(g, i,j,n1,n2))\n    simulation_expectation[i+1, j+1]&lt;- mean(rph(10000, g, rewards_at(g, i,j,n1,n2)))\n    matrix_expectation[i+1,j+1] &lt;-PH$IPV %*% U%*%diag(PH$states[,(matrix_index(i,j,0,n1,n2)+1)]+PH$states[,(matrix_index(i,j,1,n1,n2)+1)])%*%rep(1,length(PH$IPV))\n  }\n}\n\nsum(abs(matrix_expectation - algorithm_expectation))\nsum(abs(matrix_expectation - simulation_expectation))\nsum(abs(matrix_expectation - distribution_expectation))\n\n1.21430643318376e-14\n\n\n0.366276506599899\n\n\n0.00123827254283529"
  },
  {
    "objectID": "examples/python/somecode.html",
    "href": "examples/python/somecode.html",
    "title": "ptdalgorithms",
    "section": "",
    "text": "import cppimport.import_hook\nimport somecode #This will pause for a moment to compile the module\nsomecode.square(9)\n\n81\n\n\n\nimport ptdalgorithms\nimport cppimport.import_hook\nimport rabbit_state_space #This will pause for a moment to compile the module\ngraph = ptdalgorithms.Graph(rabbit_state_space.build(2, 2, 4))\n\n\ngraph.plot()"
  },
  {
    "objectID": "examples/python/rabbits_full_py_api_example.html",
    "href": "examples/python/rabbits_full_py_api_example.html",
    "title": "Rabbits (full API example)",
    "section": "",
    "text": "This notebook will describe almost all functions of the ptdalgorithms Python package. The core functionality is implemented in C, with a binding layer to Python through C++ and pybind11. Except for the specified construction code of the state space, most code will be almost equally fast to invoking the C api directly (maybe twice as slow). The package is based on graph algorithms published in (…), and is many orders of magnitude faster than matrix-based equations which are usually applied. We do not recommend using the C++ api directly.\nWe will show how to install the package and construct a state space through the Python api. We will then show how to compute the moments (expectation, variance) through the ptdalgorithms package, and how to compute the distribution functions. This means that you can make discrete and continuous phase-type distributions, compute their moments, distribution functions, sample from them, compute rewards and multivariate distributions, and time inhomogenous distributions.\nWe will also show how easy it is to create the state-space in C and return it to Python, to make large graphs!\n%load_ext autoreload\n%autoreload 2"
  },
  {
    "objectID": "examples/python/rabbits_full_py_api_example.html#installing-the-ptdalgorithms-library",
    "href": "examples/python/rabbits_full_py_api_example.html#installing-the-ptdalgorithms-library",
    "title": "Rabbits (full API example)",
    "section": "Installing the ptdalgorithms library",
    "text": "Installing the ptdalgorithms library\nUsing conda (recommended):\nconda install -c conda-forge -c munch-group ptdalgorithms\nUsing pip:\npip install ptdalgorithms\n\nimport pandas as pd\nimport numpy as np\nnp.random.seed(42)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# plt.style.use('dark_background')\n# import matplotlib\n# matplotlib.rcParams['axes.facecolor'] = '#1F1F1F'\n# matplotlib.rcParams['figure.facecolor'] = '#1F1F1F'\n\n\n#%matplotlib widget\n\n%config InlineBackend.figure_format = 'retina'\n\nimport ptdalgorithms as ptd"
  },
  {
    "objectID": "examples/python/rabbits_full_py_api_example.html#continuous-phase-type-distribution",
    "href": "examples/python/rabbits_full_py_api_example.html#continuous-phase-type-distribution",
    "title": "Rabbits (full API example)",
    "section": "Continuous phase-type distribution",
    "text": "Continuous phase-type distribution\nWe can now construct the graphs by the function. The flooding rates are set to 2 and 4\n\ngraph = construct_rabbit_graph(2, 2, 4)\n\nGet the number of vertices in the graph:\n\ngraph.vertices_length()\n\n7\n\n\nas well as integer vector states that those vertices represent:\n\nM = graph.states()\nM\n\narray([[0, 0],\n       [2, 0],\n       [1, 1],\n       [0, 0],\n       [0, 2],\n       [0, 1],\n       [1, 0]], dtype=int32)\n\n\n(or nicely as a dataframe):\n\npd.DataFrame(M, columns=[\"Rabbits left\", \"Rabbits right\"]).style.hide()\n\n\n\n\n\n\nRabbits left\nRabbits right\n\n\n\n\n0\n0\n\n\n2\n0\n\n\n1\n1\n\n\n0\n0\n\n\n0\n2\n\n\n0\n1\n\n\n1\n0\n\n\n\n\n\nThis phase-type distribution models the time until all rabits have died. For convenience, we can get its expectation and variance like this:\n\ngraph.expectation()\n\nINFO: building reward compute graph...\n\n\n0.5038265306122448\n\n\n\ngraph.variance()\n\n0.2264567497917534\n\n\nBut if you want you can get any number of moments like this (here three):\n\ngraph.moments(3)\n\n[0.5038265306122448, 0.48029792274052463, 0.6559101757731152]\n\n\nWe can find the expected waiting time given that we start in any of the states, not just the starting state:\n\ngraph.expected_waiting_time()\n\n[0.5038265306122448,\n 0.5038265306122448,\n 0.5114795918367346,\n 0.0,\n 0.30229591836734687,\n 0.28571428571428564,\n 0.4285714285714285]\n\n\nIf needed for downstream analysis, matrix-based representation of the phase-type distribution can be extracted. Note that the indices in this representatoin do not correspond to vertex indicies in the graph."
  },
  {
    "objectID": "examples/python/rabbits_full_py_api_example.html#rewards",
    "href": "examples/python/rabbits_full_py_api_example.html#rewards",
    "title": "Rabbits (full API example)",
    "section": "Rewards",
    "text": "Rewards\nWe can add rewards which are based on the number of rabbits on the second island.\n\nrewards = graph.states()[:, 1]\n\nCan also be computed like this:\n\nrewards = np.array([graph.vertex_at(i).state()[1] for i in range(graph.vertices_length())])\n\nAdding these rewards, the phase-type distribution now represent the total accumulated time that any rabbits spends on the right island.\nUsing rewards to the moment functions etc. is much faster than changing the graph.\nThe expectation and variance are now:\n\ngraph.expectation(rewards), graph.variance(rewards)\n\n(0.09438775510204081, 0.04634787588504789)\n\n\nUsing rewards to the moment functions etc. is much faster than actually changing the graph, but sometimes we might want to be interested in reward transforming the phase-type distribution, giving us the full distribution of accumulated rewards. For example if we want the pdf/cdf.\n\nright_graph = graph.reward_transform(rewards)\n\nNow we get the expectation and variance from before without adding any rewards:\n\nright_graph.expectation(), right_graph.variance()\n\nINFO: building reward compute graph...\n\n\n(0.09438775510204078, 0.046347875885047865)\n\n\nWe can find the distribution function for the the total accumulate time spent by any rabbit on an island. We show here the PDF and CDF\n\naccumulated_rewards = np.arange(0, 2, 0.01)\n\npdf = right_graph.pdf(accumulated_rewards)\ncdf = right_graph.cdf(accumulated_rewards)\n\nPDF and CDF of distribution. Notice how we have a “defect” i.e. a probability of obtaining no rewards:\n\nright_graph.defect()\n\n0.6666666666666666\n\n\nThe defect is shown with a dotted line below. Remember to always consider this defect.\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 3), sharey=True)\nax1.plot(accumulated_rewards, pdf)\nax1.set_title(\"PDF\")\nax1.set_ylim(bottom=0)\nax2.plot(accumulated_rewards, cdf)\nax2.set_title(\"CDF\")\nax2.set_ylim(bottom=0)\nax2.axhline(y=right_graph.defect(), linestyle='dotted', color='black')\nsns.despine()\n\n\n\n\n\n\n\n\nThere are also utility methods to get the stop probability i.e. probabilities of occupying each state at time t.\n\ngraph.stop_probability(0.2)\n\n[0.0,\n 0.5561531639166896,\n 0.07040541534825098,\n 0.0,\n 0.007095725804629082,\n 0.016348108066650276,\n 0.03374890558205247]\n\n\nWe can use that to compute the expected number of rabbits across time:\n\ntimes = np.arange(0, 2, 0.05)\nexpected_rabbits_left = [\n    np.sum(graph.stop_probability(i) \n           * np.sum(graph.states(), axis=1)) \n    for i in times\n    ]\n\nfig, ax = plt.subplots(1, 1, figsize=(4, 3))\nax.plot(times, expected_rabbits_left)\nax.set_xlabel('time')\nax.set_ylabel(\"Expected nr rabbits\")\nsns.despine()\n\n\n\n\n\n\n\n\nWe can also get the accumulated visiting time of a particular state. E.g. the total time before time t=0.5 where there was a rabbit on the right island:\n\nrewards = (graph.states()[:,1]&gt;0).astype(int)\nnp.sum(graph.accumulated_visiting_time(time=0.5) * rewards)\n\nnp.float64(0.04053231796047568)\n\n\n\ngraph.expected_residence_time()\n\n[0.0, 0.5038265306122448, 0.0, 0.0, 0.0, 0.0, 0.0]"
  },
  {
    "objectID": "examples/python/rabbits_full_py_api_example.html#discrete-phase-type-distributions",
    "href": "examples/python/rabbits_full_py_api_example.html#discrete-phase-type-distributions",
    "title": "Rabbits (full API example)",
    "section": "Discrete phase-type distributions",
    "text": "Discrete phase-type distributions\nWe can also work with discrete phase-type distributions. This is the number of jumps in a Markov Chain before absorption. We will model that any rabbit can find a carrot at each time with rate 0.1 and see how many carrots the rabbits will have found. We could of course just make a new state-space creation function, but we can also manipulate existing.\n\ncarrot_graph = graph.clone()\nvlength = carrot_graph.vertices_length()\ncarrot_vertices = np.repeat(False, vlength*2)\n\n\nfor i in range(vlength):\n    vertex = carrot_graph.vertex_at(i)\n    rabbits = sum(vertex.state())\n    \n    if rabbits &gt; 0:\n        obtained_carrot_vertex = carrot_graph.create_vertex([0])\n        # Go directly back to the state we came from\n        obtained_carrot_vertex.add_edge(vertex, 1)\n        # Rate of finding carrot\n        vertex.add_edge(obtained_carrot_vertex, rabbits * 0.1)\n        carrot_vertices[obtained_carrot_vertex.index()] = True\n\n\n---------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\nCell In[44], line 11\n      8 rabbits = sum(vertex.state())\n     10 if rabbits &gt; 0:\n---&gt; 11     obtained_carrot_vertex = carrot_graph.create_vertex([0])\n     12     # Go directly back to the state we came from\n     13     obtained_carrot_vertex.add_edge(vertex, 1)\n\nAttributeError: 'ptdalgorithms.ptdalgorithmscpp_pybind.Graph' object has no attribute 'create_vertex'\n\n\n\n\n\n\n\nvlength = carrot_graph.vertices_length()\ncarrot_vertices = np.repeat(False, vlength*2)\n\nfor i in range(vlength):\n    vertex = carrot_graph.vertex_at(i)\n    rabbits = sum(vertex.state())\n    \n    if rabbits &gt; 0:\n        obtained_carrot_vertex = carrot_graph.create_vertex([0])\n        # Go directly back to the state we came from\n        obtained_carrot_vertex.add_edge(vertex, 1)\n        # Rate of finding carrot\n        vertex.add_edge(obtained_carrot_vertex, rabbits * 0.1)\n        carrot_vertices[obtained_carrot_vertex.index()] = True\n\ncarrot_vertices = carrot_vertices[np.arange(carrot_graph.vertices_length())]\n\n# We now want to make the graph discrete. We do this by 'normalizing' the edges\n# This is imply scaling the vertices such that the total out-going rate is 1\n# As it is now the probability of transitions\nweights_were_multiplied_with = carrot_graph.normalize()\n\nprint(\"This is the discrete state space as a sub-transition matrix:\")\n#carrot_graph.as_matrices()\n\n\n---------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\nCell In[45], line 9\n      6 rabbits = sum(vertex.state())\n      8 if rabbits &gt; 0:\n----&gt; 9     obtained_carrot_vertex = carrot_graph.create_vertex([0])\n     10     # Go directly back to the state we came from\n     11     obtained_carrot_vertex.add_edge(vertex, 1)\n\nAttributeError: 'ptdalgorithms.ptdalgorithmscpp_pybind.Graph' object has no attribute 'create_vertex'\n\n\n\n\nfor vertex in carrot_graph.vertices():\n    print(vertex.index(),vertex.state(), vertex.edges())\n\n0 [0, 0] [1-(2,0)]\n1 [2, 0] [1-(1,1), 2-(0,0)]\n2 [1, 1] [1-(0,2), 2-(0,1), 1-(2,0), 4-(1,0)]\n3 [0, 0] []\n4 [0, 2] [1-(1,1), 4-(0,0)]\n5 [0, 1] [1-(1,0), 4-(0,0)]\n6 [1, 0] [1-(0,1), 2-(0,0)]\n\n\n\nfor vertex in carrot_graph.vertices():\n    print(vertex)\n    for edge in vertex.edges():\n        print(\"  \", edge)\n\n(0,0)\n   1-(2,0)\n(2,0)\n   1-(1,1)\n   2-(0,0)\n(1,1)\n   1-(0,2)\n   2-(0,1)\n   1-(2,0)\n   4-(1,0)\n(0,0)\n(0,2)\n   1-(1,1)\n   4-(0,0)\n(0,1)\n   1-(1,0)\n   4-(0,0)\n(1,0)\n   1-(0,1)\n   2-(0,0)\n\n\n\ncarrot_vertices.astype(int)\n\narray([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n\n\nWe now want to find the expected number of eaten carrots. We set the reward such that the carrot vertex has a reward of ‘1’.\n\nrewards = carrot_vertices.astype(int)\ncarrot_graph.expectation_discrete(rewards)\n\n\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\nCell In[49], line 2\n      1 rewards = carrot_vertices.astype(int)\n----&gt; 2 carrot_graph.expectation_discrete(rewards)\n\nRuntimeError: Failed: Rewards must match the number of vertices. Expected 7, got 14\n\n\n\nWe can verify that the number of carrots correspond to scaling the continuous graph:\n\ngraph.expectation(graph.states().sum(axis=1)) * 0.1\n\n0.09056122448979591\n\n\nOf course we cannot do this for other moments:\n\ncarrot_graph.variance_discrete(rewards)\n\n\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\nCell In[51], line 1\n----&gt; 1 carrot_graph.variance_discrete(rewards)\n\nRuntimeError: Failed: Rewards must match the number of vertices. Expected 7, got 14\n\n\n\nVerified by sampling:\n\nsamples = carrot_graph.sample_discrete(1000000, rewards)\nsamples = np.array(samples)\nnp.sum(samples**2) / 1000000 - ((np.sum(samples)) / 1000000)**2\n\n\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\nCell In[52], line 1\n----&gt; 1 samples = carrot_graph.sample_discrete(1000000, rewards)\n      2 samples = np.array(samples)\n      3 np.sum(samples**2) / 1000000 - ((np.sum(samples)) / 1000000)**2\n\nRuntimeError: Failed: Rewards must match the number of vertices. Expected 7, got 14\n\n\n\n\n# We can find the distribution function for the the total number of carrots found\ncarrots = np.arange(10)\n# Notice that with this reward transformation the graph is no longer sparse, as all paths through\n# the graph are represented!!\nfound_carrots_graph  = carrot_graph.reward_transform_discrete(rewards)\npmf = found_carrots_graph.pmf_discrete(carrots)\ncdf = found_carrots_graph.cdf_discrete(carrots)\n\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 3), sharey=True)\nx = np.arange(0, 10, 1)\nax1.plot(x, pmf)\nax1.set_title(\"PDF\")\nax1.set_xlabel('Total number of carrots found')\n# ax1.set_ylim(bottom=0)\nax2.plot(x, cdf)\nax2.set_title(\"CDF\")\n# ax2.set_ylim(bottom=0)\nax2.set_xlabel('Total number of carrots found')\nax2.axhline(y=right_graph.defect(), linestyle='dotted', color='black')\nsns.despine()"
  },
  {
    "objectID": "examples/python/rabbits_full_py_api_example.html#parameterized-edges",
    "href": "examples/python/rabbits_full_py_api_example.html#parameterized-edges",
    "title": "Rabbits (full API example)",
    "section": "Parameterized edges",
    "text": "Parameterized edges\nWe can parameterize the edges to easily update the weights of the edge\nWe do this by assigning a state to the edge.\nWe will now also say that the rate of rabbits jumping is proportional to the number of rabbits on the island.\nOur state is [rabbits able to jump, left flooding, right flooding]\n\n\ndef construct_rabbit_graph_params(nr_rabbits):\n    # We represent the vector as two integers, the number of rabbits on the left and right island\n    state_vector_length = 2\n    graph = ptd.Graph(state_vector_length)\n    initial_state = [nr_rabbits, 0]\n    # The initial state is the only starting state, with 100% starting probability\n    graph.starting_vertex().add_edge(\n      graph.find_or_create_vertex(initial_state),\n      1\n    )\n    index = 1\n    # Iterate over all unvisited vertices\n    while index &lt; graph.vertices_length():\n      vertex = graph.vertex_at(index)\n      state = vertex.state()\n      if state[0] &gt; 0:\n        # Rabbit jump left to right\n        child_state = [state[0] - 1, state[1] + 1]\n        vertex.add_edge_parameterized(\n          graph.find_or_create_vertex(child_state),\n          0,\n          [state[0],0,0]\n        )\n        # Left island flooding\n        child_state = c(0, state[1])\n        vertex.add_edge_parameterized(\n          graph.find_or_create_vertex(child_state),\n          0,\n          [0,1,0]\n        )\n      if state[1] &gt; 0:\n        # Rabbit jump right to left\n        child_state = [state[0] + 1, state[1] - 1]\n        vertex.add_edge_parameterized(\n          graph.find_or_create_vertex(child_state),\n          0, \n          [state[1],0,0]\n        )\n        # Right island flooding with rate of 4\n        child_state = [state[0], 0]\n        vertex.add_edge_parameterized(\n          graph.find_or_create_vertex(child_state),\n          0,\n          [0,0,1]\n        )\n      index = index + 1\n\n    return(graph)\n\nThe parameterized edges have what ever weight is assigned to them, and the state does not by itself mean anything.\n\nparam_graph = construct_rabbit_graph_params(2)\n\nIf we let the edge have a state, this gives us an easy way of changing the weights based on some model parameters. In this case, it is the rate of jumping left rate of flooding and right rate of flooding.\nThe update simply takes the inner product of the state vector and the model parameters, e.g. if the state is x1, x2 and the parameters are p1, p2, then the weight of the edge becomed x1p1+x2p2\n\nparam_graph.update_parameterized_weights([1, 2, 4])\nprint(\"Expectation (1,2,4):\", param_graph.expectation())\n\nparam_graph.update_parameterized_weights([2, 2, 4])\nprint(\"Expectation (1,2,4):\", param_graph.expectation())\n\nparam_graph.update_parameterized_weights([2, 4, 4])\nprint(\"Expectation (1,2,4):\", param_graph.expectation())\n\nparam_graph.update_parameterized_weights([2, 4, 18])\nprint(\"Expectation (1,2,4):\", param_graph.expectation())\n\nparam_graph.update_parameterized_weights([8, 4, 18])\nprint(\"Expectation (1,2,4):\", param_graph.expectation())\n\nExpectation (1,2,4): 0.5083056478405314\nExpectation (1,2,4): 0.49565217391304334\nExpectation (1,2,4): 0.30000000000000004\nExpectation (1,2,4): 0.22709632268736477\nExpectation (1,2,4): 0.17719439369563442\n\n\nINFO: building reward compute graph...\nINFO: building reward compute graph...\nINFO: building reward compute graph...\nINFO: building reward compute graph...\nINFO: building reward compute graph...\n\n\nNote that the moment graph has to be recalculated after updating weights\n\nparam_graph.update_parameterized_weights([1, 2, 4])\n#param_graph.as_matrices()\n      \nparam_graph.update_parameterized_weights([8, 4, 18])\n#param_graph.as_matrices()"
  },
  {
    "objectID": "examples/python/rabbits_full_py_api_example.html#time-inhomogeneity",
    "href": "examples/python/rabbits_full_py_api_example.html#time-inhomogeneity",
    "title": "Rabbits (full API example)",
    "section": "Time inhomogeneity",
    "text": "Time inhomogeneity\nIf the weights change over time - or new edges are added!\nThen the distribution is time inhomogeneous. The api also supports such distributions, but in limited manner.\nLike the pph, dph, etc. functions, it is a (very good) approximation based on very small steps. If the rates change dramatically, set the granularity as an argument to the functions!! E.g. set it to a high enough value.\nIf we pick a time far into the future, we can integrate under the pdf to find the expectation!\nIntegrating over accumulated visiting time:\n\nsum(graph.accumulated_visiting_time(10))\n\n0.5038265306014538\n\n\nThe first moment (expectation):\n\ngraph.expectation()\n\n0.5038265306122448\n\n\nSay at a certain point in time, the flooding starts!\nIn the beginning, there is no flooding\n\nparam_graph.update_parameterized_weights([1, 0, 0])\n\nWe can build a context to step over the distribution. Weights can be freely changed and edges added in such a context\n\n# import ptdalgorithms as ptd\n# import numpy as np\n\n# def c(*args):\n#     elem = []\n#     for arg in args:\n#         if hasattr(arg, '__len__') and len(arg) &gt; 1:\n#             elem.extend(arg)\n#         else:\n#             elem.append(arg)\n#     return np.array(elem)\n\n\n# nr_rabbits, flood_left, flood_right = 2, 2, 4\n\n# # we represent the vector as two integers, the number of \n# # rabbits on the left and right island\n# state_vector_length = 2\n# graph = ptd.Graph(state_vector_length)\n\n# # the initial state is the only starting state, with probability 1\n# initial_state = c(nr_rabbits, 0)\n# vertex = graph.find_or_create_vertex(initial_state)\n# graph.starting_vertex().add_edge(vertex, 1)\n\n# index = 1\n# # iterate over all unvisited vertices\n# while index &lt; graph.vertices_length():\n#     vertex = graph.vertex_at(index)\n#     state = vertex.state()\n    \n#     if state[0] &gt; 0:\n#         # rabbit jump left to right\n#         child_state = c(state[0] - 1, state[1] + 1)\n#         vertex.add_edge(\n#             graph.find_or_create_vertex(child_state),\n#             weight=1\n#         )\n#         # left island flooding\n#         child_state = c(0, state[1])\n#         vertex.add_edge(\n#             graph.find_or_create_vertex(child_state), \n#             weight=flood_left\n#         )\n#     if state[1] &gt; 0:   \n#         child_state = c(state[0] + 1, state[1] - 1)\n#         vertex.add_edge(\n#             graph.find_or_create_vertex(child_state),\n#             weight=1\n#         )\n#         # right island flooding\n#         child_state = c(state[0], 0)\n#         vertex.add_edge(\n#             graph.find_or_create_vertex(child_state), \n#             weight=flood_right\n#         )\n\n#     index += 1\n    \n# # graph.plot(nodesep=1, ranksep=0.1)\n\n\n\n# ctx = graph.distribution_context()\n# cdfs = []\n# times = []\n\n# # while ctx.time() &lt; 1.5:\n# while ctx.cdf() &lt; 0.999:\n\n#     cdfs.append(ctx.cdf())\n#     times.append(ctx.time())\n#     param_graph.update_parameterized_weights(\n#         [1,\n#         ctx.time() - 1.5, \n#         2 * ctx.time() - 1.5\n#         ]\n#     )\n#     ctx.step()\n\nIt increases by every time step. Time until all rabbits are dead. Flooding increases linearly after 1.5 time units:\n\nparam_graph.update_parameterized_weights([1, 0, 0])\n\nctx = param_graph.distribution_context()\ncdfs = []\ntimes = []\n\nwhile ctx.time() &lt; 1.5:\n    cdfs.append(ctx.cdf())\n    times.append(ctx.time())\n    ctx.step()\n\n#param_graph.update_parameterized_weights([1, 1, 1])\n\n# at time 1.5, the flooding starts!\nwhile ctx.cdf() &lt; 0.999:\n    cdfs.append(ctx.cdf())\n    times.append(ctx.time())\n    param_graph.update_parameterized_weights(\n        [1,\n        ctx.time() - 1.5, \n        2 * ctx.time() - 1.5\n        ]\n    )\n    ctx.step()\n\nfig, ax = plt.subplots(1, 1, figsize=(4, 3))\nax.plot(times, cdfs)\nsns.despine()\n\n\n\n\n\n\n\n\nIf we pick a time far into the future, we can integrate under it to find the expectation. This means that we can scale by a reward, and thereby find the marginal expectation.\nSumming over accumulated visiting time (with reward):\n\nnp.sum(graph.accumulated_visiting_time(10)*graph.states()[:,1])\n\nnp.float64(0.09438775509887067)\n\n\nThe first moment (expectation) (with reward):\n\ngraph.expectation(graph.states()[:,1])\n\n0.09438775510204081\n\n\nBut if the time is not far into the future, we get the expectation up to a certain point in time.\nExpectation (rewarded) when truncating at 0.05 time:\n\nnp.sum(graph.accumulated_visiting_time(0.05)*graph.states()[:,1])\n\nnp.float64(0.0011713234985744549)\n\n\nUntruncated expectation:\n\ngraph.expectation(graph.states()[:,1])\n\n0.09438775510204081\n\n\nExpectation (rewarded) when starting at 0.05 time:\n\ngraph.expected_waiting_time(graph.states()[:,1])\n\n[0.09438775510204081,\n 0.09438775510204081,\n 0.28316326530612246,\n 0.0,\n 0.4566326530612244,\n 0.21428571428571422,\n 0.0714285714285714]\n\n\n\nnp.sum(graph.stop_probability(0.05)*np.array(graph.expected_waiting_time(graph.states()[:,1])))\n\nnp.float64(0.09325811466426455)\n\n\nSubtracting these gives the same value:\n\n(graph.expectation(graph.states()[:,1]) \\\n     - np.sum(graph.stop_probability(0.05) \\\n              * np.array(graph.expected_waiting_time(graph.states()[:,1])))\n)\n\nnp.float64(0.0011296404377762609)\n\n\nWe can increase granularity for better performance:\n\nnp.sum(graph.accumulated_visiting_time(0.05, granularity=1000000)*graph.states()[:,1])\n\nnp.float64(0.0011138317897953385)"
  },
  {
    "objectID": "examples/python/rabbits_full_py_api_example.html#building-the-state-space-in-c",
    "href": "examples/python/rabbits_full_py_api_example.html#building-the-state-space-in-c",
    "title": "Rabbits (full API example)",
    "section": "Building the state space in C",
    "text": "Building the state space in C\nVery large models can be take a long time to construct. So if you have deloped a model that you need to construct repeatedly, the library allow you to implement the state construction as a stand-alone C/C++ extension available as python module.\nThe C code building the state space for the rabit model looks like this:\nptdalgorithms::Graph build(int starting_rabbits, float flooding_left, float flooding_right) {\n\n    size_t state_size = 2;\n    struct ptd_graph *graph = ptd_graph_create(state_size);\n    struct ptd_avl_tree *avl_tree = ptd_avl_tree_create(state_size);\n    int *initial_state = (int*)calloc(graph-&gt;state_length, sizeof(*initial_state));\n    int *child_state = (int*)calloc(graph-&gt;state_length, sizeof(*initial_state));\n    initial_state[0] = starting_rabbits;\n    ptd_graph_add_edge(\n            graph-&gt;starting_vertex,\n            ptd_find_or_create_vertex(graph, avl_tree, initial_state),\n            1\n    );\n    for (size_t k = 1; k &lt; graph-&gt;vertices_length; k++) {\n        struct ptd_vertex *vertex = graph-&gt;vertices[k];\n        int *state = vertex-&gt;state;\n        if (state[0] &gt; 0) {\n            memcpy(child_state, vertex-&gt;state, graph-&gt;state_length * sizeof(int));\n            child_state[0] -= 1;\n            child_state[1] += 1;\n\n            ptd_graph_add_edge(\n                    vertex,\n                    ptd_find_or_create_vertex(graph, avl_tree, child_state),\n                    1\n            );\n            memcpy(child_state, vertex-&gt;state, graph-&gt;state_length * sizeof(int));\n            child_state[0] = 0;\n            ptd_graph_add_edge(\n                    vertex,\n                    ptd_find_or_create_vertex(graph, avl_tree, child_state),\n                    flooding_left\n            );\n        }\n        if (state[1] &gt; 0) {\n            memcpy(child_state, vertex-&gt;state, graph-&gt;state_length * sizeof(int));\n            child_state[1] -= 1;\n            child_state[0] += 1;\n            ptd_graph_add_edge(\n                    vertex,\n                    ptd_find_or_create_vertex(graph, avl_tree, child_state),\n                    1\n            );\n            memcpy(child_state, vertex-&gt;state, graph-&gt;state_length * sizeof(int));\n            child_state[1] = 0;\n            ptd_graph_add_edge(\n                    vertex,\n                    ptd_find_or_create_vertex(graph, avl_tree, child_state),\n                    flooding_right\n            );\n        }\n    }\n    free(child_state);\n    ptdalgorithms::Graph *result = new ptdalgorithms::Graph(graph, avl_tree);\n    return *result;\n}\n\nTo access the function from python, you need to put it a separate file (`rabbit_state_space.cpp`) with the header and footer shown below:\n\n```{c}\n#include &lt;pybind11/pybind11.h&gt;\n#include &lt;ptdalgorithms.h&gt;\n#include \"stdint.h\"\n#include \"stdlib.h\"\n\nnamespace py = pybind11;\nusing namespace pybind11::literals;\n/*******************************************/\n\n\n/* Your build function goes here */\n\n\n/********************************************/\nPYBIND11_MODULE(rabbit_state_space, m) {     /* &lt;- NB: the model name must match the file name */\n     m.def(\"build\", &build);\n}\n\n/*\n&lt;%\nsetup_pybind11(cfg)\n%&gt;\n*/\nYou can see the complete code in rabbit_state_space.cpp.\nThen all you need to do is install cppimport\n\n! pip install cppimport\n\nRequirement already satisfied: cppimport in /Users/kmt/miniconda3/envs/ptd/lib/python3.11/site-packages (22.8.2)\nRequirement already satisfied: mako in /Users/kmt/miniconda3/envs/ptd/lib/python3.11/site-packages (from cppimport) (1.3.9)\nRequirement already satisfied: pybind11 in /Users/kmt/miniconda3/envs/ptd/lib/python3.11/site-packages (from cppimport) (2.13.6)\nRequirement already satisfied: filelock in /Users/kmt/miniconda3/envs/ptd/lib/python3.11/site-packages (from cppimport) (3.13.1)\nRequirement already satisfied: MarkupSafe&gt;=0.9.2 in /Users/kmt/miniconda3/envs/ptd/lib/python3.11/site-packages (from mako-&gt;cppimport) (2.1.5)\n\n\nand then run this code to import your build function.\n\n# import ptdalgorithms\nimport cppimport.import_hook\nimport rabbit_state_space # this will pause for a moment to compile the module\n\nThen you can use it to construct your graph like this:\n\ngraph = ptd.Graph(rabbit_state_space.build(2, 2, 4))\ngraph.plot()"
  },
  {
    "objectID": "c_api/index.html",
    "href": "c_api/index.html",
    "title": "ptdalgorithms",
    "section": "",
    "text": "These pages are under construction"
  },
  {
    "objectID": "pages/tutorial.html",
    "href": "pages/tutorial.html",
    "title": "ptdalgorithms",
    "section": "",
    "text": "PythonRC\n\n\nprint(\"Hello world\")\n\n\ncat(\"Hello world\")\n\n\nprintf(\"Hello World\");"
  },
  {
    "objectID": "pages/moments.html",
    "href": "pages/moments.html",
    "title": "Moments",
    "section": "",
    "text": "This pages is under construction",
    "crumbs": [
      "Basics",
      "Moments"
    ]
  },
  {
    "objectID": "pages/getting_started.html",
    "href": "pages/getting_started.html",
    "title": "Getting started",
    "section": "",
    "text": "The ptdalgorithms library provides fast and scalable algorithms for constructing and computing properties of phase-type distributions with support for both continuous and discrete, unrewarded and rewarded, univariate and multivariate distributions. For sparse models, it can be orders of magnitude faster. The code is written in C, but exposes an interface to both C, R and Python through a C++ layer.\nThe library computes moments (e.g. expectation, variance, covariance), distribution functions (pdf, cdf, pmf), laplace transform, and Markov chain stopping time probabilities. Although phase-type distributions are time-homogeneous, the library also computes moments and univariate distributions for epoch-wise time-inhomogeneous models as well as full joint probability distributions.",
    "crumbs": [
      "Getting started"
    ]
  },
  {
    "objectID": "pages/getting_started.html#installation",
    "href": "pages/getting_started.html#installation",
    "title": "Getting started",
    "section": "Installation",
    "text": "Installation\nconda install -c munch-group -c conda-forge ptdalgorithms",
    "crumbs": [
      "Getting started"
    ]
  },
  {
    "objectID": "pages/getting_started.html#quickstart",
    "href": "pages/getting_started.html#quickstart",
    "title": "Getting started",
    "section": "Quickstart",
    "text": "Quickstart\n\n\n\n\n\n\nThis pages is under construction",
    "crumbs": [
      "Getting started"
    ]
  },
  {
    "objectID": "pages/state_lumping.html",
    "href": "pages/state_lumping.html",
    "title": "State lumping",
    "section": "",
    "text": "This pages is under construction",
    "crumbs": [
      "Advanced",
      "State lumping"
    ]
  },
  {
    "objectID": "pages/joint_prob.html",
    "href": "pages/joint_prob.html",
    "title": "Joint probabilities",
    "section": "",
    "text": "This pages is under construction",
    "crumbs": [
      "Advanced",
      "Joint probabilities"
    ]
  }
]