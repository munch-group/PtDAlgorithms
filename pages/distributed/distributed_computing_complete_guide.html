<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.25">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Distributed Computing with PtDAlgorithms - Complete Guide</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../pages/distributed/slurm_cluster_setup.html" rel="next">
<link href="../../pages/svgd/svgd_with_symbolic_dag.html" rel="prev">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-7b89279ff1a6dce999919e0e67d4d9ec.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-a4e33bbe4f8c8978a0e41d3bc496056e.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../../api/_styles-quartodoc.css">
<link rel="stylesheet" href="../../numpy.css">
</head>

<body class="nav-sidebar floating nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../logo.png" alt="Phasic" class="navbar-logo light-content">
    <img src="../../logo.png" alt="Phasic" class="navbar-logo dark-content">
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link active" href="../../pages/getting_started.html" aria-current="page"> 
<span class="menu-text">Documentation</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../api/"> 
<span class="menu-text">Python API reference</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../r_api/"> 
<span class="menu-text">R API reference</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../c_api/"> 
<span class="menu-text">C API reference</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/munch-group/ptdalgorithms/"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../pages/distributed/distributed_computing_complete_guide.html">Distributed Computing</a></li><li class="breadcrumb-item"><a href="../../pages/distributed/distributed_computing_complete_guide.html">Distributed Computing with PtDAlgorithms - Complete Guide</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="../../index.html" class="sidebar-logo-link">
      </a>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/getting_started.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Getting Started</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Tutorials</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
 <span class="menu-text">pages/background/tldr.qmd</span>
  </li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/tutorials/rabbits_full_py_api_example.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Rabbits Islands - Full API</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/tutorials/coalescent_full_py_api_example.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Coalescent - Full API</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/tutorials/state_space_construction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Building models</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Bayesian inference</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/svgd/caching.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Caching System Guide</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/svgd/svgd.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">SVGD Inference</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/svgd/svgd_with_symbolic_dag.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">SVGD Inference with Symbolic DAG Optimization</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Distributed Computing</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/distributed/distributed_computing_complete_guide.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Distributed Computing with PtDAlgorithms - Complete Guide</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/distributed/slurm_cluster_setup.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">SLURM Cluster Setup and Configuration</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/distributed/cpu_monitoring.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">CPU monitoring</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">State space patterns</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/modelling/state_lumping.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">State lumping</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/modelling/laplace.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Laplace transform</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/modelling/epochs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Epochs</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/modelling/joint_prob.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Joint probabilities</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">Popgen examples</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
 <span class="menu-text">pages/modelling/coalescent-jointprob.ipynb</span>
  </li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/popgen/isolation_migration.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">isolation_migration.html</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/popgen/two-island-two-locus-arg.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Two Island Two Locus Argument</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">Phase-type distributions</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/background/math_and_alg.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Math and Algorithms</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/background/symbolic_gauss_elimination.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Symbolic Graph Elimination for Efficient Parameterized Phase-Type Distributions</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true">
 <span class="menu-text">Devel</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
 <span class="menu-text">pages/devel/architecture.qmd</span>
  </li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="https://github.com/munch-group/ptdalgorithms/issues" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Issue Tracker</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#understanding-the-need-for-distributed-computing" id="toc-understanding-the-need-for-distributed-computing" class="nav-link active" data-scroll-target="#understanding-the-need-for-distributed-computing">Understanding the Need for Distributed Computing</a></li>
  <li><a href="#the-architecture-of-distributed-computation" id="toc-the-architecture-of-distributed-computation" class="nav-link" data-scroll-target="#the-architecture-of-distributed-computation">The Architecture of Distributed Computation</a></li>
  <li><a href="#the-power-of-automatic-initialization" id="toc-the-power-of-automatic-initialization" class="nav-link" data-scroll-target="#the-power-of-automatic-initialization">The Power of Automatic Initialization</a></li>
  <li><a href="#understanding-devices-and-processes" id="toc-understanding-devices-and-processes" class="nav-link" data-scroll-target="#understanding-devices-and-processes">Understanding Devices and Processes</a></li>
  <li><a href="#building-phase-type-distribution-models-for-distributed-inference" id="toc-building-phase-type-distribution-models-for-distributed-inference" class="nav-link" data-scroll-target="#building-phase-type-distribution-models-for-distributed-inference">Building Phase-Type Distribution Models for Distributed Inference</a></li>
  <li><a href="#converting-graphs-to-jax-functions" id="toc-converting-graphs-to-jax-functions" class="nav-link" data-scroll-target="#converting-graphs-to-jax-functions">Converting Graphs to JAX Functions</a></li>
  <li><a href="#generating-synthetic-data-for-demonstration" id="toc-generating-synthetic-data-for-demonstration" class="nav-link" data-scroll-target="#generating-synthetic-data-for-demonstration">Generating Synthetic Data for Demonstration</a></li>
  <li><a href="#stein-variational-gradient-descent-theory-and-practice" id="toc-stein-variational-gradient-descent-theory-and-practice" class="nav-link" data-scroll-target="#stein-variational-gradient-descent-theory-and-practice">Stein Variational Gradient Descent: Theory and Practice</a></li>
  <li><a href="#setting-up-distributed-svgd" id="toc-setting-up-distributed-svgd" class="nav-link" data-scroll-target="#setting-up-distributed-svgd">Setting Up Distributed SVGD</a></li>
  <li><a href="#executing-distributed-svgd-inference" id="toc-executing-distributed-svgd-inference" class="nav-link" data-scroll-target="#executing-distributed-svgd-inference">Executing Distributed SVGD Inference</a></li>
  <li><a href="#analyzing-posterior-results" id="toc-analyzing-posterior-results" class="nav-link" data-scroll-target="#analyzing-posterior-results">Analyzing Posterior Results</a></li>
  <li><a href="#visualizing-the-inference-results" id="toc-visualizing-the-inference-results" class="nav-link" data-scroll-target="#visualizing-the-inference-results">Visualizing the Inference Results</a></li>
  <li><a href="#understanding-distributed-performance" id="toc-understanding-distributed-performance" class="nav-link" data-scroll-target="#understanding-distributed-performance">Understanding Distributed Performance</a></li>
  <li><a href="#deploying-on-slurm-clusters" id="toc-deploying-on-slurm-clusters" class="nav-link" data-scroll-target="#deploying-on-slurm-clusters">Deploying on SLURM Clusters</a></li>
  <li><a href="#advanced-topics-and-optimization-strategies" id="toc-advanced-topics-and-optimization-strategies" class="nav-link" data-scroll-target="#advanced-topics-and-optimization-strategies">Advanced Topics and Optimization Strategies</a></li>
  <li><a href="#troubleshooting-distributed-computation" id="toc-troubleshooting-distributed-computation" class="nav-link" data-scroll-target="#troubleshooting-distributed-computation">Troubleshooting Distributed Computation</a></li>
  <li><a href="#summary-and-best-practices" id="toc-summary-and-best-practices" class="nav-link" data-scroll-target="#summary-and-best-practices">Summary and Best Practices</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../pages/distributed/distributed_computing_complete_guide.html">Distributed Computing</a></li><li class="breadcrumb-item"><a href="../../pages/distributed/distributed_computing_complete_guide.html">Distributed Computing with PtDAlgorithms - Complete Guide</a></li></ol></nav>
<div class="quarto-title">
<h1 class="title">Distributed Computing with PtDAlgorithms - Complete Guide</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>This comprehensive guide explores the distributed computing capabilities built into PtDAlgorithms, demonstrating how computational workloads can be scaled from a single laptop to massive computing clusters spanning hundreds of nodes. The material covered here synthesizes everything you need to know about parallel and distributed computing in the context of phase-type distribution analysis, from fundamental concepts through practical implementation and deployment on production clusters.</p>
<p>The journey from sequential computation on a single machine to distributed computation across many machines has historically been fraught with complexity. Researchers and practitioners have traditionally faced hundreds of lines of boilerplate code, intricate environment variable configurations, complex inter-process communication protocols, and cluster-specific quirks that make code difficult to port between different computing environments. The distributed computing framework in PtDAlgorithms was designed specifically to eliminate these barriers, allowing you to write code once and run it anywhere, from your laptop during development to a massive SLURM cluster for production runs.</p>
<section id="understanding-the-need-for-distributed-computing" class="level1">
<h1>Understanding the Need for Distributed Computing</h1>
<p>Before diving into implementation details, it’s worth understanding why distributed computing matters for phase-type distribution analysis and Bayesian inference. When working with complex phase-type distributions, particularly those arising from population genetic models or intricate Markov processes, the computational demands can quickly become overwhelming for a single machine. Consider a typical Stein Variational Gradient Descent (SVGD) inference problem where we maintain a swarm of particles, each representing a hypothesis about model parameters. Each particle must evaluate the likelihood function, which in our case means computing properties of a phase-type distribution at multiple time points. With hundreds or thousands of particles, each requiring potentially expensive graph traversals and numerical computations, the total computational burden can easily exceed what a single CPU core can handle in reasonable time.</p>
<p>The computational challenge grows multiplicatively rather than additively. If we have 500 particles and each particle requires evaluation at 50 time points across 1000 iterations, we’re looking at 25 million individual distribution evaluations. Even if each evaluation takes just 10 milliseconds, that’s nearly 70 hours of computation on a single core. By distributing these computations across multiple devices and multiple nodes, we can reduce wall-clock time from days to hours or even minutes, making previously impractical analyses feasible.</p>
<p>Beyond raw computational speed, distributed computing also enables larger-scale problems. With more compute resources, we can maintain more particles for better posterior approximations, run longer chains for improved convergence, or tackle larger state spaces that would exhaust the memory of a single machine. The distributed framework in PtDAlgorithms handles all the orchestration needed to achieve these benefits while keeping your code simple and portable.</p>
</section>
<section id="the-architecture-of-distributed-computation" class="level1">
<h1>The Architecture of Distributed Computation</h1>
<p>Understanding how distributed computation works under the hood helps clarify both its power and its limitations. At its core, distributed computing in PtDAlgorithms builds on JAX’s distributed capabilities, which in turn leverage XLA (Accelerated Linear Algebra) for low-level execution and coordination. When you initialize distributed computing, several things happen behind the scenes to set up the computational environment.</p>
<p>First, the system needs to understand the computational topology: how many processes (typically corresponding to physical machines or nodes) are participating, what rank each process holds in the coordination hierarchy, and how many computational devices (CPU cores or GPU devices) each process controls. In a SLURM cluster environment, this information comes from environment variables that the cluster scheduler sets when launching your job. The SLURM_NTASKS variable tells us how many processes exist, SLURM_PROCID identifies which process we are, SLURM_CPUS_PER_TASK indicates how many CPU cores this process should use, and SLURM_JOB_NODELIST provides the list of machines involved. By parsing these variables automatically, the initialization function removes the burden of manual environment parsing that traditionally required dozens of lines of error-prone code.</p>
<p>Second, the processes need to establish communication channels. In JAX’s distributed model, one process serves as the coordinator, and all other processes connect to it. The coordinator is typically the process with rank 0, and it needs a known network address where others can reach it. In a SLURM environment, we extract the hostname of the first node in the node list and combine it with a specified port number (defaulting to 12345) to create the coordinator address. Each process then initializes its JAX distributed runtime with this address, its own rank, and the total number of processes. This creates a communication fabric that JAX uses internally to coordinate data movement and synchronization during parallel operations.</p>
<p>Third, the local devices on each process need configuration. JAX normally detects available hardware automatically, but in CPU-only cluster environments, we often want to create multiple logical devices corresponding to CPU cores for better parallelization. The XLA_FLAGS environment variable, specifically the xla_force_host_platform_device_count flag, controls this. By setting it to match SLURM_CPUS_PER_TASK, we ensure JAX creates one device per allocated core, enabling fine-grained parallel execution within each node.</p>
<div id="setup-imports" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the necessary components for distributed computing</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> jax</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> jax.numpy <span class="im">as</span> jnp</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> ptdalgorithms <span class="im">import</span> initialize_distributed, Graph, SVGD</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Set up plotting style for consistent visualization</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>plt.style.use(<span class="st">'seaborn-v0_8-darkgrid'</span>)</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>plt.rcParams[<span class="st">'figure.figsize'</span>] <span class="op">=</span> (<span class="dv">12</span>, <span class="dv">6</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="the-power-of-automatic-initialization" class="level1">
<h1>The Power of Automatic Initialization</h1>
<p>The initialize_distributed function represents a significant simplification over traditional distributed computing setup. In the past, setting up distributed JAX computation required detecting the execution environment, parsing various environment variables with appropriate error handling, determining the coordinator node through system calls to SLURM utilities, configuring JAX’s device detection, setting XLA compilation flags, initializing the distributed runtime with correct addresses and ranks, and implementing fallback logic for local execution. This typically resulted in 200 or more lines of boilerplate code that needed to be copied between projects and debugged independently each time.</p>
<p>The single-line initialization replaces all of this complexity with automatic detection and sensible defaults. When you call initialize_distributed, it first checks whether it’s running in a SLURM environment by looking for the SLURM_JOB_ID environment variable. If found, it extracts all relevant SLURM variables, parses the node list to identify the coordinator, computes the coordinator address, sets up JAX with appropriate device counts, and initializes distributed coordination. If not running under SLURM, it falls back to local execution with multiple CPU devices, allowing the same code to run on your laptop during development and on a cluster during production runs without any modifications.</p>
<p>Let’s initialize the distributed environment and examine what information it provides about our computational setup.</p>
<div id="initialize" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize distributed computing - this one line replaces 200+ lines of boilerplate</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="co"># The function automatically detects whether we're running on SLURM or locally</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co"># and configures JAX appropriately for the environment</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>dist_info <span class="op">=</span> initialize_distributed(</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>    coordinator_port<span class="op">=</span><span class="dv">12345</span>,  <span class="co"># Port for inter-process communication</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>    platform<span class="op">=</span><span class="st">"cpu"</span>,          <span class="co"># Use CPU devices (change to "gpu" for GPU clusters)</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>    enable_x64<span class="op">=</span><span class="va">True</span>          <span class="co"># Enable 64-bit precision for numerical accuracy</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="co"># The returned configuration object contains all information about our computational environment</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Distributed Computing Configuration"</span>)</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Job ID: </span><span class="sc">{</span>dist_info<span class="sc">.</span>job_id <span class="cf">if</span> dist_info<span class="sc">.</span>job_id <span class="cf">else</span> <span class="st">'Local execution'</span><span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Process rank: </span><span class="sc">{</span>dist_info<span class="sc">.</span>process_id<span class="sc">}</span><span class="ss"> of </span><span class="sc">{</span>dist_info<span class="sc">.</span>num_processes<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Is coordinator: </span><span class="sc">{</span>dist_info<span class="sc">.</span>is_coordinator<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Coordinator address: </span><span class="sc">{</span>dist_info<span class="sc">.</span>coordinator_address<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Local devices: </span><span class="sc">{</span>dist_info<span class="sc">.</span>local_device_count<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Global devices: </span><span class="sc">{</span>dist_info<span class="sc">.</span>global_device_count<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Platform: </span><span class="sc">{</span>dist_info<span class="sc">.</span>platform<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Only the coordinator process should print certain information to avoid cluttered output</span></span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> dist_info.is_coordinator:</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">This process is the coordinator. It will orchestrate distributed operations."</span>)</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Total computational capacity: </span><span class="sc">{</span>dist_info<span class="sc">.</span>global_device_count<span class="sc">}</span><span class="ss"> devices across </span><span class="sc">{</span>dist_info<span class="sc">.</span>num_processes<span class="sc">}</span><span class="ss"> processes"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="understanding-devices-and-processes" class="level1">
<h1>Understanding Devices and Processes</h1>
<p>The distinction between processes and devices is fundamental to understanding distributed computing in JAX. A process corresponds to an operating system process, typically one per physical machine or node in a cluster. Each process can control multiple devices, which are the actual computational units that execute operations. On a CPU-based cluster, devices typically correspond to CPU cores, while on GPU systems, devices might be individual GPU cards.</p>
<p>This two-level hierarchy enables flexible parallelization strategies. Within a single node, JAX’s pmap (parallel map) operation distributes computation across the local devices, executing the same operation on different data in a SIMD (Single Instruction Multiple Data) fashion. Across nodes, JAX’s distributed runtime coordinates data movement and synchronization, ensuring that operations spanning multiple processes execute correctly despite the physical separation of the machines.</p>
<p>The total computational capacity of your cluster equals the number of processes times the devices per process. For example, if you have 4 nodes with 16 CPU cores each, you have 4 processes and 64 total devices. When you distribute a computation across these 64 devices, JAX automatically handles both the intra-node parallelization (across the 16 cores within each node) and the inter-node coordination (between the 4 nodes), presenting a unified programming model where you simply say “execute this function in parallel across all devices” and the system handles the details.</p>
<p>Let’s examine the JAX devices available in our current environment to see this hierarchy in action.</p>
<div id="examine-devices" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># JAX provides direct access to the device configuration</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>devices <span class="op">=</span> jax.devices()</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"JAX Device Configuration"</span>)</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Total devices visible: </span><span class="sc">{</span><span class="bu">len</span>(devices)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Device details:"</span>)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, device <span class="kw">in</span> <span class="bu">enumerate</span>(devices[:<span class="dv">10</span>]):  <span class="co"># Show first 10 to avoid overwhelming output</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Device </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>device<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="bu">len</span>(devices) <span class="op">&gt;</span> <span class="dv">10</span>:</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  ... and </span><span class="sc">{</span><span class="bu">len</span>(devices) <span class="op">-</span> <span class="dv">10</span><span class="sc">}</span><span class="ss"> more devices"</span>)</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Verify that our initialization correctly configured the device count</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> <span class="bu">len</span>(devices) <span class="op">==</span> dist_info.global_device_count, <span class="st">"Device count mismatch!"</span></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Verification: Device count matches distributed configuration ✓"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="building-phase-type-distribution-models-for-distributed-inference" class="level1">
<h1>Building Phase-Type Distribution Models for Distributed Inference</h1>
<p>Before we can demonstrate distributed inference, we need a phase-type distribution model to work with. The coalescent process from population genetics provides an excellent example because it’s both scientifically meaningful and computationally interesting. The coalescent describes how genetic lineages merge backward in time, starting with a sample of DNA sequences from present-day individuals and tracing their ancestry back to a common ancestor.</p>
<p>In the simplest coalescent model, we have n sampled lineages that can coalesce pairwise at rate n(n-1)/2, where the rate reflects the probability that any two lineages find their common ancestor in a small time interval. When two lineages coalesce, we transition from n lineages to n-1 lineages, and the process continues until only one lineage remains, representing the most recent common ancestor of the sample. The distribution of time until this final common ancestor follows a phase-type distribution where states represent different numbers of lineages and transitions represent coalescent events.</p>
<p>What makes this particularly suitable for demonstrating parameterized models is that the coalescent rate depends on the effective population size. Specifically, if we scale time in units of 2N generations (where N is the effective population size), the coalescent rate for n lineages is n(n-1)/2 times a parameter θ that encapsulates both the population size and mutation rate. By building a parameterized graph where edge rates are linear functions of θ, we can efficiently evaluate the likelihood across different parameter values without rebuilding the graph structure.</p>
<p>The callback-based graph construction approach used here deserves explanation. Rather than manually creating every vertex and edge, we provide a callback function that returns the possible transitions from any given state. The Graph constructor calls this function for the initial empty state to determine starting states, then iteratively explores the reachable state space by calling the callback for each new state discovered. This lazy construction approach is memory-efficient and natural for models defined by transition rules rather than explicit state enumeration.</p>
<div id="build-coalescent" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> build_coalescent_model(nr_samples<span class="op">=</span><span class="dv">10</span>):</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Construct a parameterized coalescent model using callback-based graph construction.</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="co">    The callback function is called with the current state and must return a list of</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="co">    possible transitions. Each transition is a tuple of (next_state, weight, edge_coefficients)</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="co">    where edge_coefficients specify how this transition's rate depends on parameters.</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="co">    For the coalescent, we start with nr_samples lineages in a single state and allow</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="co">    pairwise coalescence until reaching a single ancestral lineage. The coalescent rate</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a><span class="co">    for n lineages is n(n-1)/2 times the parameter θ.</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> coalescent_callback(state, nr_samples<span class="op">=</span>nr_samples):</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>        <span class="co"># When called with empty state, return the initial configuration</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="kw">not</span> state.size:</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Start with all samples as separate lineages</span></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>            <span class="co"># The edge coefficient [1] means this initialization probability is constant</span></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> [[[nr_samples], <span class="fl">1.0</span>, [<span class="fl">1.0</span>]]]</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>        <span class="co"># For non-empty states, determine possible transitions</span></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>        n_lineages <span class="op">=</span> state[<span class="dv">0</span>]</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> n_lineages <span class="op">&gt;</span> <span class="dv">1</span>:</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Coalescent event: n lineages → n-1 lineages</span></span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Rate is n(n-1)/2 times the parameter θ</span></span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>            coalescent_rate <span class="op">=</span> n_lineages <span class="op">*</span> (n_lineages <span class="op">-</span> <span class="dv">1</span>) <span class="op">/</span> <span class="dv">2</span></span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>            next_state <span class="op">=</span> [n_lineages <span class="op">-</span> <span class="dv">1</span>]</span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>            <span class="co"># The weight 0.0 means this is not a probability (we'll multiply by θ later)</span></span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a>            <span class="co"># The edge coefficient [coalescent_rate] means the actual rate is coalescent_rate * θ</span></span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> [[next_state, <span class="fl">0.0</span>, [coalescent_rate]]]</span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a>        <span class="co"># When we reach 1 lineage, we're in the absorbing state (MRCA reached)</span></span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> []</span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Build the parameterized graph using the callback</span></span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a>    <span class="co"># The parameterized=True flag indicates edges have parameter-dependent rates</span></span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a>    graph <span class="op">=</span> Graph(</span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a>        callback<span class="op">=</span>coalescent_callback,</span>
<span id="cb4-40"><a href="#cb4-40" aria-hidden="true" tabindex="-1"></a>        parameterized<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb4-41"><a href="#cb4-41" aria-hidden="true" tabindex="-1"></a>        nr_samples<span class="op">=</span>nr_samples</span>
<span id="cb4-42"><a href="#cb4-42" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb4-43"><a href="#cb4-43" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-44"><a href="#cb4-44" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> graph</span>
<span id="cb4-45"><a href="#cb4-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-46"><a href="#cb4-46" aria-hidden="true" tabindex="-1"></a><span class="co"># Construct a coalescent model with 8 sampled sequences</span></span>
<span id="cb4-47"><a href="#cb4-47" aria-hidden="true" tabindex="-1"></a>nr_samples <span class="op">=</span> <span class="dv">8</span></span>
<span id="cb4-48"><a href="#cb4-48" aria-hidden="true" tabindex="-1"></a>coalescent_graph <span class="op">=</span> build_coalescent_model(nr_samples<span class="op">=</span>nr_samples)</span>
<span id="cb4-49"><a href="#cb4-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-50"><a href="#cb4-50" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> dist_info.is_coordinator:</span>
<span id="cb4-51"><a href="#cb4-51" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Coalescent Model Construction"</span>)</span>
<span id="cb4-52"><a href="#cb4-52" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Sampled sequences: </span><span class="sc">{</span>nr_samples<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb4-53"><a href="#cb4-53" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"State space size: </span><span class="sc">{</span>coalescent_graph<span class="sc">.</span>vertices_length()<span class="sc">}</span><span class="ss"> states"</span>)</span>
<span id="cb4-54"><a href="#cb4-54" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Parameter dimension: 1 (θ = scaled population size)"</span>)</span>
<span id="cb4-55"><a href="#cb4-55" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">The state space includes all configurations from </span><span class="sc">{</span>nr_samples<span class="sc">}</span><span class="ss"> lineages down to 1."</span>)</span>
<span id="cb4-56"><a href="#cb4-56" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Each state represents a number of lineages, and transitions represent coalescent events."</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="converting-graphs-to-jax-functions" class="level1">
<h1>Converting Graphs to JAX Functions</h1>
<p>To use phase-type distributions in modern machine learning and inference workflows, we need to convert them into functions that JAX can work with. JAX’s power comes from its ability to transform functions through operations like automatic differentiation, just-in-time compilation, vectorization, and parallelization. However, our phase-type distribution graphs are complex C++ objects that JAX can’t directly manipulate. The pmf_from_graph function solves this problem by creating a JAX-compatible wrapper that calls into the C++ implementation through a foreign function interface (FFI).</p>
<p>This conversion process involves several subtle steps. First, the graph structure must be serialized into arrays that can be passed to JAX. This includes the subintensity matrix, initial probability vector, and other structural information. Second, these arrays are registered with JAX’s callback mechanism, which allows JAX to call external code during computation. Third, the wrapper function is decorated with appropriate JAX primitives that describe its behavior during transformations like gradient computation or parallelization.</p>
<p>The discrete parameter in pmf_from_graph controls whether we’re working with a continuous-time or discrete-time phase-type distribution. For continuous distributions (discrete=False), the function evaluates the probability density function (PDF) at specified time points, representing the instantaneous probability of absorption at each time. For discrete distributions (discrete=True), it evaluates the probability mass function (PMF) at integer step counts, representing the probability of absorption after a specific number of transitions.</p>
<p>The resulting JAX function has signature model(theta, times) where theta is a parameter vector and times are evaluation points. This signature enables automatic differentiation with respect to parameters, which is essential for gradient-based inference methods like SVGD. The function can be composed with other JAX operations, passed through jax.jit for compilation, vectorized with jax.vmap, or parallelized with jax.pmap, making it a first-class citizen in the JAX ecosystem despite its C++ implementation.</p>
<div id="convert-to-jax" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert the coalescent graph to a JAX-compatible function</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="co"># This creates a function that can be differentiated, compiled, and parallelized by JAX</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>coalescent_model <span class="op">=</span> Graph.pmf_from_graph(</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>    coalescent_graph,</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    discrete<span class="op">=</span><span class="va">False</span>  <span class="co"># We want continuous-time PDF, not discrete-time PMF</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Test the model with an example parameter value</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>test_theta <span class="op">=</span> jnp.array([<span class="fl">1.5</span>])  <span class="co"># Population size parameter</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>test_times <span class="op">=</span> jnp.linspace(<span class="fl">0.1</span>, <span class="fl">5.0</span>, <span class="dv">50</span>)  <span class="co"># Time points for evaluation</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate the PDF at these time points</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>test_pdf <span class="op">=</span> coalescent_model(test_theta, test_times)</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> dist_info.is_coordinator:</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">JAX Model Conversion"</span>)</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Model signature: model(theta, times) -&gt; pdf_values"</span>)</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Test evaluation:"</span>)</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Parameter θ = </span><span class="sc">{</span><span class="bu">float</span>(test_theta[<span class="dv">0</span>])<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Time points: </span><span class="sc">{</span><span class="bu">len</span>(test_times)<span class="sc">}</span><span class="ss"> values from </span><span class="sc">{</span><span class="bu">float</span>(test_times[<span class="dv">0</span>])<span class="sc">:.2f}</span><span class="ss"> to </span><span class="sc">{</span><span class="bu">float</span>(test_times[<span class="op">-</span><span class="dv">1</span>])<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  PDF range: [</span><span class="sc">{</span><span class="bu">float</span>(jnp.<span class="bu">min</span>(test_pdf))<span class="sc">:.6f}</span><span class="ss">, </span><span class="sc">{</span><span class="bu">float</span>(jnp.<span class="bu">max</span>(test_pdf))<span class="sc">:.6f}</span><span class="ss">]"</span>)</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Visualize the PDF to see the shape of the coalescent time distribution</span></span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>    fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">5</span>))</span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>    ax.plot(test_times, test_pdf, <span class="st">'b-'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="ss">f'θ = </span><span class="sc">{</span><span class="bu">float</span>(test_theta[<span class="dv">0</span>])<span class="sc">:.2f}</span><span class="ss">'</span>)</span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>    ax.set_xlabel(<span class="st">'Time to MRCA'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>    ax.set_ylabel(<span class="st">'Probability Density'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>    ax.set_title(<span class="ss">f'Coalescent Time Distribution (</span><span class="sc">{</span>nr_samples<span class="sc">}</span><span class="ss"> samples)'</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a>    ax.legend(fontsize<span class="op">=</span><span class="dv">11</span>)</span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>    ax.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">The distribution shows the probability density for the time until all lineages coalesce."</span>)</span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"The shape reflects the sequential nature of coalescent events, with most probability"</span>)</span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"concentrated where the last few lineages are coalescing."</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="generating-synthetic-data-for-demonstration" class="level1">
<h1>Generating Synthetic Data for Demonstration</h1>
<p>To demonstrate distributed Bayesian inference, we need observed data that our inference procedure will try to explain. In a real application, this data would come from actual experiments or observations—for example, genetic sequence data from which coalescent times have been estimated. For this demonstration, we’ll generate synthetic data from a known parameter value, which has the advantage that we can verify our inference procedure correctly recovers the true parameter.</p>
<p>The data generation process involves several steps. First, we choose a true parameter value that will serve as the ground truth we’re trying to recover. Second, we evaluate our model at this parameter to get the true PDF. Third, we add realistic noise to simulate measurement uncertainty or sampling variability. The noise level should be calibrated to what you’d expect in real data—too little noise makes the problem artificially easy, while too much noise obscures the signal and makes inference difficult or impossible.</p>
<p>The choice of evaluation points also matters. We want enough points to capture the shape of the distribution, but not so many that computation becomes burdensome. The points should span the region where the PDF has significant mass; evaluating far into the tails where probability is negligible provides little information. For the coalescent, most events occur within a few coalescent time units, so we’ll focus our evaluation points there.</p>
<p>Adding noise requires care to maintain statistical validity. We add Gaussian noise scaled to the PDF magnitude, but then clip values to ensure they remain positive, since probability densities cannot be negative. The clipping introduces a slight bias, but it’s necessary for numerical stability in the log-likelihood computation during inference. In practice, ensuring your noise model matches your actual measurement process is important for obtaining valid posterior inference.</p>
<div id="generate-data" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set a true parameter value that we'll try to recover through inference</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>true_theta <span class="op">=</span> jnp.array([<span class="fl">1.2</span>])</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Choose evaluation points where we'll "observe" the PDF</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="co"># These points span the region where the coalescent distribution has significant mass</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>n_observations <span class="op">=</span> <span class="dv">40</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>observation_times <span class="op">=</span> jnp.linspace(<span class="fl">0.05</span>, <span class="fl">6.0</span>, n_observations)</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate the true model to get the PDF at these points</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>true_pdf <span class="op">=</span> coalescent_model(true_theta, observation_times)</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Add realistic measurement noise</span></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a><span class="co"># The noise level is scaled to the PDF magnitude to simulate proportional measurement error</span></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)  <span class="co"># For reproducibility</span></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>noise_level <span class="op">=</span> <span class="fl">0.08</span>  <span class="co"># 8% relative noise</span></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>noise_std <span class="op">=</span> noise_level <span class="op">*</span> <span class="bu">float</span>(jnp.<span class="bu">max</span>(true_pdf))</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>noise <span class="op">=</span> np.random.normal(<span class="dv">0</span>, noise_std, size<span class="op">=</span>true_pdf.shape)</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Add noise and clip to ensure positivity</span></span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>observed_pdf <span class="op">=</span> jnp.maximum(true_pdf <span class="op">+</span> noise, <span class="fl">1e-10</span>)</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> dist_info.is_coordinator:</span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Synthetic Data Generation"</span>)</span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"True parameter: θ = </span><span class="sc">{</span><span class="bu">float</span>(true_theta[<span class="dv">0</span>])<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Observation points: </span><span class="sc">{</span>n_observations<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Time range: [</span><span class="sc">{</span><span class="bu">float</span>(observation_times[<span class="dv">0</span>])<span class="sc">:.2f}</span><span class="ss">, </span><span class="sc">{</span><span class="bu">float</span>(observation_times[<span class="op">-</span><span class="dv">1</span>])<span class="sc">:.2f}</span><span class="ss">]"</span>)</span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Noise level: </span><span class="sc">{</span>noise_level<span class="op">*</span><span class="dv">100</span><span class="sc">:.1f}</span><span class="ss">% relative noise"</span>)</span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Noise std: </span><span class="sc">{</span>noise_std<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Visualize the synthetic data</span></span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a>    fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">6</span>))</span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a>    ax.plot(observation_times, true_pdf, <span class="st">'b-'</span>, linewidth<span class="op">=</span><span class="fl">2.5</span>, </span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a>            label<span class="op">=</span><span class="ss">f'True PDF (θ = </span><span class="sc">{</span><span class="bu">float</span>(true_theta[<span class="dv">0</span>])<span class="sc">:.3f}</span><span class="ss">)'</span>, alpha<span class="op">=</span><span class="fl">0.8</span>)</span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a>    ax.scatter(observation_times, observed_pdf, c<span class="op">=</span><span class="st">'red'</span>, s<span class="op">=</span><span class="dv">50</span>, alpha<span class="op">=</span><span class="fl">0.6</span>, </span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true" tabindex="-1"></a>               label<span class="op">=</span><span class="st">'Observed (with noise)'</span>, zorder<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb6-36"><a href="#cb6-36" aria-hidden="true" tabindex="-1"></a>    ax.axhline(y<span class="op">=</span><span class="dv">0</span>, color<span class="op">=</span><span class="st">'k'</span>, linestyle<span class="op">=</span><span class="st">'-'</span>, linewidth<span class="op">=</span><span class="fl">0.5</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb6-37"><a href="#cb6-37" aria-hidden="true" tabindex="-1"></a>    ax.set_xlabel(<span class="st">'Time to MRCA'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb6-38"><a href="#cb6-38" aria-hidden="true" tabindex="-1"></a>    ax.set_ylabel(<span class="st">'Probability Density'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb6-39"><a href="#cb6-39" aria-hidden="true" tabindex="-1"></a>    ax.set_title(<span class="st">'Synthetic Observed Data for Inference'</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb6-40"><a href="#cb6-40" aria-hidden="true" tabindex="-1"></a>    ax.legend(fontsize<span class="op">=</span><span class="dv">11</span>)</span>
<span id="cb6-41"><a href="#cb6-41" aria-hidden="true" tabindex="-1"></a>    ax.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb6-42"><a href="#cb6-42" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb6-43"><a href="#cb6-43" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb6-44"><a href="#cb6-44" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-45"><a href="#cb6-45" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">The observed data shows the true PDF corrupted by measurement noise."</span>)</span>
<span id="cb6-46"><a href="#cb6-46" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Our inference task is to recover the true parameter θ given only the noisy observations."</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="stein-variational-gradient-descent-theory-and-practice" class="level1">
<h1>Stein Variational Gradient Descent: Theory and Practice</h1>
<p>Stein Variational Gradient Descent (SVGD) is a powerful algorithm for Bayesian inference that approximates a posterior distribution using a set of particles. Unlike Markov Chain Monte Carlo methods that generate sequential samples from the posterior, SVGD maintains a swarm of particles that collectively represent the posterior and updates them simultaneously through deterministic gradient-based updates. This particle-based approach makes SVGD particularly well-suited to distributed computing because particles can be processed independently in parallel.</p>
<p>The key insight behind SVGD comes from the theory of kernelized Stein discrepancy. Given a target distribution (in our case, the Bayesian posterior), SVGD constructs a smooth transformation of the particles that reduces the discrepancy between the empirical particle distribution and the target. The transformation is chosen to be in the unit ball of a reproducing kernel Hilbert space (RKHS), which provides both theoretical guarantees and practical computational tractability. The optimal transformation turns out to have a surprisingly elegant form: it’s a weighted combination of gradients of the log target density and gradients of a kernel function measuring particle similarity.</p>
<p>Mathematically, if we denote our particles as θ₁, θ₂, …, θₙ and the target posterior density as p(θ|data), the SVGD update for each particle θᵢ has the form: θᵢ ← θᵢ + ε φ<em>(θᵢ), where ε is a step size and φ</em> is the optimal perturbation. This optimal perturbation is given by: φ*(θᵢ) = (1/n) Σⱼ [k(θⱼ, θᵢ) ∇log p(θⱼ|data) + ∇k(θⱼ, θᵢ)]. The first term attracts particles toward regions of high posterior probability, similar to gradient ascent. The second term creates repulsion between particles, preventing them from collapsing to a single mode and encouraging exploration of the posterior landscape.</p>
<p>The kernel function k(·,·) measures similarity between particles and determines the spatial scale of interaction. A common choice is the radial basis function (RBF) kernel k(θ, θ’) = exp(-||θ - θ’||²/h²), where h is a bandwidth parameter. The bandwidth controls how locally or globally particles interact: small h means only nearby particles affect each other, while large h creates long-range interactions. Adaptive bandwidth selection using the median heuristic (setting h to the median pairwise distance between particles) often works well in practice, balancing exploration and exploitation automatically as the particles move.</p>
<p>For distributed computing, SVGD’s particle structure is ideal because the gradient computation for different particles is independent and can happen simultaneously on different devices. The only coupling comes from the kernel matrix computation and the aggregation of updates, both of which can be efficiently parallelized. When we have n_devices devices and n_particles particles, we distribute particles roughly evenly across devices (ideally n_particles is a multiple of n_devices), and each device computes gradients for its subset of particles. The kernel matrix requires all-to-all communication to compute pairwise distances, but modern parallel computing frameworks like JAX handle this efficiently through collective operations.</p>
</section>
<section id="setting-up-distributed-svgd" class="level1">
<h1>Setting Up Distributed SVGD</h1>
<p>Configuring SVGD for distributed execution requires careful attention to several parameters that affect both the quality of posterior approximation and the efficiency of distributed computation. The number of particles determines how well we can approximate the posterior—more particles generally mean better approximation but also higher computational cost. The number of iterations controls how long we run the optimization, balancing convergence quality against wall-clock time. The learning rate (step size) affects convergence speed and stability, with too-large values causing instability and too-small values leading to slow convergence.</p>
<p>For distributed execution, the key consideration is ensuring particles distribute evenly across devices. If you have n_devices total devices across all processes, it’s ideal if n_particles is a multiple of n_devices, allowing exactly n_particles/n_devices particles per device. This even distribution maximizes hardware utilization and avoids load imbalancing where some devices sit idle while others process more particles. If the division isn’t exact, most implementations pad the particle count to the next multiple of the device count, adding a few duplicate particles that don’t affect results significantly.</p>
<p>The prior distribution encodes our beliefs about parameters before seeing data. For the coalescent parameter θ, which represents effective population size on a scaled timeline, we might use a weakly informative prior that prefers moderate values but doesn’t strongly constrain the inference. A Gaussian prior centered at a reasonable value with large variance works well, allowing the likelihood to dominate the posterior while preventing numerical issues from extreme parameter values. The log prior function must be differentiable since SVGD needs its gradient.</p>
<p>Initial particle placement also matters for convergence. Random initialization from a reasonable distribution (perhaps the prior or a broad Gaussian) provides diversity that helps explore the posterior. Seeding the random number generator differently on each process ensures particles start from different locations even in distributed settings. Good initialization can significantly reduce the number of iterations needed for convergence.</p>
<div id="svgd-setup" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Configure SVGD parameters for distributed inference</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Scale particle count with available computational resources</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>particles_per_device <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>n_particles <span class="op">=</span> dist_info.global_device_count <span class="op">*</span> particles_per_device</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>n_iterations <span class="op">=</span> <span class="dv">800</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>learning_rate <span class="op">=</span> <span class="fl">0.01</span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> dist_info.is_coordinator:</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">SVGD Configuration for Distributed Inference"</span>)</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Total particles: </span><span class="sc">{</span>n_particles<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Particles per device: </span><span class="sc">{</span>particles_per_device<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Total devices: </span><span class="sc">{</span>dist_info<span class="sc">.</span>global_device_count<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Number of processes: </span><span class="sc">{</span>dist_info<span class="sc">.</span>num_processes<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Iterations: </span><span class="sc">{</span>n_iterations<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Learning rate: </span><span class="sc">{</span>learning_rate<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">With </span><span class="sc">{</span>n_particles<span class="sc">}</span><span class="ss"> particles and </span><span class="sc">{</span>n_observations<span class="sc">}</span><span class="ss"> observations per particle,"</span>)</span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"each iteration requires </span><span class="sc">{</span>n_particles <span class="op">*</span> n_observations<span class="sc">:,}</span><span class="ss"> likelihood evaluations."</span>)</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Over </span><span class="sc">{</span>n_iterations<span class="sc">}</span><span class="ss"> iterations, that's </span><span class="sc">{</span>n_particles <span class="op">*</span> n_observations <span class="op">*</span> n_iterations<span class="sc">:,}</span><span class="ss"> total evaluations."</span>)</span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Distributed across </span><span class="sc">{</span>dist_info<span class="sc">.</span>global_device_count<span class="sc">}</span><span class="ss"> devices, each device handles approximately"</span>)</span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>(n_particles <span class="op">*</span> n_observations <span class="op">*</span> n_iterations) <span class="op">//</span> dist_info<span class="sc">.</span>global_device_count<span class="sc">:,}</span><span class="ss"> evaluations."</span>)</span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Define a weakly informative prior</span></span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a><span class="co"># We use a Gaussian centered at 1.0 with standard deviation 2.0</span></span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a><span class="co"># This prefers moderate population sizes but allows wide variation</span></span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> log_prior(theta):</span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a><span class="co">    Log prior density for the population size parameter.</span></span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a><span class="co">    We use log(p(θ)) = -0.5 * ((θ - μ) / σ)² plus constants.</span></span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true" tabindex="-1"></a><span class="co">    The constants can be omitted since SVGD only needs gradients.</span></span>
<span id="cb7-33"><a href="#cb7-33" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb7-34"><a href="#cb7-34" aria-hidden="true" tabindex="-1"></a>    prior_mean <span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb7-35"><a href="#cb7-35" aria-hidden="true" tabindex="-1"></a>    prior_std <span class="op">=</span> <span class="fl">2.0</span></span>
<span id="cb7-36"><a href="#cb7-36" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="op">-</span><span class="fl">0.5</span> <span class="op">*</span> jnp.<span class="bu">sum</span>((theta <span class="op">-</span> prior_mean)<span class="op">**</span><span class="dv">2</span> <span class="op">/</span> prior_std<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb7-37"><a href="#cb7-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-38"><a href="#cb7-38" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize particles randomly</span></span>
<span id="cb7-39"><a href="#cb7-39" aria-hidden="true" tabindex="-1"></a><span class="co"># Use different seeds on different processes to ensure diversity</span></span>
<span id="cb7-40"><a href="#cb7-40" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span> <span class="op">+</span> dist_info.process_id)</span>
<span id="cb7-41"><a href="#cb7-41" aria-hidden="true" tabindex="-1"></a>theta_init <span class="op">=</span> np.random.uniform(<span class="fl">0.5</span>, <span class="fl">2.0</span>, size<span class="op">=</span>(n_particles, <span class="dv">1</span>))</span>
<span id="cb7-42"><a href="#cb7-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-43"><a href="#cb7-43" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> dist_info.is_coordinator:</span>
<span id="cb7-44"><a href="#cb7-44" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Initialization Statistics:"</span>)</span>
<span id="cb7-45"><a href="#cb7-45" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Mean: </span><span class="sc">{</span>np<span class="sc">.</span>mean(theta_init)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb7-46"><a href="#cb7-46" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Std: </span><span class="sc">{</span>np<span class="sc">.</span>std(theta_init)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb7-47"><a href="#cb7-47" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Range: [</span><span class="sc">{</span>np<span class="sc">.</span><span class="bu">min</span>(theta_init)<span class="sc">:.3f}</span><span class="ss">, </span><span class="sc">{</span>np<span class="sc">.</span><span class="bu">max</span>(theta_init)<span class="sc">:.3f}</span><span class="ss">]"</span>)</span>
<span id="cb7-48"><a href="#cb7-48" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Particles are initialized uniformly between 0.5 and 2.0, bracketing the true value."</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="executing-distributed-svgd-inference" class="level1">
<h1>Executing Distributed SVGD Inference</h1>
<p>With our model, data, and configuration prepared, we’re ready to run the actual inference. The SVGD class handles all the complexity of distributed particle updates, gradient computation, and convergence monitoring. Behind the scenes, several sophisticated operations occur during each iteration of the algorithm.</p>
<p>First, for each particle, we need to compute the gradient of the log posterior density, which decomposes as log p(θ|data) = log p(data|θ) + log p(θ) - log p(data). The last term is a normalizing constant that doesn’t depend on θ, so we can ignore it. The gradient is thus ∇log p(θ|data) = ∇log p(data|θ) + ∇log p(θ), combining likelihood and prior gradients. The prior gradient is straightforward since we defined the prior analytically. The likelihood gradient is more involved because p(data|θ) involves our phase-type distribution model evaluated at θ, and we need automatic differentiation through the JAX function wrapper to compute ∇log p(data|θ).</p>
<p>Second, we compute the kernel matrix K where Kᵢⱼ = k(θᵢ, θⱼ), giving the similarity between all pairs of particles. This requires n_particles² kernel evaluations, though the matrix is symmetric so we can optimize by computing only the upper triangle. We also need the kernel gradients ∇k(θⱼ, θᵢ) for all pairs, which requires additional automatic differentiation of the kernel function. Both the kernel matrix and gradient computations parallelize naturally since different devices can compute their assigned rows independently.</p>
<p>Third, we compute the SVGD update direction φ<em>(θᵢ) for each particle using the formula φ</em>(θᵢ) = (1/n) Σⱼ [k(θⱼ, θᵢ) ∇log p(θⱼ|data) + ∇k(θⱼ, θᵢ)]. This is essentially a matrix-vector product of the kernel matrix with the gradient vectors, plus a sum of kernel gradients. The aggregation requires communication between devices to gather all particles’ gradients, but JAX’s collective operations make this efficient.</p>
<p>Finally, we update each particle: θᵢ ← θᵢ + ε φ*(θᵢ), moving particles in the direction that reduces KL divergence to the posterior. The step size ε (learning rate) scales the update magnitude. After updating, we can optionally project particles back onto valid parameter regions if they’ve strayed outside plausible bounds, though for our problem with a positive parameter this usually isn’t necessary.</p>
<p>Throughout execution, the SVGD implementation tracks convergence by monitoring the particle distribution’s evolution. If we request return_history=True, it saves particle positions at regular intervals, allowing us to visualize the optimization trajectory and verify convergence. The verbose flag controls whether progress information prints during execution, which is helpful for monitoring long-running jobs but can clutter output in repeated experiments.</p>
<div id="run-svgd" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a wrapper function that evaluates the model at our observation times</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="co"># This is what SVGD will differentiate to compute likelihood gradients</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> model_wrapper(theta):</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Evaluate coalescent model at observation times for given parameter."""</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> coalescent_model(theta, observation_times)</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Create SVGD instance with all our configuration</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>svgd <span class="op">=</span> SVGD(</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span>model_wrapper,</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>    observed_data<span class="op">=</span>observed_pdf,</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>    prior<span class="op">=</span>log_prior,</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>    theta_dim<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>    n_particles<span class="op">=</span>n_particles,</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>    n_iterations<span class="op">=</span>n_iterations,</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>    learning_rate<span class="op">=</span>learning_rate,</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>    kernel<span class="op">=</span><span class="st">'rbf_median'</span>,  <span class="co"># Use RBF kernel with adaptive bandwidth</span></span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>    theta_init<span class="op">=</span>theta_init,</span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>    seed<span class="op">=</span><span class="dv">42</span>,</span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span>(dist_info.is_coordinator)  <span class="co"># Only coordinator prints progress</span></span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> dist_info.is_coordinator:</span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Starting Distributed SVGD Inference"</span>)</span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"This will run </span><span class="sc">{</span>n_iterations<span class="sc">}</span><span class="ss"> iterations with </span><span class="sc">{</span>n_particles<span class="sc">}</span><span class="ss"> particles."</span>)</span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Computation is distributed across </span><span class="sc">{</span>dist_info<span class="sc">.</span>global_device_count<span class="sc">}</span><span class="ss"> devices."</span>)</span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Progress updates will appear below...</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Run the inference</span></span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a><span class="co"># This is where the distributed computation happens</span></span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Each device will process its assigned particles in parallel</span></span>
<span id="cb8-31"><a href="#cb8-31" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb8-32"><a href="#cb8-32" aria-hidden="true" tabindex="-1"></a>start_time <span class="op">=</span> time.time()</span>
<span id="cb8-33"><a href="#cb8-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-34"><a href="#cb8-34" aria-hidden="true" tabindex="-1"></a>svgd.fit(return_history<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb8-35"><a href="#cb8-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-36"><a href="#cb8-36" aria-hidden="true" tabindex="-1"></a>elapsed_time <span class="op">=</span> time.time() <span class="op">-</span> start_time</span>
<span id="cb8-37"><a href="#cb8-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-38"><a href="#cb8-38" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract results</span></span>
<span id="cb8-39"><a href="#cb8-39" aria-hidden="true" tabindex="-1"></a>posterior_particles <span class="op">=</span> svgd.particles</span>
<span id="cb8-40"><a href="#cb8-40" aria-hidden="true" tabindex="-1"></a>posterior_mean <span class="op">=</span> svgd.theta_mean</span>
<span id="cb8-41"><a href="#cb8-41" aria-hidden="true" tabindex="-1"></a>posterior_std <span class="op">=</span> svgd.theta_std</span>
<span id="cb8-42"><a href="#cb8-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-43"><a href="#cb8-43" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> dist_info.is_coordinator:</span>
<span id="cb8-44"><a href="#cb8-44" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">"</span> <span class="op">+</span> <span class="st">"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb8-45"><a href="#cb8-45" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Inference Complete"</span>)</span>
<span id="cb8-46"><a href="#cb8-46" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb8-47"><a href="#cb8-47" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Total time: </span><span class="sc">{</span>elapsed_time<span class="sc">:.2f}</span><span class="ss"> seconds"</span>)</span>
<span id="cb8-48"><a href="#cb8-48" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Time per iteration: </span><span class="sc">{</span>elapsed_time<span class="op">/</span>n_iterations<span class="sc">:.3f}</span><span class="ss"> seconds"</span>)</span>
<span id="cb8-49"><a href="#cb8-49" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Throughput: </span><span class="sc">{</span>n_particles <span class="op">*</span> n_iterations <span class="op">/</span> elapsed_time<span class="sc">:.0f}</span><span class="ss"> particle-iterations/second"</span>)</span>
<span id="cb8-50"><a href="#cb8-50" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">With </span><span class="sc">{</span>dist_info<span class="sc">.</span>global_device_count<span class="sc">}</span><span class="ss"> devices, speedup vs single device: ~</span><span class="sc">{</span>dist_info<span class="sc">.</span>global_device_count<span class="sc">:.1f}</span><span class="ss">x"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="analyzing-posterior-results" class="level1">
<h1>Analyzing Posterior Results</h1>
<p>After SVGD completes, we have a collection of particles that approximate the posterior distribution. These particles should concentrate in regions of high posterior probability, which means regions where both the likelihood and prior are reasonably large. Analyzing these particles involves computing summary statistics, visualizing the distribution, checking convergence, and comparing predictions against observations.</p>
<p>The posterior mean provides a point estimate of the parameter, essentially the average of all particle locations. This is analogous to the posterior mean in Bayesian inference, though technically SVGD gives us a finite sample approximation rather than exact posterior sampling. The posterior standard deviation measures uncertainty, indicating how widely the particles are spread. Large standard deviation suggests high uncertainty, while small standard deviation indicates concentrated posterior mass.</p>
<p>A credible interval, typically at 95% coverage, provides a range of plausible parameter values. If we sort the particles by parameter value, the 2.5th and 97.5th percentiles define the 95% credible interval. We can check whether the true parameter (which we know for synthetic data) falls within this interval. It should roughly 95% of the time if our inference is well-calibrated. Systematic failures to cover the true parameter indicate problems with the model, likelihood specification, or inference procedure.</p>
<p>Visualization of the particle histogram shows the approximate posterior shape. For a one-dimensional parameter like θ, a simple histogram suffices. For higher-dimensional problems, we’d use marginal histograms, pair plots, or other multivariate visualization techniques. The posterior shape reveals important information: unimodal distributions suggest simple inference problems with one clear optimal parameter value, while multimodal posteriors indicate multiple plausible explanations that the data cannot distinguish.</p>
<p>Convergence assessment involves checking whether particles have stopped moving substantially. If we saved particle history, we can plot how the mean or individual particles evolved over iterations. Good convergence looks like particle trajectories that stabilize after some burn-in period. Continued drift suggests either insufficient iterations or learning rate issues. We can also monitor the effective sample size or potential scale reduction factor to quantitatively assess convergence, though visual inspection often suffices for one-dimensional problems.</p>
<div id="analyze-posterior" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> dist_info.is_coordinator:</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute credible interval</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>    lower_quantile <span class="op">=</span> jnp.percentile(posterior_particles[:, <span class="dv">0</span>], <span class="fl">2.5</span>)</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>    upper_quantile <span class="op">=</span> jnp.percentile(posterior_particles[:, <span class="dv">0</span>], <span class="fl">97.5</span>)</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Posterior Analysis"</span>)</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"True θ:              </span><span class="sc">{</span><span class="bu">float</span>(true_theta[<span class="dv">0</span>])<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Posterior mean:      </span><span class="sc">{</span><span class="bu">float</span>(posterior_mean[<span class="dv">0</span>])<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Posterior std:       </span><span class="sc">{</span><span class="bu">float</span>(posterior_std[<span class="dv">0</span>])<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"95% Credible Int:    [</span><span class="sc">{</span><span class="bu">float</span>(lower_quantile)<span class="sc">:.4f}</span><span class="ss">, </span><span class="sc">{</span><span class="bu">float</span>(upper_quantile)<span class="sc">:.4f}</span><span class="ss">]"</span>)</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Error (mean - true): </span><span class="sc">{</span><span class="bu">float</span>(posterior_mean[<span class="dv">0</span>] <span class="op">-</span> true_theta[<span class="dv">0</span>])<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Relative error:      </span><span class="sc">{</span><span class="dv">100</span><span class="op">*</span><span class="bu">float</span>(<span class="bu">abs</span>(posterior_mean[<span class="dv">0</span>] <span class="op">-</span> true_theta[<span class="dv">0</span>])<span class="op">/</span>true_theta[<span class="dv">0</span>])<span class="sc">:.2f}</span><span class="ss">%"</span>)</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Check coverage</span></span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>    covers_true <span class="op">=</span> (lower_quantile <span class="op">&lt;=</span> true_theta[<span class="dv">0</span>]) <span class="kw">and</span> (true_theta[<span class="dv">0</span>] <span class="op">&lt;=</span> upper_quantile)</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> covers_true:</span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">✓ True parameter is within 95% credible interval"</span>)</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">⚠ True parameter is outside 95% credible interval"</span>)</span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  This may indicate insufficient data, model misspecification, or"</span>)</span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  incomplete convergence. Try increasing iterations or particles."</span>)</span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"="</span><span class="op">*</span><span class="dv">70</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="visualizing-the-inference-results" class="level1">
<h1>Visualizing the Inference Results</h1>
<p>Visual analysis of inference results provides insights that summary statistics alone cannot capture. We’ll create several visualizations that together paint a complete picture of the posterior distribution and the quality of our inference. The posterior histogram shows the approximate posterior density, revealing its shape, spread, and any multimodality. Overlaying the true parameter and posterior mean allows quick visual assessment of accuracy.</p>
<p>The convergence trace plot shows how particles evolved over iterations. For clarity, we typically plot only a subset of particles since displaying all particles creates visual clutter. The trace should show particles initially scattered across parameter space, then gradually concentrating toward regions of high posterior probability. A well-converged inference shows stable particle positions in later iterations, while poor convergence exhibits continued drift or wandering.</p>
<p>The posterior predictive plot is particularly important because it shows whether our inferred model can reproduce the observed data. We sample parameters from the posterior (by selecting particles), evaluate the model at each sampled parameter, and overlay these predictions on the observed data. Good inference produces posterior predictions that bracket the observations, with the mean prediction close to the true data-generating curve. If posterior predictions systematically deviate from observations, it suggests model misspecification—the model structure cannot capture important features of the data, regardless of parameter values.</p>
<p>These visualizations serve multiple purposes beyond assessment. They help diagnose problems early in analysis, suggest improvements to the model or inference configuration, communicate results to collaborators who may not be familiar with technical details, and build intuition about how the inference algorithm explores parameter space. Taking time to carefully examine these plots often reveals insights that lead to better analyses.</p>
<div id="visualize-results" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> dist_info.is_coordinator:</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create a comprehensive visualization with three panels</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>    fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">18</span>, <span class="dv">5</span>))</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Panel 1: Posterior histogram</span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>    ax <span class="op">=</span> axes[<span class="dv">0</span>]</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>    ax.hist(posterior_particles[:, <span class="dv">0</span>], bins<span class="op">=</span><span class="dv">30</span>, density<span class="op">=</span><span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.7</span>,</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>            color<span class="op">=</span><span class="st">'steelblue'</span>, edgecolor<span class="op">=</span><span class="st">'black'</span>, linewidth<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>    ax.axvline(<span class="bu">float</span>(true_theta[<span class="dv">0</span>]), color<span class="op">=</span><span class="st">'red'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, linewidth<span class="op">=</span><span class="fl">2.5</span>,</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>               label<span class="op">=</span><span class="ss">f'True θ = </span><span class="sc">{</span><span class="bu">float</span>(true_theta[<span class="dv">0</span>])<span class="sc">:.3f}</span><span class="ss">'</span>, zorder<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>    ax.axvline(<span class="bu">float</span>(posterior_mean[<span class="dv">0</span>]), color<span class="op">=</span><span class="st">'green'</span>, linestyle<span class="op">=</span><span class="st">'-'</span>, linewidth<span class="op">=</span><span class="fl">2.5</span>,</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>               label<span class="op">=</span><span class="ss">f'Posterior mean = </span><span class="sc">{</span><span class="bu">float</span>(posterior_mean[<span class="dv">0</span>])<span class="sc">:.3f}</span><span class="ss">'</span>, zorder<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>    ax.axvspan(<span class="bu">float</span>(lower_quantile), <span class="bu">float</span>(upper_quantile), alpha<span class="op">=</span><span class="fl">0.2</span>, color<span class="op">=</span><span class="st">'green'</span>,</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>               label<span class="op">=</span><span class="st">'95% Credible Int'</span>)</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>    ax.set_xlabel(<span class="st">'θ (Population Size Parameter)'</span>, fontsize<span class="op">=</span><span class="dv">12</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>    ax.set_ylabel(<span class="st">'Posterior Density'</span>, fontsize<span class="op">=</span><span class="dv">12</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>    ax.set_title(<span class="st">'Posterior Distribution'</span>, fontsize<span class="op">=</span><span class="dv">14</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>    ax.legend(fontsize<span class="op">=</span><span class="dv">10</span>, loc<span class="op">=</span><span class="st">'best'</span>)</span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>    ax.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Panel 2: Convergence traces</span></span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a>    ax <span class="op">=</span> axes[<span class="dv">1</span>]</span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> svgd.history <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="kw">and</span> <span class="bu">len</span>(svgd.history) <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a>        history_array <span class="op">=</span> np.array(svgd.history)</span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Plot a subset of particle trajectories for clarity</span></span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a>        n_traces <span class="op">=</span> <span class="bu">min</span>(<span class="dv">20</span>, n_particles)</span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_traces):</span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true" tabindex="-1"></a>            ax.plot(history_array[:, i, <span class="dv">0</span>], alpha<span class="op">=</span><span class="fl">0.3</span>, color<span class="op">=</span><span class="st">'steelblue'</span>, linewidth<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb10-29"><a href="#cb10-29" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Plot the mean trajectory</span></span>
<span id="cb10-30"><a href="#cb10-30" aria-hidden="true" tabindex="-1"></a>        mean_trajectory <span class="op">=</span> np.mean(history_array[:, :, <span class="dv">0</span>], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb10-31"><a href="#cb10-31" aria-hidden="true" tabindex="-1"></a>        ax.plot(mean_trajectory, color<span class="op">=</span><span class="st">'darkblue'</span>, linewidth<span class="op">=</span><span class="dv">3</span>, label<span class="op">=</span><span class="st">'Mean trajectory'</span>, zorder<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb10-32"><a href="#cb10-32" aria-hidden="true" tabindex="-1"></a>        ax.axhline(<span class="bu">float</span>(true_theta[<span class="dv">0</span>]), color<span class="op">=</span><span class="st">'red'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, linewidth<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb10-33"><a href="#cb10-33" aria-hidden="true" tabindex="-1"></a>                   label<span class="op">=</span><span class="ss">f'True θ'</span>, zorder<span class="op">=</span><span class="dv">9</span>)</span>
<span id="cb10-34"><a href="#cb10-34" aria-hidden="true" tabindex="-1"></a>        ax.set_xlabel(<span class="st">'Iteration'</span>, fontsize<span class="op">=</span><span class="dv">12</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb10-35"><a href="#cb10-35" aria-hidden="true" tabindex="-1"></a>        ax.set_ylabel(<span class="st">'θ'</span>, fontsize<span class="op">=</span><span class="dv">12</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb10-36"><a href="#cb10-36" aria-hidden="true" tabindex="-1"></a>        ax.set_title(<span class="st">'SVGD Convergence'</span>, fontsize<span class="op">=</span><span class="dv">14</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb10-37"><a href="#cb10-37" aria-hidden="true" tabindex="-1"></a>        ax.legend(fontsize<span class="op">=</span><span class="dv">10</span>, loc<span class="op">=</span><span class="st">'best'</span>)</span>
<span id="cb10-38"><a href="#cb10-38" aria-hidden="true" tabindex="-1"></a>        ax.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb10-39"><a href="#cb10-39" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb10-40"><a href="#cb10-40" aria-hidden="true" tabindex="-1"></a>        ax.text(<span class="fl">0.5</span>, <span class="fl">0.5</span>, <span class="st">'Convergence history not saved</span><span class="ch">\n</span><span class="st">(run with return_history=True)'</span>,</span>
<span id="cb10-41"><a href="#cb10-41" aria-hidden="true" tabindex="-1"></a>                ha<span class="op">=</span><span class="st">'center'</span>, va<span class="op">=</span><span class="st">'center'</span>, fontsize<span class="op">=</span><span class="dv">12</span>, transform<span class="op">=</span>ax.transAxes)</span>
<span id="cb10-42"><a href="#cb10-42" aria-hidden="true" tabindex="-1"></a>        ax.set_xticks([])</span>
<span id="cb10-43"><a href="#cb10-43" aria-hidden="true" tabindex="-1"></a>        ax.set_yticks([])</span>
<span id="cb10-44"><a href="#cb10-44" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb10-45"><a href="#cb10-45" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Panel 3: Posterior predictive</span></span>
<span id="cb10-46"><a href="#cb10-46" aria-hidden="true" tabindex="-1"></a>    ax <span class="op">=</span> axes[<span class="dv">2</span>]</span>
<span id="cb10-47"><a href="#cb10-47" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Sample particles for posterior predictions</span></span>
<span id="cb10-48"><a href="#cb10-48" aria-hidden="true" tabindex="-1"></a>    n_posterior_samples <span class="op">=</span> <span class="bu">min</span>(<span class="dv">50</span>, n_particles)</span>
<span id="cb10-49"><a href="#cb10-49" aria-hidden="true" tabindex="-1"></a>    sample_indices <span class="op">=</span> np.random.choice(n_particles, n_posterior_samples, replace<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb10-50"><a href="#cb10-50" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb10-51"><a href="#cb10-51" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plot posterior predictive samples</span></span>
<span id="cb10-52"><a href="#cb10-52" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> idx <span class="kw">in</span> sample_indices:</span>
<span id="cb10-53"><a href="#cb10-53" aria-hidden="true" tabindex="-1"></a>        theta_sample <span class="op">=</span> jnp.array([posterior_particles[idx, <span class="dv">0</span>]])</span>
<span id="cb10-54"><a href="#cb10-54" aria-hidden="true" tabindex="-1"></a>        pred_pdf <span class="op">=</span> coalescent_model(theta_sample, observation_times)</span>
<span id="cb10-55"><a href="#cb10-55" aria-hidden="true" tabindex="-1"></a>        ax.plot(observation_times, pred_pdf, <span class="st">'b-'</span>, alpha<span class="op">=</span><span class="fl">0.1</span>, linewidth<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb10-56"><a href="#cb10-56" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb10-57"><a href="#cb10-57" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plot true PDF</span></span>
<span id="cb10-58"><a href="#cb10-58" aria-hidden="true" tabindex="-1"></a>    ax.plot(observation_times, true_pdf, <span class="st">'r-'</span>, linewidth<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb10-59"><a href="#cb10-59" aria-hidden="true" tabindex="-1"></a>            label<span class="op">=</span><span class="ss">f'True PDF (θ=</span><span class="sc">{</span><span class="bu">float</span>(true_theta[<span class="dv">0</span>])<span class="sc">:.3f}</span><span class="ss">)'</span>, alpha<span class="op">=</span><span class="fl">0.8</span>, zorder<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb10-60"><a href="#cb10-60" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb10-61"><a href="#cb10-61" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plot posterior mean prediction</span></span>
<span id="cb10-62"><a href="#cb10-62" aria-hidden="true" tabindex="-1"></a>    mean_pred <span class="op">=</span> coalescent_model(jnp.array([posterior_mean[<span class="dv">0</span>]]), observation_times)</span>
<span id="cb10-63"><a href="#cb10-63" aria-hidden="true" tabindex="-1"></a>    ax.plot(observation_times, mean_pred, <span class="st">'g--'</span>, linewidth<span class="op">=</span><span class="fl">2.5</span>,</span>
<span id="cb10-64"><a href="#cb10-64" aria-hidden="true" tabindex="-1"></a>            label<span class="op">=</span><span class="ss">f'Posterior mean (θ=</span><span class="sc">{</span><span class="bu">float</span>(posterior_mean[<span class="dv">0</span>])<span class="sc">:.3f}</span><span class="ss">)'</span>, alpha<span class="op">=</span><span class="fl">0.9</span>, zorder<span class="op">=</span><span class="dv">9</span>)</span>
<span id="cb10-65"><a href="#cb10-65" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb10-66"><a href="#cb10-66" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plot observed data</span></span>
<span id="cb10-67"><a href="#cb10-67" aria-hidden="true" tabindex="-1"></a>    ax.scatter(observation_times, observed_pdf, c<span class="op">=</span><span class="st">'black'</span>, s<span class="op">=</span><span class="dv">40</span>, alpha<span class="op">=</span><span class="fl">0.6</span>,</span>
<span id="cb10-68"><a href="#cb10-68" aria-hidden="true" tabindex="-1"></a>               label<span class="op">=</span><span class="st">'Observed data'</span>, zorder<span class="op">=</span><span class="dv">11</span>)</span>
<span id="cb10-69"><a href="#cb10-69" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb10-70"><a href="#cb10-70" aria-hidden="true" tabindex="-1"></a>    ax.set_xlabel(<span class="st">'Time to MRCA'</span>, fontsize<span class="op">=</span><span class="dv">12</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb10-71"><a href="#cb10-71" aria-hidden="true" tabindex="-1"></a>    ax.set_ylabel(<span class="st">'Probability Density'</span>, fontsize<span class="op">=</span><span class="dv">12</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb10-72"><a href="#cb10-72" aria-hidden="true" tabindex="-1"></a>    ax.set_title(<span class="st">'Posterior Predictive Check'</span>, fontsize<span class="op">=</span><span class="dv">14</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb10-73"><a href="#cb10-73" aria-hidden="true" tabindex="-1"></a>    ax.legend(fontsize<span class="op">=</span><span class="dv">10</span>, loc<span class="op">=</span><span class="st">'best'</span>)</span>
<span id="cb10-74"><a href="#cb10-74" aria-hidden="true" tabindex="-1"></a>    ax.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb10-75"><a href="#cb10-75" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb10-76"><a href="#cb10-76" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb10-77"><a href="#cb10-77" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb10-78"><a href="#cb10-78" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb10-79"><a href="#cb10-79" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Visualization Interpretation:"</span>)</span>
<span id="cb10-80"><a href="#cb10-80" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Left panel: Shows the approximate posterior distribution over θ."</span>)</span>
<span id="cb10-81"><a href="#cb10-81" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  The histogram represents our uncertainty about the parameter value."</span>)</span>
<span id="cb10-82"><a href="#cb10-82" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  The true value (red line) should fall within the main mass if inference succeeded."</span>)</span>
<span id="cb10-83"><a href="#cb10-83" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Middle panel: Shows how particles moved during optimization."</span>)</span>
<span id="cb10-84"><a href="#cb10-84" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Particles should converge toward the true parameter region."</span>)</span>
<span id="cb10-85"><a href="#cb10-85" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Stable trajectories in later iterations indicate convergence."</span>)</span>
<span id="cb10-86"><a href="#cb10-86" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Right panel: Compares posterior predictions against observed data."</span>)</span>
<span id="cb10-87"><a href="#cb10-87" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Light blue curves are predictions from individual posterior samples."</span>)</span>
<span id="cb10-88"><a href="#cb10-88" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  These should bracket the observations, indicating good model fit."</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="understanding-distributed-performance" class="level1">
<h1>Understanding Distributed Performance</h1>
<p>The performance benefits of distributed computing come from parallelizing independent computations across multiple devices. In SVGD, the primary computational bottleneck is evaluating gradients of the log posterior for each particle. Since particles are independent, these gradient computations parallelize perfectly—if we have n devices and n particles, each device can compute one particle’s gradient simultaneously, achieving n-fold speedup over sequential execution.</p>
<p>However, perfect linear speedup rarely occurs in practice due to several factors. Communication overhead arises when devices need to exchange information, such as gathering all particles’ gradients to compute the kernel matrix or broadcasting updated particle positions. Load imbalancing happens if particle counts don’t divide evenly across devices or if some gradient computations take longer than others. Synchronization barriers force faster devices to wait for slower ones before proceeding. Fixed costs like initialization and result collection don’t parallelize.</p>
<p>The actual speedup depends on the ratio of computation to communication time. For large models where each gradient evaluation is expensive, computation dominates and we achieve near-linear speedup. For simple models with cheap gradients, communication overhead becomes significant and speedup plateaus. The particle-to-device ratio also matters: too few particles per device means devices are underutilized, while too many particles increases memory pressure and can cause slowdowns.</p>
<p>In our coalescent example, the phase-type distribution evaluation involves graph traversal and numerical computation that’s expensive enough to make parallelization worthwhile. With properly configured distributed execution, we can expect 80-90% parallel efficiency (achieving 80-90% of theoretical linear speedup) across moderate numbers of devices. Beyond certain scales, diminishing returns set in as communication overhead grows, suggesting there’s an optimal cluster size for any given problem that balances computational gain against coordination cost.</p>
<div id="performance-analysis" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> dist_info.is_coordinator:</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Distributed Performance Analysis"</span>)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute various performance metrics</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>    total_gradient_evals <span class="op">=</span> n_particles <span class="op">*</span> n_iterations</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>    evals_per_second <span class="op">=</span> total_gradient_evals <span class="op">/</span> elapsed_time</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>    evals_per_device <span class="op">=</span> total_gradient_evals <span class="op">/</span> dist_info.global_device_count</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>    time_per_eval <span class="op">=</span> elapsed_time <span class="op">/</span> total_gradient_evals</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Computational Workload:"</span>)</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Total gradient evaluations: </span><span class="sc">{</span>total_gradient_evals<span class="sc">:,}</span><span class="ss">"</span>)</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Each evaluation involves computing likelihood at </span><span class="sc">{</span>n_observations<span class="sc">}</span><span class="ss"> time points"</span>)</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Total likelihood evaluations: </span><span class="sc">{</span>total_gradient_evals <span class="op">*</span> n_observations<span class="sc">:,}</span><span class="ss">"</span>)</span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Actual Performance:"</span>)</span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Total elapsed time: </span><span class="sc">{</span>elapsed_time<span class="sc">:.2f}</span><span class="ss"> seconds"</span>)</span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Gradient evaluations per second: </span><span class="sc">{</span>evals_per_second<span class="sc">:.1f}</span><span class="ss">"</span>)</span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Time per gradient evaluation: </span><span class="sc">{</span>time_per_eval<span class="op">*</span><span class="dv">1000</span><span class="sc">:.2f}</span><span class="ss"> ms"</span>)</span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Distributed Scaling:"</span>)</span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Devices used: </span><span class="sc">{</span>dist_info<span class="sc">.</span>global_device_count<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Processes (nodes) used: </span><span class="sc">{</span>dist_info<span class="sc">.</span>num_processes<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Evaluations per device: </span><span class="sc">{</span>evals_per_device<span class="sc">:,.0f}</span><span class="ss">"</span>)</span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Work distribution: </span><span class="sc">{</span>particles_per_device<span class="sc">}</span><span class="ss"> particles/device"</span>)</span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-27"><a href="#cb11-27" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Estimate speedup (rough approximation assuming perfect single-device baseline)</span></span>
<span id="cb11-28"><a href="#cb11-28" aria-hidden="true" tabindex="-1"></a>    estimated_single_device_time <span class="op">=</span> elapsed_time <span class="op">*</span> dist_info.global_device_count</span>
<span id="cb11-29"><a href="#cb11-29" aria-hidden="true" tabindex="-1"></a>    parallel_efficiency <span class="op">=</span> (estimated_single_device_time <span class="op">/</span> elapsed_time) <span class="op">/</span> dist_info.global_device_count</span>
<span id="cb11-30"><a href="#cb11-30" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-31"><a href="#cb11-31" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Speedup Analysis (estimates):"</span>)</span>
<span id="cb11-32"><a href="#cb11-32" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Estimated single-device time: </span><span class="sc">{</span>estimated_single_device_time<span class="op">/</span><span class="dv">60</span><span class="sc">:.1f}</span><span class="ss"> minutes"</span>)</span>
<span id="cb11-33"><a href="#cb11-33" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Actual multi-device time: </span><span class="sc">{</span>elapsed_time<span class="op">/</span><span class="dv">60</span><span class="sc">:.1f}</span><span class="ss"> minutes"</span>)</span>
<span id="cb11-34"><a href="#cb11-34" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Theoretical max speedup: </span><span class="sc">{</span>dist_info<span class="sc">.</span>global_device_count<span class="sc">}</span><span class="ss">x"</span>)</span>
<span id="cb11-35"><a href="#cb11-35" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Parallel efficiency: </span><span class="sc">{</span>parallel_efficiency<span class="op">*</span><span class="dv">100</span><span class="sc">:.1f}</span><span class="ss">%"</span>)</span>
<span id="cb11-36"><a href="#cb11-36" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-37"><a href="#cb11-37" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Key Insight:"</span>)</span>
<span id="cb11-38"><a href="#cb11-38" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> parallel_efficiency <span class="op">&gt;</span> <span class="fl">0.8</span>:</span>
<span id="cb11-39"><a href="#cb11-39" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  Excellent parallel efficiency! Communication overhead is minimal."</span>)</span>
<span id="cb11-40"><a href="#cb11-40" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> parallel_efficiency <span class="op">&gt;</span> <span class="fl">0.6</span>:</span>
<span id="cb11-41"><a href="#cb11-41" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  Good parallel efficiency. Some communication overhead present."</span>)</span>
<span id="cb11-42"><a href="#cb11-42" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb11-43"><a href="#cb11-43" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  Moderate parallel efficiency. Communication overhead is significant."</span>)</span>
<span id="cb11-44"><a href="#cb11-44" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  Consider increasing work per device (more particles or complex model)."</span>)</span>
<span id="cb11-45"><a href="#cb11-45" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-46"><a href="#cb11-46" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"="</span><span class="op">*</span><span class="dv">70</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="deploying-on-slurm-clusters" class="level1">
<h1>Deploying on SLURM Clusters</h1>
<p>The code we’ve written so far runs identically on a laptop during development and on a massive SLURM cluster during production. This portability is a key design goal of the distributed computing framework. However, actually submitting jobs to a SLURM cluster requires some additional infrastructure: SLURM batch scripts that request computational resources, load necessary software modules, activate Python environments, and launch your code across multiple nodes.</p>
<p>Writing SLURM scripts manually is tedious and error-prone, with subtle issues like incorrect environment variable settings or module loading order causing hard-to-debug failures. The PtDAlgorithms distribution includes tools to generate SLURM scripts automatically from YAML configuration files, reducing script creation from a manual chore to a simple command. These generated scripts handle all the boilerplate: SBATCH directives for resource requests, module loading, environment activation, coordinator address setup, and proper process launching with srun.</p>
<p>Configuration files separate cluster-specific settings (partition names, module names, resource limits) from your analysis code. You might have different configurations for different clusters, or different profiles for different job sizes on the same cluster. Common profiles include debug (quick testing with minimal resources), small (initial development), medium (standard production), large (big jobs), and production (maximum scale). By selecting an appropriate profile, you automatically get reasonable resource allocations without manually tuning dozens of SLURM parameters.</p>
<p>The workflow for cluster deployment typically follows this pattern: develop and test your code locally, convert your notebook or script to a Python file if needed, choose or create an appropriate cluster configuration, generate a SLURM submission script, submit the job and monitor its progress, examine output logs when complete, and iterate based on results. The key advantage of this workflow is that the same analysis code runs everywhere—only the resource configuration changes between local testing and cluster production.</p>
<div id="slurm-example" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> dist_info.is_coordinator:</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">SLURM Cluster Deployment Guide"</span>)</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Step 1: Save your analysis as a Python script"</span>)</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  jupyter nbconvert --to python distributed_computing_complete_guide.ipynb"</span>)</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  # Creates distributed_computing_complete_guide.py"</span>)</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Step 2: Choose a cluster configuration"</span>)</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Available predefined profiles:"</span>)</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"    - debug: 1 node, 4 CPUs, 30 minutes (quick testing)"</span>)</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"    - small: 2 nodes, 8 CPUs each, 1 hour (development)"</span>)</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"    - medium: 4 nodes, 16 CPUs each, 2 hours (standard jobs)"</span>)</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"    - large: 8 nodes, 16 CPUs each, 4 hours (large-scale)"</span>)</span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"    - production: 8 nodes, 32 CPUs each, 8 hours (maximum scale)"</span>)</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Step 3: Generate SLURM submission script"</span>)</span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  python generate_slurm_script.py </span><span class="ch">\\</span><span class="ss">"</span>)</span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"      --profile medium </span><span class="ch">\\</span><span class="ss">"</span>)</span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"      --script distributed_computing_complete_guide.py </span><span class="ch">\\</span><span class="ss">"</span>)</span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"      --output submit.sh"</span>)</span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Step 4: Submit to cluster"</span>)</span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  sbatch submit.sh"</span>)</span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  # Or combine steps 3 and 4:"</span>)</span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  sbatch &lt;(python generate_slurm_script.py --profile medium --script yourscript.py)"</span>)</span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb12-28"><a href="#cb12-28" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Step 5: Monitor job progress"</span>)</span>
<span id="cb12-29"><a href="#cb12-29" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  squeue -u $USER           # Check job status"</span>)</span>
<span id="cb12-30"><a href="#cb12-30" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  tail -f logs/job_*.out    # Follow output log"</span>)</span>
<span id="cb12-31"><a href="#cb12-31" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  scancel &lt;job_id&gt;          # Cancel if needed"</span>)</span>
<span id="cb12-32"><a href="#cb12-32" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb12-33"><a href="#cb12-33" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Cluster-Specific Configuration:"</span>)</span>
<span id="cb12-34"><a href="#cb12-34" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  For your specific cluster, you may need to create a custom YAML config:"</span>)</span>
<span id="cb12-35"><a href="#cb12-35" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  "</span>)</span>
<span id="cb12-36"><a href="#cb12-36" aria-hidden="true" tabindex="-1"></a>    example_config <span class="op">=</span> <span class="st">"""  # my_cluster.yaml</span></span>
<span id="cb12-37"><a href="#cb12-37" aria-hidden="true" tabindex="-1"></a><span class="st">  name: my_cluster</span></span>
<span id="cb12-38"><a href="#cb12-38" aria-hidden="true" tabindex="-1"></a><span class="st">  nodes: 4</span></span>
<span id="cb12-39"><a href="#cb12-39" aria-hidden="true" tabindex="-1"></a><span class="st">  cpus_per_node: 24</span></span>
<span id="cb12-40"><a href="#cb12-40" aria-hidden="true" tabindex="-1"></a><span class="st">  memory_per_cpu: </span><span class="ch">\"</span><span class="st">8G</span><span class="ch">\"</span></span>
<span id="cb12-41"><a href="#cb12-41" aria-hidden="true" tabindex="-1"></a><span class="st">  time_limit: </span><span class="ch">\"</span><span class="st">03:00:00</span><span class="ch">\"</span></span>
<span id="cb12-42"><a href="#cb12-42" aria-hidden="true" tabindex="-1"></a><span class="st">  partition: </span><span class="ch">\"</span><span class="st">compute</span><span class="ch">\"</span><span class="st">      # Your cluster's partition name</span></span>
<span id="cb12-43"><a href="#cb12-43" aria-hidden="true" tabindex="-1"></a><span class="st">  modules_to_load:</span></span>
<span id="cb12-44"><a href="#cb12-44" aria-hidden="true" tabindex="-1"></a><span class="st">    - </span><span class="ch">\"</span><span class="st">python/3.11</span><span class="ch">\"</span><span class="st">          # Your cluster's Python module</span></span>
<span id="cb12-45"><a href="#cb12-45" aria-hidden="true" tabindex="-1"></a><span class="st">    - </span><span class="ch">\"</span><span class="st">gcc/11.2.0</span><span class="ch">\"</span><span class="st">           # If needed</span></span>
<span id="cb12-46"><a href="#cb12-46" aria-hidden="true" tabindex="-1"></a><span class="st">  env_vars:</span></span>
<span id="cb12-47"><a href="#cb12-47" aria-hidden="true" tabindex="-1"></a><span class="st">    JAX_ENABLE_X64: </span><span class="ch">\"</span><span class="st">1</span><span class="ch">\"</span><span class="st">"""</span></span>
<span id="cb12-48"><a href="#cb12-48" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(example_config)</span>
<span id="cb12-49"><a href="#cb12-49" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb12-50"><a href="#cb12-50" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Then use: python generate_slurm_script.py --config my_cluster.yaml --script yourscript.py"</span>)</span>
<span id="cb12-51"><a href="#cb12-51" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"="</span><span class="op">*</span><span class="dv">70</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="advanced-topics-and-optimization-strategies" class="level1">
<h1>Advanced Topics and Optimization Strategies</h1>
<p>Beyond basic distributed inference, several advanced techniques can improve performance, convergence quality, or enable new applications. Understanding these techniques helps you tackle challenging inference problems and extract maximum value from computational resources.</p>
<p>Adaptive learning rates can significantly improve convergence. Rather than using a fixed learning rate throughout optimization, you can decay it over time (starting with larger steps for rapid initial movement, then smaller steps for fine-tuning) or adapt it based on convergence indicators like the change in particle positions between iterations. Some SVGD implementations support automatic learning rate scheduling.</p>
<p>Kernel bandwidth selection deserves careful attention. The median heuristic (setting bandwidth to the median pairwise particle distance) adapts automatically as particles move, but you might get better results with problem-specific tuning. Larger bandwidths encourage global exploration, while smaller bandwidths enable local refinement. Some recent work suggests using multiple kernels with different bandwidths simultaneously.</p>
<p>Moment-based regularization addresses a common challenge: likelihood-based inference can sometimes produce posteriors that match observed data points but produce incorrect predictions for other quantities. Adding terms to the objective that penalize disagreement between posterior predictions and observed moments (mean, variance, etc.) can improve generalization. This is particularly useful when you have both distributional observations and moment estimates from independent data.</p>
<p>Symbolic computation for parameterized graphs provides enormous speedup when you need to evaluate phase-type distributions at many parameter values. The symbolic Gaussian elimination procedure converts a parameterized cyclic graph into an acyclic form where the dependence on parameters is explicit. Subsequent evaluations at different parameters require only updating edge weights rather than retraversing the graph, achieving orders of magnitude speedup for parameter sweeps.</p>
<p>Checkpointing for long-running jobs is essential for production workflows. Saving particle positions and optimization state periodically allows resuming interrupted jobs without starting over. On clusters with job time limits, checkpointing enables multi-stage optimization where each job picks up where the previous one left off.</p>
<p>Multi-fidelity inference uses cheaper approximate models during early optimization to quickly identify promising parameter regions, then switches to expensive accurate models for final refinement. For phase-type distributions, you might start with a reduced state space or coarser time discretization, then increase resolution as particles converge.</p>
<div id="advanced-example" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> dist_info.is_coordinator:</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Advanced Optimization Strategies"</span>)</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">1. Adaptive Learning Rate Schedule"</span>)</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   Instead of fixed learning_rate=0.01, use a schedule:"</span>)</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   "</span>)</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   def learning_rate_schedule(iteration, initial_rate=0.05):"</span>)</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"       # Exponential decay"</span>)</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"       return initial_rate * (0.995 ** iteration)"</span>)</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   "</span>)</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   This starts with aggressive exploration and gradually refines."</span>)</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">2. Kernel Bandwidth Tuning"</span>)</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   The median heuristic is automatic but may not be optimal:"</span>)</span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   "</span>)</span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   # Try different kernel strategies:"</span>)</span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   kernel='rbf_median'      # Automatic (default)"</span>)</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   kernel='rbf_adaptive'    # Adapts differently"</span>)</span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   kernel=1.5               # Fixed bandwidth"</span>)</span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   "</span>)</span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   Larger bandwidth → more global exploration"</span>)</span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   Smaller bandwidth → more local refinement"</span>)</span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">3. Increasing Particles for Better Approximation"</span>)</span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   More particles = better posterior approximation:"</span>)</span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   "</span>)</span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   n_particles_options = [50, 100, 200, 500]"</span>)</span>
<span id="cb13-29"><a href="#cb13-29" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   "</span>)</span>
<span id="cb13-30"><a href="#cb13-30" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   Trade-off: Better approximation vs longer computation time"</span>)</span>
<span id="cb13-31"><a href="#cb13-31" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   With distributed execution, can afford more particles"</span>)</span>
<span id="cb13-32"><a href="#cb13-32" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-33"><a href="#cb13-33" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">4. Multi-Stage Optimization"</span>)</span>
<span id="cb13-34"><a href="#cb13-34" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   Coarse-to-fine refinement:"</span>)</span>
<span id="cb13-35"><a href="#cb13-35" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   "</span>)</span>
<span id="cb13-36"><a href="#cb13-36" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   # Stage 1: Quick exploration with fewer particles"</span>)</span>
<span id="cb13-37"><a href="#cb13-37" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   svgd_coarse = SVGD(model, data, n_particles=50, n_iterations=200)"</span>)</span>
<span id="cb13-38"><a href="#cb13-38" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   svgd_coarse.fit()"</span>)</span>
<span id="cb13-39"><a href="#cb13-39" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   "</span>)</span>
<span id="cb13-40"><a href="#cb13-40" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   # Stage 2: Refinement with more particles initialized near coarse solution"</span>)</span>
<span id="cb13-41"><a href="#cb13-41" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   theta_refined = np.random.normal(svgd_coarse.theta_mean, svgd_coarse.theta_std, (200, 1))"</span>)</span>
<span id="cb13-42"><a href="#cb13-42" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   svgd_fine = SVGD(model, data, n_particles=200, theta_init=theta_refined)"</span>)</span>
<span id="cb13-43"><a href="#cb13-43" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   svgd_fine.fit()"</span>)</span>
<span id="cb13-44"><a href="#cb13-44" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-45"><a href="#cb13-45" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">5. Symbolic Computation for Fast Parameter Sweeps"</span>)</span>
<span id="cb13-46"><a href="#cb13-46" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   For models evaluated at many parameter values:"</span>)</span>
<span id="cb13-47"><a href="#cb13-47" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   "</span>)</span>
<span id="cb13-48"><a href="#cb13-48" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   # Convert to symbolic form once (expensive)"</span>)</span>
<span id="cb13-49"><a href="#cb13-49" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   symbolic_graph = graph.symbolic_elimination()"</span>)</span>
<span id="cb13-50"><a href="#cb13-50" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   "</span>)</span>
<span id="cb13-51"><a href="#cb13-51" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   # Then evaluate quickly at many parameters"</span>)</span>
<span id="cb13-52"><a href="#cb13-52" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   for theta in parameter_grid:"</span>)</span>
<span id="cb13-53"><a href="#cb13-53" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"       symbolic_graph.update_weights(theta)"</span>)</span>
<span id="cb13-54"><a href="#cb13-54" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"       pdf = symbolic_graph.pdf(times)  # Much faster!"</span>)</span>
<span id="cb13-55"><a href="#cb13-55" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-56"><a href="#cb13-56" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">6. Moment-Based Regularization"</span>)</span>
<span id="cb13-57"><a href="#cb13-57" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   If you have moment estimates in addition to distribution observations:"</span>)</span>
<span id="cb13-58"><a href="#cb13-58" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   "</span>)</span>
<span id="cb13-59"><a href="#cb13-59" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   observed_moments = [mean_estimate, variance_estimate]"</span>)</span>
<span id="cb13-60"><a href="#cb13-60" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   svgd.fit_regularized("</span>)</span>
<span id="cb13-61"><a href="#cb13-61" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"       observed_times=observation_times,"</span>)</span>
<span id="cb13-62"><a href="#cb13-62" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"       observed_moments=observed_moments,"</span>)</span>
<span id="cb13-63"><a href="#cb13-63" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"       regularization=0.5  # Weight of moment term"</span>)</span>
<span id="cb13-64"><a href="#cb13-64" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   )"</span>)</span>
<span id="cb13-65"><a href="#cb13-65" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-66"><a href="#cb13-66" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"="</span><span class="op">*</span><span class="dv">70</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="troubleshooting-distributed-computation" class="level1">
<h1>Troubleshooting Distributed Computation</h1>
<p>Distributed computing introduces complexity, and with complexity comes potential for issues. Understanding common problems and their solutions helps you debug issues quickly and maintain productive workflows. Most distributed computing problems fall into a few categories: environment configuration, communication failures, resource limitations, convergence issues, or numerical instabilities.</p>
<p>Environment configuration problems often manifest as import errors or “module not found” exceptions. These typically stem from the Python environment not being properly activated on compute nodes or required packages not being installed. Ensure your SLURM script activates the environment (using pixi shell-hook or conda activate) before running Python. Module loading order can also matter—some modules need to be loaded before others, and the automatically generated scripts handle common cases but may need customization for unusual clusters.</p>
<p>Communication failures usually appear as timeouts or “unable to connect to coordinator” errors. These indicate processes can’t communicate, often due to firewall rules blocking the coordinator port, incorrect coordinator address computation, or network interface mismatches. Verify the coordinator port is open and that processes can reach each other over the network. On clusters with multiple network interfaces (like InfiniBand for fast interconnect), you may need to specify which interface to use.</p>
<p>Resource limitations cause jobs to fail due to exceeding memory, time, or storage limits. Memory exhaustion typically occurs with too many particles or too large a state space. Reduce particles per device or increase memory allocation in your configuration. Time limit exhaustion means the job didn’t finish before the cluster’s time limit. Increase the time_limit in your config or reduce iterations. Storage issues arise when writing large output files fills quota—compress outputs or write to appropriate storage locations.</p>
<p>Convergence issues manifest as poor parameter estimates or high posterior variance. These might indicate insufficient iterations, inappropriate learning rate, or fundamental inferability problems where the data doesn’t constrain the parameters. Check convergence diagnostics, visualize particle trajectories, and verify your model is identifiable given the available data. Sometimes the issue is model misspecification rather than inference failure.</p>
<p>Numerical instabilities appear as NaN or Inf values in gradients or likelihoods. These usually stem from evaluating distributions at extreme parameter values where computations overflow or underflow. Adding bounds to parameter ranges, using log-space computations, or adjusting prior distributions can help. Numerical issues can also arise from too-large learning rates causing particles to jump to pathological regions.</p>
<div id="troubleshooting-guide" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> dist_info.is_coordinator:</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Troubleshooting Guide for Distributed Computing"</span>)</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>    troubleshooting_scenarios <span class="op">=</span> [</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>        {</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>            <span class="st">"problem"</span>: <span class="st">"Job fails immediately with ModuleNotFoundError"</span>,</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>            <span class="st">"diagnosis"</span>: <span class="st">"Python environment not activated on compute nodes"</span>,</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>            <span class="st">"solution"</span>: [</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>                <span class="st">"Verify SLURM script includes environment activation"</span>,</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>                <span class="st">"For pixi: eval </span><span class="ch">\"</span><span class="st">$(pixi shell-hook)</span><span class="ch">\"</span><span class="st">"</span>,</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>                <span class="st">"For conda: conda activate your_env"</span>,</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>                <span class="st">"Test environment on compute node: srun python -c 'import ptdalgorithms'"</span></span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>            ]</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>        },</span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>        {</span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>            <span class="st">"problem"</span>: <span class="st">"Processes timeout connecting to coordinator"</span>,</span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>            <span class="st">"diagnosis"</span>: <span class="st">"Network communication failure"</span>,</span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>            <span class="st">"solution"</span>: [</span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a>                <span class="st">"Check coordinator port is not blocked by firewall"</span>,</span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a>                <span class="st">"Verify coordinator address in logs"</span>,</span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a>                <span class="st">"Try different coordinator_port (e.g., 12346 instead of 12345)"</span>,</span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a>                <span class="st">"Check network interface: may need to specify interface for InfiniBand clusters"</span></span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>            ]</span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a>        },</span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a>        {</span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a>            <span class="st">"problem"</span>: <span class="st">"Job killed due to memory exhaustion"</span>,</span>
<span id="cb14-28"><a href="#cb14-28" aria-hidden="true" tabindex="-1"></a>            <span class="st">"diagnosis"</span>: <span class="st">"Insufficient memory allocation"</span>,</span>
<span id="cb14-29"><a href="#cb14-29" aria-hidden="true" tabindex="-1"></a>            <span class="st">"solution"</span>: [</span>
<span id="cb14-30"><a href="#cb14-30" aria-hidden="true" tabindex="-1"></a>                <span class="st">"Reduce particles_per_device"</span>,</span>
<span id="cb14-31"><a href="#cb14-31" aria-hidden="true" tabindex="-1"></a>                <span class="st">"Increase memory_per_cpu in cluster config"</span>,</span>
<span id="cb14-32"><a href="#cb14-32" aria-hidden="true" tabindex="-1"></a>                <span class="st">"Use smaller state spaces or discretization"</span>,</span>
<span id="cb14-33"><a href="#cb14-33" aria-hidden="true" tabindex="-1"></a>                <span class="st">"Monitor memory with: sstat -j &lt;job_id&gt; --format=MaxRSS"</span></span>
<span id="cb14-34"><a href="#cb14-34" aria-hidden="true" tabindex="-1"></a>            ]</span>
<span id="cb14-35"><a href="#cb14-35" aria-hidden="true" tabindex="-1"></a>        },</span>
<span id="cb14-36"><a href="#cb14-36" aria-hidden="true" tabindex="-1"></a>        {</span>
<span id="cb14-37"><a href="#cb14-37" aria-hidden="true" tabindex="-1"></a>            <span class="st">"problem"</span>: <span class="st">"Job exceeds time limit before completion"</span>,</span>
<span id="cb14-38"><a href="#cb14-38" aria-hidden="true" tabindex="-1"></a>            <span class="st">"diagnosis"</span>: <span class="st">"Computation took longer than allocated time"</span>,</span>
<span id="cb14-39"><a href="#cb14-39" aria-hidden="true" tabindex="-1"></a>            <span class="st">"solution"</span>: [</span>
<span id="cb14-40"><a href="#cb14-40" aria-hidden="true" tabindex="-1"></a>                <span class="st">"Increase time_limit in cluster config"</span>,</span>
<span id="cb14-41"><a href="#cb14-41" aria-hidden="true" tabindex="-1"></a>                <span class="st">"Reduce n_iterations or n_particles"</span>,</span>
<span id="cb14-42"><a href="#cb14-42" aria-hidden="true" tabindex="-1"></a>                <span class="st">"Use checkpointing to resume in subsequent jobs"</span>,</span>
<span id="cb14-43"><a href="#cb14-43" aria-hidden="true" tabindex="-1"></a>                <span class="st">"Profile to identify bottlenecks: may be suboptimal model evaluation"</span></span>
<span id="cb14-44"><a href="#cb14-44" aria-hidden="true" tabindex="-1"></a>            ]</span>
<span id="cb14-45"><a href="#cb14-45" aria-hidden="true" tabindex="-1"></a>        },</span>
<span id="cb14-46"><a href="#cb14-46" aria-hidden="true" tabindex="-1"></a>        {</span>
<span id="cb14-47"><a href="#cb14-47" aria-hidden="true" tabindex="-1"></a>            <span class="st">"problem"</span>: <span class="st">"Poor convergence or high posterior variance"</span>,</span>
<span id="cb14-48"><a href="#cb14-48" aria-hidden="true" tabindex="-1"></a>            <span class="st">"diagnosis"</span>: <span class="st">"Insufficient optimization or inferability issues"</span>,</span>
<span id="cb14-49"><a href="#cb14-49" aria-hidden="true" tabindex="-1"></a>            <span class="st">"solution"</span>: [</span>
<span id="cb14-50"><a href="#cb14-50" aria-hidden="true" tabindex="-1"></a>                <span class="st">"Increase n_iterations (try 2x current value)"</span>,</span>
<span id="cb14-51"><a href="#cb14-51" aria-hidden="true" tabindex="-1"></a>                <span class="st">"Increase n_particles for better approximation"</span>,</span>
<span id="cb14-52"><a href="#cb14-52" aria-hidden="true" tabindex="-1"></a>                <span class="st">"Check particle trajectories for convergence"</span>,</span>
<span id="cb14-53"><a href="#cb14-53" aria-hidden="true" tabindex="-1"></a>                <span class="st">"Verify model is identifiable from data (try synthetic data with known parameters)"</span>,</span>
<span id="cb14-54"><a href="#cb14-54" aria-hidden="true" tabindex="-1"></a>                <span class="st">"Adjust learning_rate (try both 0.5x and 2x current value)"</span></span>
<span id="cb14-55"><a href="#cb14-55" aria-hidden="true" tabindex="-1"></a>            ]</span>
<span id="cb14-56"><a href="#cb14-56" aria-hidden="true" tabindex="-1"></a>        },</span>
<span id="cb14-57"><a href="#cb14-57" aria-hidden="true" tabindex="-1"></a>        {</span>
<span id="cb14-58"><a href="#cb14-58" aria-hidden="true" tabindex="-1"></a>            <span class="st">"problem"</span>: <span class="st">"NaN or Inf in gradients"</span>,</span>
<span id="cb14-59"><a href="#cb14-59" aria-hidden="true" tabindex="-1"></a>            <span class="st">"diagnosis"</span>: <span class="st">"Numerical instability"</span>,</span>
<span id="cb14-60"><a href="#cb14-60" aria-hidden="true" tabindex="-1"></a>            <span class="st">"solution"</span>: [</span>
<span id="cb14-61"><a href="#cb14-61" aria-hidden="true" tabindex="-1"></a>                <span class="st">"Reduce learning_rate"</span>,</span>
<span id="cb14-62"><a href="#cb14-62" aria-hidden="true" tabindex="-1"></a>                <span class="st">"Add parameter bounds to prior"</span>,</span>
<span id="cb14-63"><a href="#cb14-63" aria-hidden="true" tabindex="-1"></a>                <span class="st">"Check for extreme likelihood values at particle positions"</span>,</span>
<span id="cb14-64"><a href="#cb14-64" aria-hidden="true" tabindex="-1"></a>                <span class="st">"Enable 64-bit precision: enable_x64=True"</span>,</span>
<span id="cb14-65"><a href="#cb14-65" aria-hidden="true" tabindex="-1"></a>                <span class="st">"Add small epsilon to prevent log(0): jnp.log(value + 1e-10)"</span></span>
<span id="cb14-66"><a href="#cb14-66" aria-hidden="true" tabindex="-1"></a>            ]</span>
<span id="cb14-67"><a href="#cb14-67" aria-hidden="true" tabindex="-1"></a>        },</span>
<span id="cb14-68"><a href="#cb14-68" aria-hidden="true" tabindex="-1"></a>        {</span>
<span id="cb14-69"><a href="#cb14-69" aria-hidden="true" tabindex="-1"></a>            <span class="st">"problem"</span>: <span class="st">"Code runs locally but fails on cluster"</span>,</span>
<span id="cb14-70"><a href="#cb14-70" aria-hidden="true" tabindex="-1"></a>            <span class="st">"diagnosis"</span>: <span class="st">"Environment differences"</span>,</span>
<span id="cb14-71"><a href="#cb14-71" aria-hidden="true" tabindex="-1"></a>            <span class="st">"solution"</span>: [</span>
<span id="cb14-72"><a href="#cb14-72" aria-hidden="true" tabindex="-1"></a>                <span class="st">"Check JAX/Python versions match"</span>,</span>
<span id="cb14-73"><a href="#cb14-73" aria-hidden="true" tabindex="-1"></a>                <span class="st">"Verify all dependencies installed in cluster environment"</span>,</span>
<span id="cb14-74"><a href="#cb14-74" aria-hidden="true" tabindex="-1"></a>                <span class="st">"Test on single cluster node first: srun --nodes=1 python script.py"</span>,</span>
<span id="cb14-75"><a href="#cb14-75" aria-hidden="true" tabindex="-1"></a>                <span class="st">"Check environment variables are correctly set in SLURM script"</span></span>
<span id="cb14-76"><a href="#cb14-76" aria-hidden="true" tabindex="-1"></a>            ]</span>
<span id="cb14-77"><a href="#cb14-77" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb14-78"><a href="#cb14-78" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb14-79"><a href="#cb14-79" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb14-80"><a href="#cb14-80" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, scenario <span class="kw">in</span> <span class="bu">enumerate</span>(troubleshooting_scenarios, <span class="dv">1</span>):</span>
<span id="cb14-81"><a href="#cb14-81" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Scenario </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>scenario[<span class="st">'problem'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb14-82"><a href="#cb14-82" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Diagnosis: </span><span class="sc">{</span>scenario[<span class="st">'diagnosis'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb14-83"><a href="#cb14-83" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Solutions:"</span>)</span>
<span id="cb14-84"><a href="#cb14-84" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> solution <span class="kw">in</span> scenario[<span class="st">'solution'</span>]:</span>
<span id="cb14-85"><a href="#cb14-85" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"  • </span><span class="sc">{</span>solution<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb14-86"><a href="#cb14-86" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb14-87"><a href="#cb14-87" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">"</span> <span class="op">+</span> <span class="st">"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb14-88"><a href="#cb14-88" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">General Debugging Strategy:"</span>)</span>
<span id="cb14-89"><a href="#cb14-89" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  1. Test locally first to isolate cluster-specific issues"</span>)</span>
<span id="cb14-90"><a href="#cb14-90" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  2. Start with debug profile (minimal resources) for quick iteration"</span>)</span>
<span id="cb14-91"><a href="#cb14-91" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  3. Check logs carefully - error messages usually point to the problem"</span>)</span>
<span id="cb14-92"><a href="#cb14-92" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  4. Verify environment on compute nodes before submitting large jobs"</span>)</span>
<span id="cb14-93"><a href="#cb14-93" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  5. Monitor resource usage during execution to catch issues early"</span>)</span>
<span id="cb14-94"><a href="#cb14-94" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"="</span><span class="op">*</span><span class="dv">70</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="summary-and-best-practices" class="level1">
<h1>Summary and Best Practices</h1>
<p>This comprehensive guide has covered distributed computing with PtDAlgorithms from fundamental concepts through practical implementation to advanced optimization and troubleshooting. The key insights that emerge from this material are straightforward: modern distributed computing frameworks can dramatically simplify what was once extremely complex, but success requires understanding both the high-level abstractions and the underlying mechanisms.</p>
<p>The single most important practice is to develop incrementally, testing at each stage before scaling up. Write and debug your code locally where iteration is fast and debugging is easy. Test on a cluster with minimal resources (debug profile) to verify environment configuration and basic functionality. Scale to small production jobs to validate performance and convergence. Only then move to large-scale production runs. This staged approach catches problems early when they’re easy to fix rather than late when they’re expensive.</p>
<p>Understanding your computational requirements helps choose appropriate resources. Estimate how long computations will take based on test runs, then request cluster resources accordingly. Over-requesting wastes allocation and may delay job start, while under-requesting leads to killed jobs and wasted computation. Profile your code to identify bottlenecks—if evaluation is cheap, adding more devices won’t help much, but if evaluation is expensive, distributed execution provides near-linear speedup.</p>
<p>Monitoring and logging are essential for production workflows. Write informative log messages at key points (initialization, iteration milestones, completion). Save intermediate results so you can analyze partial results if jobs fail. Use the coordinator check (dist_info.is_coordinator) to avoid cluttered output from multiple processes all printing the same information. Monitor resource usage during execution to catch memory leaks or inefficiencies.</p>
<p>Finally, remember that distributed computing is a tool to solve problems faster or at larger scale, not an end in itself. If local execution suffices for your problem, use it—simplicity has value. Distribute when you need results faster than local execution can provide, when your problem doesn’t fit in local memory, or when you want to explore larger parameter spaces or use more particles for better inference. The framework makes distribution easy, but that doesn’t mean you should always use it.</p>
<div id="summary" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> dist_info.is_coordinator:</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">"</span> <span class="op">+</span> <span class="st">"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"DISTRIBUTED COMPUTING WITH PTDALGORITHMS - SUMMARY"</span>)</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Key Capabilities Demonstrated:"</span>)</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  ✓ Automatic SLURM detection and configuration"</span>)</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  ✓ JAX distributed initialization"</span>)</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  ✓ Parameterized phase-type distribution models"</span>)</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  ✓ JAX function conversion for automatic differentiation"</span>)</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  ✓ Distributed SVGD Bayesian inference"</span>)</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  ✓ Parallel gradient computation across devices"</span>)</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  ✓ Convergence monitoring and visualization"</span>)</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  ✓ Posterior analysis and predictive checking"</span>)</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Best Practices Checklist:"</span>)</span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  □ Test locally before submitting to cluster"</span>)</span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  □ Start with debug profile for initial cluster testing"</span>)</span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  □ Use particles evenly divisible by device count"</span>)</span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  □ Monitor convergence with return_history=True"</span>)</span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  □ Check posterior predictive matches observations"</span>)</span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  □ Use coordinator check for output/logging"</span>)</span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  □ Save intermediate results for long-running jobs"</span>)</span>
<span id="cb15-24"><a href="#cb15-24" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  □ Profile performance to identify bottlenecks"</span>)</span>
<span id="cb15-25"><a href="#cb15-25" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb15-26"><a href="#cb15-26" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Next Steps:"</span>)</span>
<span id="cb15-27"><a href="#cb15-27" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  1. Apply to your own phase-type distribution models"</span>)</span>
<span id="cb15-28"><a href="#cb15-28" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  2. Experiment with different cluster configurations"</span>)</span>
<span id="cb15-29"><a href="#cb15-29" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  3. Explore advanced techniques (symbolic computation, regularization)"</span>)</span>
<span id="cb15-30"><a href="#cb15-30" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  4. Scale to production workloads on your cluster"</span>)</span>
<span id="cb15-31"><a href="#cb15-31" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb15-32"><a href="#cb15-32" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Resources:"</span>)</span>
<span id="cb15-33"><a href="#cb15-33" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  • PtDAlgorithms documentation: https://docs.ptdalgorithms.org"</span>)</span>
<span id="cb15-34"><a href="#cb15-34" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  • JAX distributed computing: https://jax.readthedocs.io/en/latest/distributed.html"</span>)</span>
<span id="cb15-35"><a href="#cb15-35" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  • SVGD paper: Liu &amp; Wang (2016), NIPS"</span>)</span>
<span id="cb15-36"><a href="#cb15-36" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  • Phase-type distributions: Røikjer et al. (2022), Statistics and Computing"</span>)</span>
<span id="cb15-37"><a href="#cb15-37" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb15-38"><a href="#cb15-38" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">"</span> <span class="op">+</span> <span class="st">"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb15-39"><a href="#cb15-39" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Thank you for reading this comprehensive guide!"</span>)</span>
<span id="cb15-40"><a href="#cb15-40" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"="</span><span class="op">*</span><span class="dv">70</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/munch-group\.github\.io\/PtDAlgorithms\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../pages/svgd/svgd_with_symbolic_dag.html" class="pagination-link" aria-label="SVGD Inference with Symbolic DAG Optimization">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">SVGD Inference with Symbolic DAG Optimization</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../pages/distributed/slurm_cluster_setup.html" class="pagination-link" aria-label="SLURM Cluster Setup and Configuration">
        <span class="nav-page-text">SLURM Cluster Setup and Configuration</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>