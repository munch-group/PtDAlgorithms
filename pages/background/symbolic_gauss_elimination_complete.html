<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.25">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Symbolic Graph Elimination for Phase-Type Distributions - Complete Guide</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-7b89279ff1a6dce999919e0e67d4d9ec.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-8eb735be1893943fe49fb9ca03c59cb5.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../../api/_styles-quartodoc.css">
<link rel="stylesheet" href="../../numpy.css">
</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../logo.png" alt="Phasic" class="navbar-logo light-content">
    <img src="../../logo.png" alt="Phasic" class="navbar-logo dark-content">
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../pages/getting_started.html"> 
<span class="menu-text">Documentation</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../api/"> 
<span class="menu-text">Python API reference</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../r_api/"> 
<span class="menu-text">R API reference</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../c_api/"> 
<span class="menu-text">C API reference</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/munch-group/ptdalgorithms/"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#understanding-the-computational-bottleneck" id="toc-understanding-the-computational-bottleneck" class="nav-link active" data-scroll-target="#understanding-the-computational-bottleneck">Understanding the Computational Bottleneck</a></li>
  <li><a href="#the-symbolic-elimination-insight" id="toc-the-symbolic-elimination-insight" class="nav-link" data-scroll-target="#the-symbolic-elimination-insight">The Symbolic Elimination Insight</a></li>
  <li><a href="#building-blocks-expression-trees-and-symbolic-representation" id="toc-building-blocks-expression-trees-and-symbolic-representation" class="nav-link" data-scroll-target="#building-blocks-expression-trees-and-symbolic-representation">Building Blocks: Expression Trees and Symbolic Representation</a></li>
  <li><a href="#the-symbolic-elimination-algorithm-in-detail" id="toc-the-symbolic-elimination-algorithm-in-detail" class="nav-link" data-scroll-target="#the-symbolic-elimination-algorithm-in-detail">The Symbolic Elimination Algorithm in Detail</a></li>
  <li><a href="#expression-evaluation-and-graph-instantiation" id="toc-expression-evaluation-and-graph-instantiation" class="nav-link" data-scroll-target="#expression-evaluation-and-graph-instantiation">Expression Evaluation and Graph Instantiation</a></li>
  <li><a href="#comprehensive-performance-analysis" id="toc-comprehensive-performance-analysis" class="nav-link" data-scroll-target="#comprehensive-performance-analysis">Comprehensive Performance Analysis</a></li>
  <li><a href="#symbolic-dag-caching-avoiding-repeated-elimination-across-sessions" id="toc-symbolic-dag-caching-avoiding-repeated-elimination-across-sessions" class="nav-link" data-scroll-target="#symbolic-dag-caching-avoiding-repeated-elimination-across-sessions">Symbolic DAG Caching: Avoiding Repeated Elimination Across Sessions</a>
  <ul class="collapse">
  <li><a href="#content-based-graph-hashing" id="toc-content-based-graph-hashing" class="nav-link" data-scroll-target="#content-based-graph-hashing">Content-Based Graph Hashing</a></li>
  <li><a href="#automatic-caching-in-high-level-api" id="toc-automatic-caching-in-high-level-api" class="nav-link" data-scroll-target="#automatic-caching-in-high-level-api">Automatic Caching in High-Level API</a></li>
  <li><a href="#cache-management-and-sharing" id="toc-cache-management-and-sharing" class="nav-link" data-scroll-target="#cache-management-and-sharing">Cache Management and Sharing</a></li>
  <li><a href="#combined-performance-impact-symbolic-elimination-caching" id="toc-combined-performance-impact-symbolic-elimination-caching" class="nav-link" data-scroll-target="#combined-performance-impact-symbolic-elimination-caching">Combined Performance Impact: Symbolic Elimination + Caching</a></li>
  </ul></li>
  <li><a href="#integration-with-bayesian-inference-algorithms" id="toc-integration-with-bayesian-inference-algorithms" class="nav-link" data-scroll-target="#integration-with-bayesian-inference-algorithms">Integration with Bayesian Inference Algorithms</a></li>
  <li><a href="#practical-considerations-and-best-practices" id="toc-practical-considerations-and-best-practices" class="nav-link" data-scroll-target="#practical-considerations-and-best-practices">Practical Considerations and Best Practices</a></li>
  <li><a href="#advanced-topics-and-future-directions" id="toc-advanced-topics-and-future-directions" class="nav-link" data-scroll-target="#advanced-topics-and-future-directions">Advanced Topics and Future Directions</a></li>
  <li><a href="#summary-and-key-takeaways" id="toc-summary-and-key-takeaways" class="nav-link" data-scroll-target="#summary-and-key-takeaways">Summary and Key Takeaways</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Symbolic Graph Elimination for Phase-Type Distributions - Complete Guide</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>The computational challenge of evaluating phase-type distributions repeatedly with different parameter values represents one of the most significant bottlenecks in modern Bayesian inference workflows. When conducting parameter estimation using methods like Stein Variational Gradient Descent, Markov Chain Monte Carlo, or gradient-based optimization, we find ourselves in a situation where the same underlying graph structure must be evaluated thousands or even millions of times, each time with slightly different edge weights determined by our current parameter hypothesis. The naive approach to this problem involves updating edge weights and then running a complete graph elimination algorithm—a process with cubic complexity in the number of states—for every single evaluation. This becomes prohibitively expensive very quickly, turning what should be tractable inference problems into computational nightmares that require days or weeks of computing time.</p>
<p>The key insight that unlocks dramatic performance improvements comes from recognizing a fundamental property of parameterized phase-type distributions: while the numeric values of edge weights change as we vary parameters, the structural relationships between these weights remain constant. The graph elimination algorithm performs the same sequence of operations regardless of the specific numeric values involved—it eliminates vertices in the same order, creates the same bypass edges, and performs the same structural transformations. What changes is merely the arithmetic: instead of multiplying specific numbers, we’re multiplying different numbers, but the pattern of multiplication, addition, and division operations stays the same. This observation suggests a powerful optimization strategy: perform the elimination algorithm once to determine the structure of all computations, then represent edge weights not as concrete numbers but as symbolic expressions that can be rapidly evaluated for any parameter vector.</p>
<p>This document provides a complete exploration of symbolic graph elimination for phase-type distributions, combining theoretical foundations with practical implementation guidance. We’ll begin by understanding the computational problem in depth, examining why traditional approaches struggle and what specific patterns in the computation suggest opportunities for optimization. From there, we’ll develop the symbolic elimination algorithm itself, understanding how expression trees can represent parameterized computations and how these trees can be efficiently evaluated. Throughout, we’ll maintain a focus on both the mathematical elegance of the approach and its practical implications for real-world inference problems, using concrete examples from population genetics and reliability theory to illustrate the concepts.</p>
<div id="setup" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> ptdalgorithms <span class="im">import</span> Graph, SymbolicDAG</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Configure plotting for clear visualizations</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>plt.style.use(<span class="st">'seaborn-v0_8-darkgrid'</span>)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>plt.rcParams[<span class="st">'figure.figsize'</span>] <span class="op">=</span> (<span class="dv">12</span>, <span class="dv">6</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<section id="understanding-the-computational-bottleneck" class="level1">
<h1>Understanding the Computational Bottleneck</h1>
<p>To appreciate why symbolic elimination provides such dramatic speedups, we must first understand the computational structure of phase-type distribution evaluation and why repeated evaluations with different parameters prove so expensive. Phase-type distributions describe the time until absorption in continuous-time or discrete-time Markov chains, and computing properties like probability density functions, cumulative distributions, or moments requires solving systems of linear equations derived from the chain’s structure. The standard approach uses a graph elimination algorithm that progressively removes vertices from the Markov chain graph while maintaining equivalence of the absorption time distribution.</p>
<p>The elimination algorithm works by selecting non-absorbing vertices one at a time and “eliminating” them by creating direct edges that bypass the eliminated vertex. When we eliminate a vertex v that has parent vertices (vertices with edges leading to v) and child vertices (vertices that v has edges leading to), we must create new edges from each parent to each child that capture the probability of eventually reaching the child from the parent via paths that go through v. This involves computing probabilities for two-step paths (parent to v, then v to child), handling potential self-loops at v through geometric series, and combining these with any existing direct edges between parents and children. The complexity arises because in graphs with high connectivity, eliminating a single vertex can create many new edges, and we must eliminate most vertices in the graph before reaching a final acyclic form suitable for efficient forward evaluation.</p>
<p>In the worst case, when the graph is densely connected, eliminating n vertices can require operations proportional to n³. More precisely, if each vertex has degree O(n)—meaning it connects to many other vertices—then each elimination step processes O(n²) parent-child pairs, and we perform n elimination steps, yielding O(n³) total operations. For sparse graphs with bounded degree, the complexity reduces to O(n²) or even O(n log n), but many phase-type distributions arising from realistic models exhibit moderate to high connectivity. The critical observation for our purposes is that this cubic cost must be paid every time we evaluate the distribution with different edge weights, because the elimination algorithm operates on numeric values and produces a graph with concrete numeric edge weights that cannot be reused when parameters change.</p>
<p>Let’s make this concrete with a simple example from population genetics. The coalescent model describes how genetic lineages merge backward in time, and represents one of the fundamental models in population genetics. Consider a sample of k DNA sequences from a population. Working backward in time, these k sequences represent k separate lineages that can coalesce pairwise when they find common ancestors. The model has a simple structure: starting with k lineages, at any time point, any two lineages might coalesce (merge), reducing the count to k-1 lineages. The process continues until only one lineage remains, representing the most recent common ancestor of the sample. The coalescence rate depends on the effective population size through a parameter θ, with the rate for n lineages being proportional to n(n-1)/2 × θ, reflecting the number of pairs that might coalesce. This gives us a phase-type distribution with roughly k states (one for each possible lineage count) and simple linear dependence on the single parameter θ.</p>
<div id="coalescent-model" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> coalescent_callback(state, nr_samples<span class="op">=</span><span class="dv">4</span>):</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Coalescent model callback for constructing the state space.</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="co">    The state represents the number of lineages remaining. We start with nr_samples</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="co">    lineages and coalesce down to 1. The coalescence rate for n lineages is</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="co">    n(n-1)/2 times a parameter θ representing effective population size.</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="co">    To enable symbolic elimination, we specify edge_state vectors (the coefficients</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="co">    that multiply parameter values). Here, edge_state = [base_rate] means the</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="co">    actual rate is θ[0] * base_rate after calling update_parameterized_weights([θ]).</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">len</span>(state) <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Initial state: start with nr_samples lineages</span></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>        <span class="co"># The base rate for n lineages coalescing to n-1 is n(n-1)/2</span></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>        base_rate <span class="op">=</span> nr_samples <span class="op">*</span> (nr_samples <span class="op">-</span> <span class="dv">1</span>) <span class="op">/</span> <span class="dv">2</span></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Return: (next_state, placeholder_weight, edge_state_coefficients)</span></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>        <span class="co"># The actual weight will be θ * base_rate after parameterization</span></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> [([nr_samples <span class="op">-</span> <span class="dv">1</span>], <span class="fl">0.0</span>, [base_rate])]</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> state[<span class="dv">0</span>] <span class="op">&lt;=</span> <span class="dv">1</span>:</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Absorbing state: reached the most recent common ancestor</span></span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> []</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Transition from n lineages to n-1 lineages via coalescence</span></span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>    n <span class="op">=</span> state[<span class="dv">0</span>]</span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>    base_rate <span class="op">=</span> n <span class="op">*</span> (n <span class="op">-</span> <span class="dv">1</span>) <span class="op">/</span> <span class="dv">2</span></span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> [([n <span class="op">-</span> <span class="dv">1</span>], <span class="fl">0.0</span>, [base_rate])]</span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Construct the coalescent graph for 4 samples</span></span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Building coalescent graph for phylogenetic analysis...</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a>coalescent_graph <span class="op">=</span> Graph(callback<span class="op">=</span>coalescent_callback, parameterized<span class="op">=</span><span class="va">True</span>, nr_samples<span class="op">=</span><span class="dv">4</span>)</span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Graph structure:"</span>)</span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  States: </span><span class="sc">{</span>coalescent_graph<span class="sc">.</span>vertices_length()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Represents the genealogy: 4 lineages → 3 lineages → 2 lineages → 1 lineage (MRCA)"</span>)</span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Parameter dimension: 1 (θ = effective population size)"</span>)</span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Each state transition has a coalescence rate that scales linearly with θ."</span>)</span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"The distribution of time to the most recent common ancestor follows a phase-type distribution."</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>Now let’s see the computational bottleneck in action. Suppose we’re conducting Bayesian inference to estimate the effective population size θ from genetic data. Our inference algorithm—whether SVGD, MCMC, or another method—requires evaluating the model’s likelihood for many different θ values. With the traditional approach, each evaluation follows the same pattern: update the graph’s edge weights to reflect the current θ, run the elimination algorithm to convert the cyclic graph to an acyclic form suitable for computation, then evaluate the desired quantity (probability density, moments, etc.) on the resulting acyclic graph. The middle step, graph elimination, dominates the computational cost despite being structurally redundant—we’re performing the same elimination sequence over and over, just with different numbers.</p>
<p>Let’s measure this effect quantitatively by simulating an inference scenario where we evaluate the expected coalescence time for many different population size hypotheses. In a real SVGD run with 100 particles over 50 iterations, we’d need 5000 evaluations. Even for this simple 4-state coalescent model, the repeated eliminations add up quickly.</p>
<div id="measure-bottleneck" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate evaluating the model for many parameter values (as in SVGD)</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>n_evaluations <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>theta_values <span class="op">=</span> np.random.exponential(<span class="fl">1.0</span>, n_evaluations)</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Traditional Approach: Repeated Graph Elimination</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Simulating </span><span class="sc">{</span>n_evaluations<span class="sc">}</span><span class="ss"> likelihood evaluations (typical for one SVGD iteration)</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a fresh graph for benchmarking</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>graph_traditional <span class="op">=</span> Graph(callback<span class="op">=</span>coalescent_callback, parameterized<span class="op">=</span><span class="va">True</span>, nr_samples<span class="op">=</span><span class="dv">4</span>)</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>start_time <span class="op">=</span> time.time()</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>expectations_traditional <span class="op">=</span> []</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, theta <span class="kw">in</span> <span class="bu">enumerate</span>(theta_values):</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Step 1: Update edge weights with new parameter value (fast, O(n))</span></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>    graph_traditional.update_parameterized_weights([theta])</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Step 2: Compute expectation</span></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Behind the scenes, this calls the elimination algorithm (slow, O(n³))</span></span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># The elimination converts the graph to acyclic form, then computes moments</span></span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>    expectation <span class="op">=</span> graph_traditional.moments(<span class="dv">1</span>)[<span class="dv">0</span>]</span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>    expectations_traditional.append(expectation)</span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> i <span class="op">&lt;</span> <span class="dv">3</span>:</span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  Evaluation </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">: θ = </span><span class="sc">{</span>theta<span class="sc">:.3f}</span><span class="ss"> → E[T_MRCA] = </span><span class="sc">{</span>expectation<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a>elapsed_traditional <span class="op">=</span> time.time() <span class="op">-</span> start_time</span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">  ..."</span>)</span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Results:"</span>)</span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Total time: </span><span class="sc">{</span>elapsed_traditional<span class="sc">:.4f}</span><span class="ss"> seconds"</span>)</span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Time per evaluation: </span><span class="sc">{</span>elapsed_traditional<span class="op">/</span>n_evaluations<span class="op">*</span><span class="dv">1000</span><span class="sc">:.3f}</span><span class="ss"> milliseconds"</span>)</span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">⚠️  Bottleneck: Each evaluation runs O(n³) graph elimination"</span>)</span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  This elimination reconstructs the same computational structure every time!"</span>)</span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  For n=</span><span class="sc">{</span>coalescent_graph<span class="sc">.</span>vertices_length()<span class="sc">}</span><span class="ss"> states: </span><span class="sc">{</span>n_evaluations<span class="sc">}</span><span class="ss"> × O(</span><span class="sc">{</span>coalescent_graph<span class="sc">.</span>vertices_length()<span class="sc">}</span><span class="ss">³) operations"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="the-symbolic-elimination-insight" class="level1">
<h1>The Symbolic Elimination Insight</h1>
<p>The dramatic inefficiency we’ve just observed stems from a fundamental mismatch between what computation we need to perform and what computation we actually perform. What we need is to evaluate the same computational structure—the same sequence of additions, multiplications, and divisions—with different input values. What we’re doing is rediscovering that computational structure from scratch for every new input, even though the structure never changes. This is analogous to recompiling a program every time you want to run it with different command-line arguments: technically correct but wastefully redundant.</p>
<p>The key insight that enables symbolic elimination is recognizing that the graph elimination algorithm has two conceptually distinct roles. First, it determines which vertices to eliminate in which order and which bypass edges to create—decisions that depend only on the graph’s topology, not on specific edge weights. Second, it performs arithmetic operations to compute the weights of new edges based on the weights of existing edges—operations that do depend on numeric values. In the traditional algorithm, these two roles are intertwined: we make structural decisions and perform arithmetic simultaneously as we traverse the graph. The symbolic approach separates these concerns by performing the structural decisions once to build a template, then filling in that template with different numeric values as needed.</p>
<p>To make this concrete, consider what happens when we eliminate a vertex v with two parents p₁ and p₂ and one child c.&nbsp;The elimination algorithm determines that we need to create edges from p₁ to c and from p₂ to c (the structural decision). The weight of the new edge from p₁ to c should be the weight from p₁ to v times the weight from v to c, divided by one minus any self-loop weight at v, then added to any existing edge from p₁ to c (the arithmetic). With traditional elimination using concrete numbers, we might compute: w_{p₁,c}’ = w_{p₁,c} + (w_{p₁,v} × w_{v,c}) / (1 - w_{v,v}). With symbolic elimination, we instead build an expression tree that represents this computation: ADD(w_{p₁,c}, DIV(MUL(w_{p₁,v}, w_{v,c}), SUB(CONST(1), w_{v,v}))), where each w_{·,·} is itself an expression in terms of parameters.</p>
<p>This expression tree representation has profound implications. Once we’ve constructed these trees by running the elimination algorithm symbolically, we can evaluate them for any parameter vector by simply traversing the trees and performing arithmetic at each node. Tree evaluation is linear in the tree size—we visit each node once, perform one arithmetic operation, and combine results from children. Since the elimination algorithm on an n-vertex graph creates expression trees of total size O(n³) in the worst case but O(n) per edge in sparse graphs, evaluation becomes O(n³) total for dense graphs but potentially much faster for realistic cases. More importantly, evaluation doesn’t repeat any structural work—there’s no vertex elimination, no topological sorting, no decision-making, just straightforward arithmetic along predetermined paths through the expression trees.</p>
<p>The complexity analysis bears this out rigorously. For m parameter vectors and an n-vertex graph, the traditional approach requires O(mn³) operations: we perform O(n³) elimination for each of the m evaluations. The symbolic approach requires O(n³) once for symbolic elimination, then O(S) for each of m evaluations, where S is the total expression tree size. In the worst case with dense graphs, S = O(n³), giving O(n³ + mn³) = O(mn³) total complexity—no improvement. But this worst case is pessimistic for two reasons. First, many practical graphs are sparse with bounded degree, yielding S = O(n) and total complexity O(n³ + mn), an improvement factor of Θ(n²) for large m. Second, even for dense graphs, the constant factors differ dramatically: symbolic evaluation is just arithmetic with no control flow overhead, while repeated elimination involves complex graph algorithms with significant constant overhead.</p>
</section>
<section id="building-blocks-expression-trees-and-symbolic-representation" class="level1">
<h1>Building Blocks: Expression Trees and Symbolic Representation</h1>
<p>To implement symbolic elimination, we need a way to represent computations symbolically rather than executing them immediately. Expression trees provide the natural data structure for this purpose. Each node in the tree represents either a primitive value (a constant or a parameter) or an arithmetic operation combining results from child nodes. By building these trees during elimination and evaluating them later, we achieve the separation of structural and numeric computation that drives our speedup.</p>
<p>The expression type system includes several primitive types that form the foundation of all symbolic computations. A CONST node represents a constant numeric value that never changes with parameters—for example, the value 1.0 that appears in the expression (1 - p) when computing geometric series for self-loops. A PARAM node references a specific parameter by index, essentially representing θ_k for some k. More commonly, we use DOT nodes that represent dot products between a constant coefficient vector and the parameter vector, computing Σᵢ aᵢθᵢ. This is the fundamental parameterization primitive: an edge with base rate r that scales linearly with parameter θ₁ becomes DOT([r, 0, …]).</p>
<p>On top of these primitives, we build composite expressions using binary operations. ADD nodes represent sums, MUL nodes represent products, DIV nodes represent quotients, and SUB nodes represent differences. There’s also a unary INV node representing reciprocals (1/x), which appears frequently when converting sums of rates to probabilities. These operations compose freely: the children of a MUL node can themselves be MUL, ADD, or any other expression type, allowing arbitrary nesting depth. The semantics are straightforward—to evaluate an expression tree at a given parameter vector θ, we recursively evaluate all child nodes to get numeric values, then apply the operation at the current node. For a DOT node with coefficient vector a, evaluation returns Σᵢ aᵢθᵢ. For a MUL node with children e₁ and e₂, evaluation returns eval(e₁, θ) × eval(e₂, θ).</p>
<p>Let’s see how these expression types combine to represent real computations from our coalescent model. Initially, an edge representing coalescence of 6 lineages (rate 6(6-1)/2 = 15 per unit of θ) starts as DOT([15.0]). When we convert this to a probability by multiplying by the reciprocal of the total outgoing rate, we might get MUL(DOT([15.0]), INV(ADD(DOT([15.0]), DOT([5.0])))), which represents (15θ) / (15θ + 5θ) = 15/20 = 0.75 regardless of θ. Notice how θ cancels algebraically—this could be simplified, but the unsimplified form is what naturally arises from the elimination algorithm. During elimination, when we create bypass edges, these expressions grow more complex. A two-step path with probabilities p₁ = DOT([a]) and p₂ = DOT([b]) combines as MUL(DOT([a]), DOT([b])), and if we add this to an existing edge DOT([c]), we get ADD(DOT([c]), MUL(DOT([a]), DOT([b]))).</p>
</section>
<section id="the-symbolic-elimination-algorithm-in-detail" class="level1">
<h1>The Symbolic Elimination Algorithm in Detail</h1>
<p>Now we can describe the symbolic elimination algorithm itself, which mirrors the structure of numeric graph elimination but operates on expression trees instead of floating-point numbers. The algorithm proceeds through several phases, each serving a specific purpose in constructing the symbolic directed acyclic graph that represents our computation.</p>
<p>The first phase establishes the elimination order through topological sorting. We need to eliminate vertices in an order that respects dependencies: vertices should be eliminated before the vertices they feed into, insofar as possible given cycles. We begin by identifying strongly connected components using Tarjan’s algorithm—maximal sets of vertices that can reach each other through directed paths. Within each component, cycles make the ordering partially arbitrary, but across components, the component graph is acyclic and defines a clear ordering. We sort components topologically, then within each component, we order vertices to prioritize non-absorbing states before absorbing ones. This ordering ensures that when we eliminate a vertex, most of its dependent vertices haven’t been eliminated yet, minimizing the complexity of expression trees.</p>
<p>The second phase initializes edge expressions based on the parameterization. Each edge in the original graph has an associated coefficient vector specifying how its weight depends on parameters. We create DOT expressions for these edges: if edge (i,j) has coefficient vector a_{ij}, we create the expression DOT(a_{ij}) to represent w_{ij}(θ) = Σ_k a_{ij,k}θ_k. This establishes the base layer of our symbolic computation—every subsequent expression we build will ultimately reference these DOT nodes at the leaves of the expression trees. At this point, each edge stores a symbolic expression rather than a concrete weight, but otherwise the graph structure remains unchanged from the input.</p>
<p>The third phase computes symbolic exit rates for each vertex. In a phase-type distribution, the total exit rate from a vertex equals the sum of weights of all outgoing edges. The reciprocal of this total rate converts raw edge weights to transition probabilities. Symbolically, for a vertex v with outgoing edges to vertices j₁, j₂, …, j_k, we construct the expression sum = ADD(w_{v,j₁}, ADD(w_{v,j₂}, …)) by building a tree of ADD nodes combining all edge weight expressions. Then we create r̂_v = INV(sum) to represent 1 / (sum of outgoing rates). This expression tree will be reused whenever we need to convert edge weights to probabilities involving vertex v.</p>
<p>The fourth phase converts edge weights to probability expressions by multiplying each edge weight by the source vertex’s rate expression. For edge (i,j), we compute p̂<em>{ij} = MUL(ŵ</em>{ij}, r̂_i), creating a tree that represents the transition probability from i to j. After this phase, all edges store probability expressions rather than weight expressions, and we’re ready for the main elimination loop. This conversion is subtle but important: elimination operates on transition probabilities, not rates, because we need to compute the probability of multi-step paths through intermediate vertices.</p>
<p>The fifth and final phase performs the actual elimination loop, processing vertices in reverse topological order. For each non-absorbing vertex v, we identify its parents P(v) (vertices with edges leading to v) and children C(v) (vertices v has edges leading to). The goal is to create direct edges from parents to children that bypass v, capturing all probability mass that flows from parents to children via v. For each parent p and child c, we need to add a new edge (or augment an existing edge) from p to c.&nbsp;The probability of this path is the probability of reaching v from p times the probability of reaching c from v: MUL(p̂<em>{pv}, p̂</em>{vc}). If v has a self-loop, we must account for the possibility of revisiting v multiple times before exiting, which introduces a geometric series scaling factor 1/(1 - p̂<em>{vv}). We represent this as INV(SUB(CONST(1), p̂</em>{vv})). The final probability for the new edge combines these: MUL(MUL(p̂<em>{pv}, p̂</em>{vc}), scale). If an edge from p to c already exists, we add this new probability: ADD(p̂_{pc}, new_prob). After processing all parent-child pairs, we remove vertex v and all its edges from the graph.</p>
<p>This elimination continues until only absorbing vertices and vertices that feed directly into absorbing vertices remain. The result is a symbolic DAG where each edge stores an expression tree that, when evaluated at parameter vector θ, produces the correct transition probability for that parameter value. The DAG has the critical property that it’s acyclic—forward evaluation can proceed without cycles or fixed-point iteration—and that its expressions encode the complete computational recipe for converting parameters to probabilities.</p>
<div id="symbolic-elimination-demo" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Performing Symbolic Elimination</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="co"># First, we must initialize the parameter dimension by calling update once</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="co"># This tells the C code how many parameters the model has</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>coalescent_graph.update_parameterized_weights([<span class="fl">1.0</span>])  <span class="co"># Initialize with θ = 1.0</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Step 1: Initialize parameter dimension"</span>)</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Called update_parameterized_weights with initial θ = [1.0]"</span>)</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  This establishes that our model has 1 parameter</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Now perform symbolic elimination</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Step 2: Run symbolic elimination algorithm"</span>)</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  This executes the O(n³) graph elimination once..."</span>)</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  But instead of computing numbers, we build expression trees...</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>start_symbolic <span class="op">=</span> time.time()</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>symbolic_dag <span class="op">=</span> coalescent_graph.eliminate_to_dag()</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>elimination_time <span class="op">=</span> time.time() <span class="op">-</span> start_symbolic</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"✓ Symbolic elimination completed in </span><span class="sc">{</span>elimination_time<span class="sc">:.4f}</span><span class="ss"> seconds</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Resulting Symbolic DAG:"</span>)</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Vertices: </span><span class="sc">{</span>symbolic_dag<span class="sc">.</span>vertices_length<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Parameters: </span><span class="sc">{</span>symbolic_dag<span class="sc">.</span>param_length<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Is acyclic: </span><span class="sc">{</span>symbolic_dag<span class="sc">.</span>is_acyclic<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">What the DAG contains:"</span>)</span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  • Graph topology: vertex states and edge connectivity"</span>)</span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  • Expression trees: each edge has a symbolic expression for its probability"</span>)</span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  • Example expression: ADD(MUL(DOT([r1]), INV(...)), DOT([r2]))"</span>)</span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">These expressions will be evaluated in O(n) time for each parameter vector."</span>)</span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"No more O(n³) elimination needed!"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="expression-evaluation-and-graph-instantiation" class="level1">
<h1>Expression Evaluation and Graph Instantiation</h1>
<p>With a symbolic DAG in hand, we can now instantiate concrete graphs for specific parameter values through a process called expression evaluation. This is where the symbolic representation pays off: evaluation is a simple tree traversal that requires linear time in the expression tree size, with no complex control flow or graph algorithms involved.</p>
<p>Expression evaluation proceeds recursively through the tree structure. For leaf nodes, evaluation is immediate: CONST nodes return their stored constant value, PARAM nodes index into the parameter vector and return θ_k, and DOT nodes compute the dot product Σᵢ aᵢθᵢ by iterating through stored coefficient-index pairs and accumulating the weighted sum. For internal nodes representing operations, we first recursively evaluate all children to obtain numeric values, then apply the operation. A MUL node with children evaluating to v₁ and v₂ returns v₁ × v₂. An ADD node returns v₁ + v₂. A DIV node returns v₁ / v₂. An INV node with child evaluating to v returns 1/v. A SUB node returns v₁ - v₂. The recursion naturally handles arbitrary nesting—a MUL node’s children might themselves be complex trees, but from the MUL node’s perspective, we simply evaluate them to get numbers and multiply those numbers.</p>
<p>Graph instantiation applies expression evaluation to every edge in the symbolic DAG, creating a concrete graph with numeric edge weights. We create a new graph structure with the same vertex set as the symbolic DAG, then for each edge (i,j) in the DAG, we evaluate its expression tree at the given parameter vector θ to obtain a numeric probability p_{ij}(θ), and add an edge from i to j with weight p_{ij}(θ) to the concrete graph. The result is a graph that represents exactly the same phase-type distribution as if we had run numeric elimination with these parameters, but obtained much more quickly because we avoided repeating the O(n³) elimination process.</p>
<p>The time complexity of instantiation depends on the total expression tree size S, which is the sum of node counts across all edge expressions in the symbolic DAG. Evaluating a tree with k nodes requires O(k) time (assuming constant-time arithmetic operations), so evaluating all edge expressions requires O(S) time. In the worst case with dense graphs, S = O(n³) because we might have O(n²) edges each with expressions of size O(n). For sparse graphs with bounded degree, S = O(n) because we have O(n) edges each with expressions of constant size. In practice, S is typically much smaller than n³ due to both sparsity and the fact that expression trees from elimination rarely reach their worst-case depth.</p>
<p>Let’s see instantiation in action by evaluating our coalescent model at several different population sizes and comparing the results to the traditional approach. This demonstrates both the correctness of symbolic elimination—the results match exactly—and its speed advantage.</p>
<div id="instantiation-demo" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Graph Instantiation: Fast Evaluation at Different Parameter Values</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Test instantiation at the same parameter values we used earlier</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>test_theta_values <span class="op">=</span> theta_values[:<span class="dv">5</span>]  <span class="co"># First 5 for detailed output</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Instantiating graphs for </span><span class="sc">{</span><span class="bu">len</span>(test_theta_values)<span class="sc">}</span><span class="ss"> different θ values...</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, theta <span class="kw">in</span> <span class="bu">enumerate</span>(test_theta_values):</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Instantiate: evaluate all expression trees with this θ value</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># This is O(S) where S is total expression tree size</span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>    start_inst <span class="op">=</span> time.time()</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>    concrete_graph <span class="op">=</span> symbolic_dag.instantiate([theta])</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>    inst_time <span class="op">=</span> (time.time() <span class="op">-</span> start_inst) <span class="op">*</span> <span class="dv">1000</span>  <span class="co"># Convert to ms</span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute expectation on the instantiated graph</span></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># The graph is already acyclic, so this is fast forward evaluation O(n)</span></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>    expectation <span class="op">=</span> concrete_graph.moments(<span class="dv">1</span>)[<span class="dv">0</span>]</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  θ = </span><span class="sc">{</span>theta<span class="sc">:.3f}</span><span class="ss">: E[T_MRCA] = </span><span class="sc">{</span>expectation<span class="sc">:.3f}</span><span class="ss">, instantiation: </span><span class="sc">{</span>inst_time<span class="sc">:.3f}</span><span class="ss">ms"</span>)</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Key Observations:"</span>)</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  ✓ Each instantiation is O(S) ≈ O(n) for sparse graphs"</span>)</span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  ✓ No graph elimination needed - expressions pre-encode the computation"</span>)</span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  ✓ Results are numerically identical to traditional approach"</span>)</span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  ✓ Instantiation time is dominated by tree traversal and arithmetic"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="comprehensive-performance-analysis" class="level1">
<h1>Comprehensive Performance Analysis</h1>
<p>Having established that symbolic elimination produces correct results, we now turn to the critical question of performance. How much faster is the symbolic approach in practice, and how does the speedup depend on problem characteristics like graph size and number of evaluations? To answer these questions rigorously, we need carefully controlled benchmarks that isolate the effects we’re measuring while accounting for implementation details and measurement overhead.</p>
<p>The fundamental comparison we want to make is between two workflows for evaluating a parameterized phase-type distribution m times with different parameters. The traditional workflow updates weights and runs numeric elimination m times, while the symbolic workflow runs symbolic elimination once and then instantiates m times. To ensure fair comparison, we should use identical parameter values for both approaches, measure only the evaluation operations (excluding setup like graph construction), and run multiple trials to account for timing variance from system load and other factors. We also need to consider warm-up effects: the first few iterations might be slower due to cache misses or JIT compilation, so we should either exclude them or ensure both approaches see similar warm-up conditions.</p>
<p>Let’s design a comprehensive benchmark that measures performance across a range of evaluation counts. This will let us see how the speedup grows as we amortize the one-time symbolic elimination cost over more evaluations. We expect the speedup to increase roughly linearly with the number of evaluations for small counts (where the O(n³) elimination cost dominates) and to plateau at some maximum speedup determined by the ratio of elimination cost to instantiation cost.</p>
<div id="benchmark-comprehensive" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> benchmark_traditional(n_evals, graph):</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Benchmark traditional approach with repeated elimination."""</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>    theta_values <span class="op">=</span> np.random.exponential(<span class="fl">1.0</span>, n_evals)</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>    start <span class="op">=</span> time.time()</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> theta <span class="kw">in</span> theta_values:</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>        graph.update_parameterized_weights([theta])</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>        _ <span class="op">=</span> graph.moments(<span class="dv">1</span>)[<span class="dv">0</span>]  <span class="co"># Triggers elimination internally</span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>    elapsed <span class="op">=</span> time.time() <span class="op">-</span> start</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> elapsed, theta_values</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> benchmark_symbolic(n_evals, symbolic_dag, theta_values):</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Benchmark symbolic approach with instantiation."""</span></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>    start <span class="op">=</span> time.time()</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> theta <span class="kw">in</span> theta_values:</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>        concrete <span class="op">=</span> symbolic_dag.instantiate([theta])</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>        _ <span class="op">=</span> concrete.moments(<span class="dv">1</span>)[<span class="dv">0</span>]</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>    elapsed <span class="op">=</span> time.time() <span class="op">-</span> start</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> elapsed</span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Comprehensive Performance Benchmark</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Test different evaluation counts to see speedup growth</span></span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a>eval_counts <span class="op">=</span> [<span class="dv">10</span>, <span class="dv">25</span>, <span class="dv">50</span>, <span class="dv">100</span>, <span class="dv">200</span>, <span class="dv">500</span>]</span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Create graphs for benchmarking</span></span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a>graph_bench_trad <span class="op">=</span> Graph(callback<span class="op">=</span>coalescent_callback, parameterized<span class="op">=</span><span class="va">True</span>, nr_samples<span class="op">=</span><span class="dv">4</span>)</span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a>graph_bench_symb <span class="op">=</span> Graph(callback<span class="op">=</span>coalescent_callback, parameterized<span class="op">=</span><span class="va">True</span>, nr_samples<span class="op">=</span><span class="dv">4</span>)</span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a>graph_bench_symb.update_parameterized_weights([<span class="fl">1.0</span>])</span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a>dag_bench <span class="op">=</span> graph_bench_symb.eliminate_to_dag()</span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Testing with coalescent model (n=</span><span class="sc">{</span>graph_bench_trad<span class="sc">.</span>vertices_length()<span class="sc">}</span><span class="ss"> states)</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb6-36"><a href="#cb6-36" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span><span class="st">'Evals'</span><span class="sc">:&gt;6}</span><span class="ss"> | </span><span class="sc">{</span><span class="st">'Traditional'</span><span class="sc">:&gt;12}</span><span class="ss"> | </span><span class="sc">{</span><span class="st">'Symbolic'</span><span class="sc">:&gt;12}</span><span class="ss"> | </span><span class="sc">{</span><span class="st">'Speedup'</span><span class="sc">:&gt;8}</span><span class="ss">"</span>)</span>
<span id="cb6-37"><a href="#cb6-37" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span><span class="st">'-'</span><span class="op">*</span><span class="dv">6</span><span class="sc">}</span><span class="ss">-+-</span><span class="sc">{</span><span class="st">'-'</span><span class="op">*</span><span class="dv">12</span><span class="sc">}</span><span class="ss">-+-</span><span class="sc">{</span><span class="st">'-'</span><span class="op">*</span><span class="dv">12</span><span class="sc">}</span><span class="ss">-+-</span><span class="sc">{</span><span class="st">'-'</span><span class="op">*</span><span class="dv">8</span><span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-38"><a href="#cb6-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-39"><a href="#cb6-39" aria-hidden="true" tabindex="-1"></a>results_traditional <span class="op">=</span> []</span>
<span id="cb6-40"><a href="#cb6-40" aria-hidden="true" tabindex="-1"></a>results_symbolic <span class="op">=</span> []</span>
<span id="cb6-41"><a href="#cb6-41" aria-hidden="true" tabindex="-1"></a>speedups <span class="op">=</span> []</span>
<span id="cb6-42"><a href="#cb6-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-43"><a href="#cb6-43" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> n_evals <span class="kw">in</span> eval_counts:</span>
<span id="cb6-44"><a href="#cb6-44" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Benchmark traditional</span></span>
<span id="cb6-45"><a href="#cb6-45" aria-hidden="true" tabindex="-1"></a>    time_trad, theta_vals <span class="op">=</span> benchmark_traditional(n_evals, graph_bench_trad)</span>
<span id="cb6-46"><a href="#cb6-46" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-47"><a href="#cb6-47" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Benchmark symbolic (use same theta values for fairness)</span></span>
<span id="cb6-48"><a href="#cb6-48" aria-hidden="true" tabindex="-1"></a>    time_symb <span class="op">=</span> benchmark_symbolic(n_evals, dag_bench, theta_vals)</span>
<span id="cb6-49"><a href="#cb6-49" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-50"><a href="#cb6-50" aria-hidden="true" tabindex="-1"></a>    speedup <span class="op">=</span> time_trad <span class="op">/</span> time_symb <span class="cf">if</span> time_symb <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> <span class="dv">0</span></span>
<span id="cb6-51"><a href="#cb6-51" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-52"><a href="#cb6-52" aria-hidden="true" tabindex="-1"></a>    results_traditional.append(time_trad)</span>
<span id="cb6-53"><a href="#cb6-53" aria-hidden="true" tabindex="-1"></a>    results_symbolic.append(time_symb)</span>
<span id="cb6-54"><a href="#cb6-54" aria-hidden="true" tabindex="-1"></a>    speedups.append(speedup)</span>
<span id="cb6-55"><a href="#cb6-55" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-56"><a href="#cb6-56" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>n_evals<span class="sc">:6d}</span><span class="ss"> | </span><span class="sc">{</span>time_trad<span class="sc">:10.4f}</span><span class="ss">s | </span><span class="sc">{</span>time_symb<span class="sc">:10.4f}</span><span class="ss">s | </span><span class="sc">{</span>speedup<span class="sc">:7.1f}</span><span class="ss">×"</span>)</span>
<span id="cb6-57"><a href="#cb6-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-58"><a href="#cb6-58" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Key Insights:"</span>)</span>
<span id="cb6-59"><a href="#cb6-59" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  • Speedup stabilizes at ~</span><span class="sc">{</span>speedups[<span class="op">-</span><span class="dv">1</span>]<span class="sc">:.0f}</span><span class="ss">× for large evaluation counts"</span>)</span>
<span id="cb6-60"><a href="#cb6-60" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  • Traditional approach: O(m × n³) where m = number of evaluations"</span>)</span>
<span id="cb6-61"><a href="#cb6-61" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  • Symbolic approach: O(n³ + m × S) where S ≈ O(n) for sparse graphs"</span>)</span>
<span id="cb6-62"><a href="#cb6-62" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  • For this </span><span class="sc">{</span>graph_bench_trad<span class="sc">.</span>vertices_length()<span class="sc">}</span><span class="ss">-state model: speedup ≈ </span><span class="sc">{</span>np<span class="sc">.</span>mean(speedups[<span class="op">-</span><span class="dv">3</span>:])<span class="sc">:.1f}</span><span class="ss">× on average"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="plot-performance" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize the performance comparison</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>fig, (ax1, ax2) <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">5</span>))</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Left panel: Time vs evaluation count</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>ax1.plot(eval_counts, results_traditional, <span class="st">'o-'</span>, linewidth<span class="op">=</span><span class="fl">2.5</span>, markersize<span class="op">=</span><span class="dv">8</span>,</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>         label<span class="op">=</span><span class="st">'Traditional (O(m×n³))'</span>, color<span class="op">=</span><span class="st">'#e74c3c'</span>)</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>ax1.plot(eval_counts, results_symbolic, <span class="st">'s-'</span>, linewidth<span class="op">=</span><span class="fl">2.5</span>, markersize<span class="op">=</span><span class="dv">8</span>,</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>         label<span class="op">=</span><span class="st">'Symbolic (O(n³+m×n))'</span>, color<span class="op">=</span><span class="st">'#27ae60'</span>)</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>ax1.set_xlabel(<span class="st">'Number of Evaluations'</span>, fontsize<span class="op">=</span><span class="dv">13</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>ax1.set_ylabel(<span class="st">'Total Time (seconds)'</span>, fontsize<span class="op">=</span><span class="dv">13</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>ax1.set_title(<span class="st">'Computation Time vs Evaluation Count'</span>, fontsize<span class="op">=</span><span class="dv">14</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>ax1.legend(fontsize<span class="op">=</span><span class="dv">11</span>, loc<span class="op">=</span><span class="st">'upper left'</span>)</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>ax1.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Right panel: Speedup vs evaluation count</span></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>ax2.plot(eval_counts, speedups, <span class="st">'o-'</span>, linewidth<span class="op">=</span><span class="fl">2.5</span>, markersize<span class="op">=</span><span class="dv">8</span>, color<span class="op">=</span><span class="st">'#3498db'</span>)</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>ax2.axhline(y<span class="op">=</span><span class="dv">1</span>, color<span class="op">=</span><span class="st">'red'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, alpha<span class="op">=</span><span class="fl">0.5</span>, linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'No speedup'</span>)</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>ax2.set_xlabel(<span class="st">'Number of Evaluations'</span>, fontsize<span class="op">=</span><span class="dv">13</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>ax2.set_ylabel(<span class="st">'Speedup Factor'</span>, fontsize<span class="op">=</span><span class="dv">13</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>ax2.set_title(<span class="st">'Speedup: Traditional / Symbolic'</span>, fontsize<span class="op">=</span><span class="dv">14</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>ax2.legend(fontsize<span class="op">=</span><span class="dv">11</span>, loc<span class="op">=</span><span class="st">'upper left'</span>)</span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>ax2.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Performance Analysis:"</span>)</span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  The left panel shows that traditional time grows linearly with evaluations,"</span>)</span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  while symbolic time grows much more slowly after the initial elimination cost."</span>)</span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">  The right panel shows speedup increasing as we amortize the one-time symbolic"</span>)</span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  elimination across more evaluations, then plateauing at the maximum speedup"</span>)</span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  determined by the ratio of elimination cost to instantiation cost."</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="symbolic-dag-caching-avoiding-repeated-elimination-across-sessions" class="level1">
<h1>Symbolic DAG Caching: Avoiding Repeated Elimination Across Sessions</h1>
<p>While symbolic elimination dramatically accelerates parameter sweeps within a single session by performing graph elimination once and reusing the result, we face a new challenge when working across multiple sessions: each time we restart our Python interpreter or begin a new analysis, we must rebuild the symbolic DAG from scratch. For models with large state spaces, this one-time O(n³) symbolic elimination can still take seconds or even minutes, creating friction in iterative workflows where we repeatedly refine analyses, experiment with different inference configurations, or share models among research collaborators.</p>
<p>The fundamental issue is that symbolic elimination produces a specific computation structure—a directed acyclic graph with expression trees on edges—that depends only on the graph’s topological structure and parameterization pattern, not on any specific parameter values. Two graphs with identical topology and identical parameterization patterns will produce identical symbolic DAGs through the elimination algorithm. This structural equivalence suggests a caching opportunity: if we can detect when two graphs are structurally identical, we can compute the symbolic DAG once, store it to disk, and retrieve it in future sessions, completely bypassing the elimination algorithm.</p>
<p>The PtDAlgorithms library implements a sophisticated symbolic DAG caching system that automatically recognizes when a graph has been symbolically eliminated before and retrieves the cached result. The system uses cryptographic hashing to compute a unique fingerprint for each graph’s structure, stores symbolic DAGs in an indexed database for fast retrieval, and handles cache invalidation, export/import for sharing caches with collaborators, and integration with distributed computing environments. For users, the caching is largely transparent—graphs are automatically cached when first eliminated, and subsequent eliminations of structurally identical graphs return instantly from the cache.</p>
<p>This caching layer transforms the workflow for iterative model development and collaborative research. Models that took minutes to eliminate now load instantly on subsequent runs. Collaborators can share pre-computed symbolic DAGs alongside code, allowing others to immediately begin inference without waiting for elimination. Large parameter sweep experiments can be checkpointed and resumed without re-elimination. The combination of within-session speedup from symbolic elimination and cross-session speedup from caching enables workflows that would be prohibitively slow with traditional approaches.</p>
<section id="content-based-graph-hashing" class="level2">
<h2 class="anchored" data-anchor-id="content-based-graph-hashing">Content-Based Graph Hashing</h2>
<p>The foundation of the caching system is a content-based hashing scheme that assigns each graph a unique 256-bit hash value based on its structure. This hash must have several critical properties: it must be deterministic (the same graph always produces the same hash), collision-resistant (different graphs produce different hashes with overwhelming probability), and independent of parameter values (changing edge weights doesn’t change the hash). The last property is essential because symbolic elimination produces the same computation structure regardless of which specific parameter values we use—only the graph’s topology and parameterization pattern matter.</p>
<p>The hashing algorithm combines several techniques to achieve these properties. We use the SHA-256 cryptographic hash function as the underlying primitive, providing strong collision resistance with a 2^-256 probability that two different graphs produce the same hash. To handle the challenge that graphs have no canonical ordering of vertices, we employ a modified Weisfeiler-Lehman graph hashing scheme that aggregates vertex-level hashes in a way that’s independent of vertex enumeration. For each vertex, we compute a hash of its state vector (the integer coordinates identifying its position in the state space) and its outgoing edges, where each edge contributes a hash combining the target vertex’s state and the edge’s parameterization coefficients. We then sort these vertex hashes lexicographically and concatenate them to produce a final graph-level hash.</p>
<p>Crucially, the hash depends only on graph structure and parameterization patterns, not on concrete parameter values. When we hash an edge with coefficients [a₁, a₂, …, aₖ], we include these coefficients in the hash because they determine how edge weights scale with parameters, which affects the symbolic DAG structure. But we don’t include the current edge weight value itself, because that’s just a₁θ₁ + a₂θ₂ + … + aₖθₖ evaluated at the current parameters, and different parameter choices shouldn’t change the hash. This design ensures that a graph constructed for θ = [1.0, 2.0] produces the same hash as an identical graph constructed for θ = [3.5, 7.2], allowing cache hits across different parameterizations.</p>
<div id="cache-demo-first-run" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> ptdalgorithms <span class="im">import</span> SymbolicCache</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Demonstrating Symbolic DAG Caching</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize cache</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>cache <span class="op">=</span> SymbolicCache()</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Cache Configuration:"</span>)</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Location: </span><span class="sc">{</span>cache<span class="sc">.</span>cache_dir<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Backend: SQLite database with content-addressed storage"</span>)</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Hash algorithm: SHA-256 with Weisfeiler-Lehman graph hashing</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Build a fresh coalescent graph</span></span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"First Run: Building symbolic DAG from scratch..."</span>)</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>graph_cache_test <span class="op">=</span> Graph(callback<span class="op">=</span>coalescent_callback, parameterized<span class="op">=</span><span class="va">True</span>, nr_samples<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>graph_cache_test.update_parameterized_weights([<span class="fl">1.0</span>])</span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a><span class="co"># First elimination: cache miss, must compute</span></span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>start_first <span class="op">=</span> time.time()</span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a>dag_first <span class="op">=</span> graph_cache_test.eliminate_to_dag()</span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>time_first <span class="op">=</span> time.time() <span class="op">-</span> start_first</span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"✓ Symbolic elimination completed in </span><span class="sc">{</span>time_first<span class="sc">:.4f}</span><span class="ss">s"</span>)</span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  This result is now cached for future use</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Get cache statistics</span></span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a>cache_info <span class="op">=</span> cache.info()</span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Cache Statistics:"</span>)</span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Entries: </span><span class="sc">{</span>cache_info[<span class="st">'num_entries'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb8-31"><a href="#cb8-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Total size: </span><span class="sc">{</span>cache_info[<span class="st">'total_size_mb'</span>]<span class="sc">:.2f}</span><span class="ss"> MB"</span>)</span>
<span id="cb8-32"><a href="#cb8-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Hit rate: </span><span class="sc">{</span>cache_info[<span class="st">'hit_rate'</span>]<span class="op">*</span><span class="dv">100</span><span class="sc">:.1f}</span><span class="ss">% (this session)"</span> <span class="cf">if</span> cache_info[<span class="st">'hit_rate'</span>] <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="cf">else</span> <span class="st">"  Hit rate: N/A (first run)"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="cache-demo-second-run" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Second Run: Using cached symbolic DAG..."</span>)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Build an identical graph with different parameter value</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="co"># The structure is the same, so we should get a cache hit</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>graph_cache_test2 <span class="op">=</span> Graph(callback<span class="op">=</span>coalescent_callback, parameterized<span class="op">=</span><span class="va">True</span>, nr_samples<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>graph_cache_test2.update_parameterized_weights([<span class="fl">2.5</span>])  <span class="co"># Different parameter value</span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Second elimination: cache hit, should be instant</span></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>start_second <span class="op">=</span> time.time()</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>dag_second <span class="op">=</span> graph_cache_test2.eliminate_to_dag()</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>time_second <span class="op">=</span> time.time() <span class="op">-</span> start_second</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"✓ Retrieved from cache in </span><span class="sc">{</span>time_second<span class="sc">:.4f}</span><span class="ss">s"</span>)</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Speedup: </span><span class="sc">{</span>time_first<span class="op">/</span>time_second<span class="sc">:.0f}</span><span class="ss">× faster than computing from scratch"</span>)</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Key Insight:"</span>)</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  • Graph with θ=[1.0] and θ=[2.5] have identical structure"</span>)</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  • Both produce the same symbolic DAG through elimination"</span>)</span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  • Cache recognizes this and avoids redundant computation"</span>)</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  • Result: </span><span class="sc">{</span>time_first<span class="op">/</span>time_second<span class="sc">:.0f}</span><span class="ss">× speedup on subsequent runs"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="automatic-caching-in-high-level-api" class="level2">
<h2 class="anchored" data-anchor-id="automatic-caching-in-high-level-api">Automatic Caching in High-Level API</h2>
<p>While the explicit caching workflow demonstrates how the system works, in practice you rarely need to interact with the cache directly. The <code>Graph.pmf_from_graph()</code> and <code>Graph.pmf_from_graph_parameterized()</code> methods automatically check the cache before performing symbolic elimination, providing transparent caching without any code changes. This automatic caching is enabled by default but can be disabled with the <code>use_cache=False</code> parameter if needed.</p>
<p>The automatic caching workflow proceeds as follows: when you call <code>pmf_from_graph(graph)</code>, the function first computes a hash of the graph’s structure, queries the symbolic cache to see if a DAG with this hash exists, and if found, deserializes the cached DAG and uses it directly. Only if the cache misses does the function perform symbolic elimination, after which it stores the result in the cache for future use. This means that the first time you construct a model, you pay the elimination cost, but every subsequent construction of the same model (even in different Python sessions) retrieves instantly from the cache.</p>
<p>This behavior is especially powerful when combined with parameterized models used in inference. During SVGD or MCMC, you might run your inference script dozens of times while tuning hyperparameters, adjusting priors, or debugging code. With automatic caching, the expensive symbolic elimination happens only on the first run—every subsequent run starts immediately with inference, saving minutes or hours of waiting. For collaborative projects, team members can share the cache directory, and once one person has computed the symbolic DAG for a model, everyone else gets instant loading.</p>
<div id="automatic-cache-demo" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Automatic Caching with High-Level API</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Build graph for a larger coalescent model</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Building larger coalescent model (n=8 samples)..."</span>)</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>graph_auto <span class="op">=</span> Graph(callback<span class="op">=</span>coalescent_callback, parameterized<span class="op">=</span><span class="va">True</span>, nr_samples<span class="op">=</span><span class="dv">8</span>)</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a><span class="co"># First call: cache miss (graph not seen before)</span></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">First call to pmf_from_graph() with n=8:"</span>)</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>start_auto1 <span class="op">=</span> time.time()</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>model_auto <span class="op">=</span> Graph.pmf_from_graph(graph_auto, use_cache<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>time_auto1 <span class="op">=</span> time.time() <span class="op">-</span> start_auto1</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Completed in </span><span class="sc">{</span>time_auto1<span class="sc">:.4f}</span><span class="ss">s (includes symbolic elimination + caching)"</span>)</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Build another identical graph with different initial parameters</span></span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>graph_auto2 <span class="op">=</span> Graph(callback<span class="op">=</span>coalescent_callback, parameterized<span class="op">=</span><span class="va">True</span>, nr_samples<span class="op">=</span><span class="dv">8</span>)</span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Second call: cache hit</span></span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Second call to pmf_from_graph() with n=8 (identical structure):"</span>)</span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a>start_auto2 <span class="op">=</span> time.time()</span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a>model_auto2 <span class="op">=</span> Graph.pmf_from_graph(graph_auto2, use_cache<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a>time_auto2 <span class="op">=</span> time.time() <span class="op">-</span> start_auto2</span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Completed in </span><span class="sc">{</span>time_auto2<span class="sc">:.4f}</span><span class="ss">s (cache hit!)"</span>)</span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Speedup: </span><span class="sc">{</span>time_auto1<span class="op">/</span>time_auto2<span class="sc">:.0f}</span><span class="ss">×"</span>)</span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">💡 Key Benefit:"</span>)</span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"   • No code changes needed - caching is automatic"</span>)</span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"   • Works across Python sessions and restarts"</span>)</span>
<span id="cb10-29"><a href="#cb10-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"   • Persistent cache shared among all scripts"</span>)</span>
<span id="cb10-30"><a href="#cb10-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   • For this model: </span><span class="sc">{</span>time_auto1<span class="op">/</span>time_auto2<span class="sc">:.0f}</span><span class="ss">× speedup on second+ runs"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="cache-management-and-sharing" class="level2">
<h2 class="anchored" data-anchor-id="cache-management-and-sharing">Cache Management and Sharing</h2>
<p>The symbolic cache is designed to be low-maintenance, automatically handling storage, indexing, and cleanup. However, for advanced workflows, the cache system provides tools for inspecting cache contents, importing and exporting caches for sharing with collaborators, and managing cache size and age.</p>
<p><strong>Cache Location and Structure:</strong> By default, the cache is stored in <code>~/.ptdalgorithms_cache/symbolic/</code> with a SQLite database for indexing and individual JSON files for each symbolic DAG. This structure allows fast lookups by hash while keeping DAGs in a human-readable format that can be inspected or debugged if needed.</p>
<p><strong>Inspection and Statistics:</strong> The <code>cache.info()</code> method provides summary statistics about cache size, number of entries, and hit rates. The <code>cache.list_entries()</code> method shows individual cache entries with their hashes, timestamps, and metadata. The standalone <code>print_cache_info()</code> function provides a formatted summary suitable for notebooks and scripts.</p>
<p><strong>Export and Import:</strong> For sharing models with collaborators or deploying pre-computed models to production, the <code>cache.export_library()</code> method packages selected cache entries into a directory that can be shared. The <code>cache.import_library()</code> method imports these entries into another user’s cache. This enables workflows where one person computes expensive symbolic DAGs and others immediately load them.</p>
<p><strong>Cache Cleanup:</strong> The cache automatically evicts old entries using an LRU (Least Recently Used) policy when it reaches a size limit (default 10GB). Manual cleanup is available through <code>cache.clear()</code> to remove all entries or <code>cache.vacuum()</code> to remove entries older than a specified age. For programmatic control, you can query and delete specific entries by hash.</p>
<p><strong>Distributed Computing:</strong> In HPC environments with shared filesystems, multiple compute nodes can share a single cache by configuring the cache directory to point to network storage. The cache uses file locking to coordinate concurrent access, allowing distributed jobs to safely share symbolic DAGs without redundant computation. See the distributed computing tutorial for details.</p>
<div id="cache-management-demo" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> ptdalgorithms <span class="im">import</span> print_cache_info</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Cache Management Tools</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Show detailed cache information</span></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Cache Summary:"</span>)</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>print_cache_info()</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a><span class="co"># List recent cache entries</span></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Recent Cache Entries:</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>entries <span class="op">=</span> cache.list_entries(limit<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, entry <span class="kw">in</span> <span class="bu">enumerate</span>(entries, <span class="dv">1</span>):</span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">. Hash: </span><span class="sc">{</span>entry[<span class="st">'hash_key'</span>][:<span class="dv">16</span>]<span class="sc">}</span><span class="ss">..."</span>)</span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   Created: </span><span class="sc">{</span>entry[<span class="st">'created_at'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   Vertices: </span><span class="sc">{</span>entry[<span class="st">'vertices'</span>]<span class="sc">}</span><span class="ss">, Edges: </span><span class="sc">{</span>entry[<span class="st">'edges'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   Size: </span><span class="sc">{</span>entry[<span class="st">'size_kb'</span>]<span class="sc">:.1f}</span><span class="ss"> KB</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Export cache for sharing</span></span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Exporting cache for collaborators..."</span>)</span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a>export_dir <span class="op">=</span> Path(<span class="st">"/tmp/ptd_cache_export"</span>)</span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a>cache.export_library(export_dir, hash_keys<span class="op">=</span><span class="va">None</span>)  <span class="co"># Export all entries</span></span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"✓ Cache exported to: </span><span class="sc">{</span>export_dir<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Share this directory with collaborators so they can:"</span>)</span>
<span id="cb11-27"><a href="#cb11-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  cache.import_library('</span><span class="sc">{</span>export_dir<span class="sc">}</span><span class="ss">')"</span>)</span>
<span id="cb11-28"><a href="#cb11-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"And immediately use your pre-computed symbolic DAGs!"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="combined-performance-impact-symbolic-elimination-caching" class="level2">
<h2 class="anchored" data-anchor-id="combined-performance-impact-symbolic-elimination-caching">Combined Performance Impact: Symbolic Elimination + Caching</h2>
<p>Understanding the full performance picture requires considering both symbolic elimination and caching together. These two techniques address complementary bottlenecks: symbolic elimination accelerates parameter sweeps within a session by avoiding repeated graph elimination for each parameter value, while caching accelerates subsequent sessions by avoiding repeated symbolic elimination for the same model structure.</p>
<p><strong>Within-Session Performance:</strong> Symbolic elimination provides speedups proportional to the number of parameter evaluations—for m evaluations, we see roughly m× speedup compared to traditional approaches, since we perform O(n³) work once instead of m times. For inference with hundreds of SVGD particles or thousands of MCMC iterations, this translates to 100-1000× speedup. In our earlier benchmark, we measured speedups ranging from 10× to 50× depending on the number of evaluations.</p>
<p><strong>Cross-Session Performance:</strong> Caching provides speedups for the symbolic elimination step itself—instead of O(n³) elimination on each script run, we pay this cost only once and retrieve in O(1) time (technically O(n) for deserialization, but vastly faster than O(n³) elimination). For models where symbolic elimination takes seconds to minutes, caching eliminates this startup delay entirely on subsequent runs. Typical speedups for cache hits range from 50× to 1000× depending on model complexity.</p>
<p><strong>Combined Impact:</strong> The two techniques multiply: within a session, symbolic elimination gives us m× speedup over traditional approaches, and across sessions, caching gives us another k× speedup for the elimination step (where k is the ratio of elimination time to cache retrieval time). For a typical workflow with 100 parameter evaluations and 10 script runs during development, the effective speedup is roughly 100 × k ≈ 1000× compared to traditional approaches without either optimization.</p>
<p><strong>Practical Example:</strong> Consider developing a Bayesian inference pipeline for a coalescent model. The workflow might involve:</p>
<ol type="1">
<li><strong>First development session:</strong> Build model, run symbolic elimination (10s), run SVGD with 100 particles × 50 iterations (5000 evaluations, 30s with symbolic elimination vs 8 hours traditional)</li>
<li><strong>Second session (tune priors):</strong> Load from cache (0.1s), run SVGD (30s). Traditional: 8 hours.</li>
<li><strong>Third session (adjust SVGD hyperparameters):</strong> Load from cache (0.1s), run SVGD (30s). Traditional: 8 hours.</li>
<li><strong>Subsequent sessions:</strong> Continue development with instant model loading and fast inference.</li>
</ol>
<p>Total development time: ~2 minutes for model setup across all sessions + inference time, compared to 24+ hours with traditional approaches. The combination of symbolic elimination and caching transforms iterative model development from a multi-day process to an interactive workflow.</p>
</section>
</section>
<section id="integration-with-bayesian-inference-algorithms" class="level1">
<h1>Integration with Bayesian Inference Algorithms</h1>
<p>The performance benefits of symbolic elimination become most apparent when we consider its application to Bayesian inference, where the pattern of repeated evaluations with different parameters is not just common but fundamental to the algorithms themselves. Stein Variational Gradient Descent provides an excellent example of how symbolic elimination transforms inference from computationally prohibitive to practically feasible.</p>
<p>SVGD approximates a posterior distribution using a swarm of particles that evolve under a carefully designed dynamics. At each iteration, we must evaluate the log posterior density and its gradient for every particle, then update particle positions based on interactions with other particles through a kernel function. For a parameterized phase-type distribution serving as the likelihood component of the posterior, each evaluation requires computing distribution properties (typically the PDF or PMF values at observed data points) for the particle’s current parameter vector. With traditional elimination, this means running the O(n³) elimination algorithm twice per particle per iteration—once for the forward pass computing the likelihood, and once for the gradient computation through automatic differentiation. For 100 particles over 50 iterations, that’s 10,000 eliminations, each with cubic cost in state space size.</p>
<p>Symbolic elimination changes this calculation dramatically. We perform symbolic elimination once before starting SVGD, obtaining a symbolic DAG that encodes the computation structure. During each SVGD iteration, evaluating the likelihood for a particle requires instantiating the symbolic DAG with the particle’s parameters (O(n) operation) and then computing distribution properties on the resulting acyclic graph (another O(n) operation). Gradient computation through automatic differentiation also benefits: modern AD frameworks like JAX can differentiate through the instantiation and evaluation operations, requiring only O(n) additional work per particle rather than O(n³). The total cost becomes O(n³ + T × m × n) where T is the number of iterations and m is the number of particles, compared to O(T × m × n³) for the traditional approach—a speedup factor of Θ(T × m) that can easily reach hundreds or thousands for realistic inference problems.</p>
<p>Beyond SVGD, symbolic elimination accelerates other inference methods similarly. Markov Chain Monte Carlo methods like Metropolis-Hastings or Hamiltonian Monte Carlo evaluate the target density at each proposed state, requiring one graph evaluation per MCMC step. With millions of MCMC steps common for ensuring convergence and obtaining low-variance estimates, the speedup from avoiding repeated elimination becomes multiplicative with the chain length. Maximum likelihood estimation and maximum a posteriori estimation through gradient-based optimization also benefit, as each optimization iteration requires evaluating the objective and its gradient at the current parameter estimate. Even sensitivity analysis—computing derivatives of distribution properties with respect to parameters using finite differences or automatic differentiation—sees dramatic speedups from symbolic elimination’s efficient parameter sweeps.</p>
<div id="svgd-simulation" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Simulating SVGD Workflow with Symbolic Elimination</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="co"># SVGD configuration</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>n_particles <span class="op">=</span> <span class="dv">50</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>n_iterations <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Configuration:"</span>)</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Particles: </span><span class="sc">{</span>n_particles<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Iterations: </span><span class="sc">{</span>n_iterations<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Total evaluations: </span><span class="sc">{</span>n_particles <span class="op">*</span> n_iterations<span class="sc">}</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Setup symbolic DAG (one-time cost)</span></span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>graph_svgd <span class="op">=</span> Graph(callback<span class="op">=</span>coalescent_callback, parameterized<span class="op">=</span><span class="va">True</span>, nr_samples<span class="op">=</span><span class="dv">4</span>)</span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>graph_svgd.update_parameterized_weights([<span class="fl">1.0</span>])</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"One-time setup: Performing symbolic elimination..."</span>)</span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>start_elim <span class="op">=</span> time.time()</span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>dag_svgd <span class="op">=</span> graph_svgd.eliminate_to_dag()</span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a>elim_time <span class="op">=</span> time.time() <span class="op">-</span> start_elim</span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"✓ Symbolic elimination completed in </span><span class="sc">{</span>elim_time<span class="sc">:.4f}</span><span class="ss">s</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize particles</span></span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a>particles <span class="op">=</span> np.random.exponential(<span class="fl">1.0</span>, n_particles)</span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Running SVGD iterations...</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-28"><a href="#cb12-28" aria-hidden="true" tabindex="-1"></a>total_start <span class="op">=</span> time.time()</span>
<span id="cb12-29"><a href="#cb12-29" aria-hidden="true" tabindex="-1"></a>iteration_times <span class="op">=</span> []</span>
<span id="cb12-30"><a href="#cb12-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-31"><a href="#cb12-31" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> iteration <span class="kw">in</span> <span class="bu">range</span>(n_iterations):</span>
<span id="cb12-32"><a href="#cb12-32" aria-hidden="true" tabindex="-1"></a>    iter_start <span class="op">=</span> time.time()</span>
<span id="cb12-33"><a href="#cb12-33" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb12-34"><a href="#cb12-34" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Evaluate likelihood for all particles (O(m × n) with symbolic elimination)</span></span>
<span id="cb12-35"><a href="#cb12-35" aria-hidden="true" tabindex="-1"></a>    log_probs <span class="op">=</span> []</span>
<span id="cb12-36"><a href="#cb12-36" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> theta <span class="kw">in</span> particles:</span>
<span id="cb12-37"><a href="#cb12-37" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Fast O(n) instantiation + evaluation</span></span>
<span id="cb12-38"><a href="#cb12-38" aria-hidden="true" tabindex="-1"></a>        concrete <span class="op">=</span> dag_svgd.instantiate([theta])</span>
<span id="cb12-39"><a href="#cb12-39" aria-hidden="true" tabindex="-1"></a>        expectation <span class="op">=</span> concrete.moments(<span class="dv">1</span>)[<span class="dv">0</span>]</span>
<span id="cb12-40"><a href="#cb12-40" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Use negative expectation as proxy for log posterior</span></span>
<span id="cb12-41"><a href="#cb12-41" aria-hidden="true" tabindex="-1"></a>        log_prob <span class="op">=</span> <span class="op">-</span>expectation</span>
<span id="cb12-42"><a href="#cb12-42" aria-hidden="true" tabindex="-1"></a>        log_probs.append(log_prob)</span>
<span id="cb12-43"><a href="#cb12-43" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb12-44"><a href="#cb12-44" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Simulate SVGD particle update (simplified for demonstration)</span></span>
<span id="cb12-45"><a href="#cb12-45" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Real SVGD would compute kernel interactions and gradients</span></span>
<span id="cb12-46"><a href="#cb12-46" aria-hidden="true" tabindex="-1"></a>    particles <span class="op">+=</span> np.random.randn(n_particles) <span class="op">*</span> <span class="fl">0.05</span></span>
<span id="cb12-47"><a href="#cb12-47" aria-hidden="true" tabindex="-1"></a>    particles <span class="op">=</span> np.maximum(particles, <span class="fl">0.01</span>)  <span class="co"># Keep positive</span></span>
<span id="cb12-48"><a href="#cb12-48" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb12-49"><a href="#cb12-49" aria-hidden="true" tabindex="-1"></a>    iter_time <span class="op">=</span> time.time() <span class="op">-</span> iter_start</span>
<span id="cb12-50"><a href="#cb12-50" aria-hidden="true" tabindex="-1"></a>    iteration_times.append(iter_time)</span>
<span id="cb12-51"><a href="#cb12-51" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb12-52"><a href="#cb12-52" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Iteration </span><span class="sc">{</span>iteration<span class="op">+</span><span class="dv">1</span><span class="sc">:2d}</span><span class="ss">: </span><span class="sc">{</span>iter_time<span class="sc">:.4f}</span><span class="ss">s, mean(log_prob)=</span><span class="sc">{</span>np<span class="sc">.</span>mean(log_probs)<span class="sc">:7.3f}</span><span class="ss">"</span>)</span>
<span id="cb12-53"><a href="#cb12-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-54"><a href="#cb12-54" aria-hidden="true" tabindex="-1"></a>total_time <span class="op">=</span> time.time() <span class="op">-</span> total_start</span>
<span id="cb12-55"><a href="#cb12-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-56"><a href="#cb12-56" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Results:"</span>)</span>
<span id="cb12-57"><a href="#cb12-57" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Total SVGD time: </span><span class="sc">{</span>total_time<span class="sc">:.4f}</span><span class="ss">s"</span>)</span>
<span id="cb12-58"><a href="#cb12-58" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Time per iteration: </span><span class="sc">{</span>np<span class="sc">.</span>mean(iteration_times)<span class="sc">:.4f}</span><span class="ss">s"</span>)</span>
<span id="cb12-59"><a href="#cb12-59" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Time per evaluation: </span><span class="sc">{</span>total_time<span class="op">/</span>(n_particles<span class="op">*</span>n_iterations)<span class="op">*</span><span class="dv">1000</span><span class="sc">:.3f}</span><span class="ss">ms"</span>)</span>
<span id="cb12-60"><a href="#cb12-60" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">  One-time symbolic elimination: </span><span class="sc">{</span>elim_time<span class="sc">:.4f}</span><span class="ss">s"</span>)</span>
<span id="cb12-61"><a href="#cb12-61" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Amortized cost per evaluation: </span><span class="sc">{</span>(elim_time <span class="op">+</span> total_time)<span class="op">/</span>(n_particles<span class="op">*</span>n_iterations)<span class="op">*</span><span class="dv">1000</span><span class="sc">:.3f}</span><span class="ss">ms"</span>)</span>
<span id="cb12-62"><a href="#cb12-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-63"><a href="#cb12-63" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare to traditional approach</span></span>
<span id="cb12-64"><a href="#cb12-64" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Comparison to Traditional Approach:"</span>)</span>
<span id="cb12-65"><a href="#cb12-65" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Traditional: </span><span class="sc">{</span>n_particles <span class="op">*</span> n_iterations<span class="sc">}</span><span class="ss"> × O(n³) eliminations"</span>)</span>
<span id="cb12-66"><a href="#cb12-66" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Symbolic: 1 × O(n³) elimination + </span><span class="sc">{</span>n_particles <span class="op">*</span> n_iterations<span class="sc">}</span><span class="ss"> × O(n) instantiations"</span>)</span>
<span id="cb12-67"><a href="#cb12-67" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Expected speedup: ~</span><span class="sc">{</span>n_particles <span class="op">*</span> n_iterations<span class="sc">}</span><span class="ss">× for large graphs"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="practical-considerations-and-best-practices" class="level1">
<h1>Practical Considerations and Best Practices</h1>
<p>While symbolic elimination provides dramatic performance improvements in the right contexts, using it effectively requires understanding when it applies, how to structure your models appropriately, and what trade-offs to consider. Several practical factors influence whether symbolic elimination is beneficial for a particular problem and how much speedup you can expect.</p>
<p>The most important consideration is the evaluation pattern: symbolic elimination is worthwhile when you need to evaluate the same graph structure with many different parameter values, but not for one-off evaluations or problems where the graph structure itself changes with parameters. The break-even point occurs around 10-20 evaluations for moderately sized graphs, where the time saved by avoiding repeated eliminations exceeds the overhead of symbolic elimination and storage. For inference algorithms that naturally perform hundreds or thousands of evaluations, this break-even is reached almost immediately, making symbolic elimination essentially free given the enormous subsequent speedups.</p>
<p>Graph structure plays a crucial role in determining speedup magnitude. Sparse graphs with bounded vertex degree benefit most dramatically because their expression trees remain small (size O(n) total rather than O(n³)), making instantiation extremely fast relative to elimination. Dense graphs still benefit significantly, but the speedup is limited by the ratio of elimination time to instantiation time rather than asymptotically growing with the number of evaluations. For very small graphs (fewer than 10 vertices), the absolute time savings may be negligible regardless of speedup factor, though this rarely matters in practice since small graphs are already fast to evaluate.</p>
<p>The parameterization structure affects both the ease of using symbolic elimination and its performance. Linear parameterizations—where edge weights are linear combinations of parameters—work perfectly with the expression tree framework and arise naturally in many models. More complex parameterizations involving nonlinear functions of parameters (exponentials, powers, etc.) can still be handled by encoding these functions as DOT nodes with appropriately computed coefficients, though this may require model restructuring. The key requirement is that edge weights be computable from parameters through arithmetic operations representable in the expression type system.</p>
<p>Memory consumption deserves attention for large-scale problems. The symbolic DAG stores expression trees for all edges, using more memory than the original numeric graph. Expression tree size grows with graph size and complexity, potentially becoming significant for graphs with thousands of vertices or heavily nested elimination structures. For models where memory becomes limiting, strategies include working with partitioned state spaces, using lazy evaluation to avoid materializing all expressions simultaneously, or applying expression simplification to reduce tree sizes. In practice, memory is rarely the limiting factor for graphs of reasonable size (up to hundreds of vertices), and the computational speedup typically justifies the memory overhead.</p>
<p>Numerical stability generally poses no concerns with symbolic elimination because expression evaluation performs the same arithmetic operations in the same order as traditional elimination would, just with different input values. Floating-point errors accumulate identically, and results match traditional evaluation to machine precision. One subtle point: very deep expression trees might accumulate slightly more rounding error than shallower alternatives due to longer chains of operations, but this effect is negligible for practical expression depths. If numerical issues arise, they typically indicate problems with the underlying model parameterization rather than the symbolic elimination technique.</p>
<div id="best-practices" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Best Practices for Symbolic Elimination</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">When to Use Symbolic Elimination:</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"✓ RECOMMENDED for:"</span>)</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  • Bayesian inference (SVGD, MCMC, optimization)"</span>)</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  • Parameter sweeps and sensitivity analysis"</span>)</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  • Any scenario requiring 10+ evaluations with different parameters"</span>)</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  • Models with moderate to large state spaces (n &gt; 10 vertices)"</span>)</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">✗ NOT RECOMMENDED for:"</span>)</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  • Single or few evaluations (overhead exceeds savings)"</span>)</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  • Models where graph structure changes with parameters"</span>)</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  • Very small graphs (n &lt; 5) where evaluation is already fast"</span>)</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n\n</span><span class="st">Standard Workflow Pattern:</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>workflow <span class="op">=</span> <span class="st">"""# Step 1: Define parameterized model</span></span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a><span class="st">def model_callback(state, **kwargs):</span></span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a><span class="st">    # Return transitions with edge_state coefficient vectors</span></span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a><span class="st">    return [(next_state, 0.0, [coeff1, coeff2, ...])]</span></span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a><span class="st"># Step 2: Create parameterized graph</span></span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a><span class="st">graph = Graph(callback=model_callback, parameterized=True)</span></span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a><span class="st"># Step 3: Initialize parameter length</span></span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a><span class="st">graph.update_parameterized_weights(initial_params)</span></span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a><span class="st"># Step 4: Symbolic elimination (ONCE - O(n³))</span></span>
<span id="cb13-29"><a href="#cb13-29" aria-hidden="true" tabindex="-1"></a><span class="st">dag = graph.eliminate_to_dag()</span></span>
<span id="cb13-30"><a href="#cb13-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-31"><a href="#cb13-31" aria-hidden="true" tabindex="-1"></a><span class="st"># Step 5: Use for inference (MANY TIMES - O(n) each)</span></span>
<span id="cb13-32"><a href="#cb13-32" aria-hidden="true" tabindex="-1"></a><span class="st">for theta in parameter_samples:</span></span>
<span id="cb13-33"><a href="#cb13-33" aria-hidden="true" tabindex="-1"></a><span class="st">    concrete = dag.instantiate(theta)  # Fast!</span></span>
<span id="cb13-34"><a href="#cb13-34" aria-hidden="true" tabindex="-1"></a><span class="st">    result = compute_property(concrete)</span></span>
<span id="cb13-35"><a href="#cb13-35" aria-hidden="true" tabindex="-1"></a><span class="st">"""</span></span>
<span id="cb13-36"><a href="#cb13-36" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(workflow)</span>
<span id="cb13-37"><a href="#cb13-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-38"><a href="#cb13-38" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Common Pitfalls and Solutions:</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb13-39"><a href="#cb13-39" aria-hidden="true" tabindex="-1"></a>pitfalls <span class="op">=</span> [</span>
<span id="cb13-40"><a href="#cb13-40" aria-hidden="true" tabindex="-1"></a>    (<span class="st">"Forgot to call update_parameterized_weights before eliminate_to_dag"</span>,</span>
<span id="cb13-41"><a href="#cb13-41" aria-hidden="true" tabindex="-1"></a>     <span class="st">"This initializes the parameter dimension. Call it with initial values."</span>),</span>
<span id="cb13-42"><a href="#cb13-42" aria-hidden="true" tabindex="-1"></a>    (<span class="st">"Graph structure changes with parameters"</span>,</span>
<span id="cb13-43"><a href="#cb13-43" aria-hidden="true" tabindex="-1"></a>     <span class="st">"Symbolic elimination requires fixed structure. Restructure model if possible."</span>),</span>
<span id="cb13-44"><a href="#cb13-44" aria-hidden="true" tabindex="-1"></a>    (<span class="st">"Using symbolic elimination for just 1-2 evaluations"</span>,</span>
<span id="cb13-45"><a href="#cb13-45" aria-hidden="true" tabindex="-1"></a>     <span class="st">"Not worth the overhead. Use traditional approach for few evaluations."</span>),</span>
<span id="cb13-46"><a href="#cb13-46" aria-hidden="true" tabindex="-1"></a>    (<span class="st">"Memory concerns with very large graphs"</span>,</span>
<span id="cb13-47"><a href="#cb13-47" aria-hidden="true" tabindex="-1"></a>     <span class="st">"Consider partitioning state space or using lazy evaluation strategies."</span>)</span>
<span id="cb13-48"><a href="#cb13-48" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb13-49"><a href="#cb13-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-50"><a href="#cb13-50" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, (pitfall, solution) <span class="kw">in</span> <span class="bu">enumerate</span>(pitfalls, <span class="dv">1</span>):</span>
<span id="cb13-51"><a href="#cb13-51" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">. Issue: </span><span class="sc">{</span>pitfall<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb13-52"><a href="#cb13-52" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   Solution: </span><span class="sc">{</span>solution<span class="sc">}</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb13-53"><a href="#cb13-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-54"><a href="#cb13-54" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Performance Expectations:</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb13-55"><a href="#cb13-55" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  For coalescent model (</span><span class="sc">{</span>coalescent_graph<span class="sc">.</span>vertices_length()<span class="sc">}</span><span class="ss"> states):"</span>)</span>
<span id="cb13-56"><a href="#cb13-56" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"    • Traditional: ~</span><span class="sc">{</span>results_traditional[<span class="op">-</span><span class="dv">1</span>]<span class="op">/</span><span class="dv">500</span><span class="op">*</span><span class="dv">1000</span><span class="sc">:.3f}</span><span class="ss">ms per evaluation"</span>)</span>
<span id="cb13-57"><a href="#cb13-57" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"    • Symbolic: ~</span><span class="sc">{</span>results_symbolic[<span class="op">-</span><span class="dv">1</span>]<span class="op">/</span><span class="dv">500</span><span class="op">*</span><span class="dv">1000</span><span class="sc">:.3f}</span><span class="ss">ms per evaluation (after elimination)"</span>)</span>
<span id="cb13-58"><a href="#cb13-58" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"    • Speedup: ~</span><span class="sc">{</span>speedups[<span class="op">-</span><span class="dv">1</span>]<span class="sc">:.0f}</span><span class="ss">× for 500 evaluations"</span>)</span>
<span id="cb13-59"><a href="#cb13-59" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">  Speedup grows with:"</span>)</span>
<span id="cb13-60"><a href="#cb13-60" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"    • Number of evaluations (amortizes one-time cost)"</span>)</span>
<span id="cb13-61"><a href="#cb13-61" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"    • Graph size (O(n³) vs O(n) difference magnifies)"</span>)</span>
<span id="cb13-62"><a href="#cb13-62" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"    • Graph sparsity (sparse graphs have smaller expression trees)"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="advanced-topics-and-future-directions" class="level1">
<h1>Advanced Topics and Future Directions</h1>
<p>Beyond the core symbolic elimination algorithm, several advanced techniques and extensions can further improve performance or enable new applications. Understanding these topics helps you extract maximum value from symbolic elimination in sophisticated inference pipelines and points toward future research directions that could expand the technique’s applicability.</p>
<p>Expression simplification represents a promising avenue for reducing instantiation overhead. The symbolic elimination algorithm constructs expressions compositionally based on the elimination sequence, which naturally produces redundant structure. For example, MUL(DOT([a]), DOT([b])) could be simplified to DOT([a*b]) if we know a and b are constant coefficients. More sophisticated simplifications include constant folding (evaluating constant subexpressions at compile time), algebraic identities (x + 0 = x, x * 1 = x), and common subexpression elimination (sharing identical subtrees across multiple expressions). Implementing these optimizations requires balancing the compilation cost of running simplification passes against the runtime savings from evaluating smaller trees—for inference with many iterations, this balance often favors aggressive simplification.</p>
<p>Automatic differentiation through symbolic DAGs opens possibilities for gradient-based inference without numerical differentiation overhead. Modern AD frameworks like JAX can differentiate through the instantiation and evaluation operations, computing gradients of distribution properties with respect to parameters. Because instantiation is just expression evaluation (a sequence of arithmetic operations), its derivative is straightforward to compute using the chain rule. This enables SVGD and other gradient-based methods to use symbolic elimination seamlessly, obtaining both forward evaluation and gradient computation with O(n) per-particle cost instead of O(n³). The implementation requires careful handling of the boundary between the C++ symbolic elimination code and JAX’s Python-level AD machinery, but the payoff in inference speed is substantial.</p>
<p>Parallelization of instantiation offers potential for further speedups in scenarios with many concurrent evaluations. When computing likelihood across multiple independent data points or evaluating gradients using finite differences, we need to instantiate the symbolic DAG with multiple parameter vectors simultaneously. These instantiations are completely independent and thus embarrassingly parallel—we can distribute them across CPU cores or GPU threads without any coordination. Implementing batched evaluation where multiple parameter vectors are processed together using SIMD operations or GPU kernels could provide additional factors of 10-100× speedup beyond what symbolic elimination already achieves. This becomes especially attractive for large-scale inference problems where thousands of particles or Markov chain replicas require concurrent likelihood evaluations.</p>
<p>Sparse graph exploitation through graph partitioning and hierarchical elimination could reduce expression tree sizes for special graph structures. Many phase-type distributions have natural hierarchical or modular structure where the state space decomposes into weakly connected components. By recognizing this structure and eliminating within components before combining across components, we might generate simpler expressions than blind elimination would produce. Research into graph algorithms that exploit structure during elimination—analogous to nested dissection for sparse linear systems—could lead to theoretical improvements in the expression size bound S, perhaps reducing it from O(n³) to O(n^{2.5}) or better for certain graph families.</p>
</section>
<section id="summary-and-key-takeaways" class="level1">
<h1>Summary and Key Takeaways</h1>
<p>Symbolic graph elimination transforms the computational landscape for parameterized phase-type distributions by recognizing and exploiting the separation between computational structure and numeric values. The traditional approach to evaluating phase-type distributions with different parameters treats each evaluation as independent, running an expensive O(n³) graph elimination algorithm every time parameters change. This redundancy becomes crippling for inference algorithms that require thousands of evaluations. Symbolic elimination solves this problem by performing the elimination algorithm once to build a template in the form of expression trees, then rapidly filling in that template with different numeric values for subsequent evaluations.</p>
<p>The technique rests on a elegant insight: the graph elimination algorithm makes the same structural decisions regardless of edge weights, executing the same sequence of vertex eliminations and bypass edge creations for any parameter values. What changes is only the arithmetic—the specific numbers being multiplied and added. By representing these numbers symbolically as expressions in terms of parameters, we separate the O(n³) structural work (done once during symbolic elimination) from the O(n) arithmetic work (done for each evaluation during instantiation). For inference problems with hundreds or thousands of evaluations, this separation yields speedups ranging from 10× to 1000× depending on graph size and structure.</p>
<p>Implementation of symbolic elimination requires building an expression tree system to represent parameterized computations, extending the graph elimination algorithm to construct these trees instead of computing numbers, and providing an instantiation mechanism that evaluates expression trees efficiently. The PtDAlgorithms library implements this in carefully optimized C code with Python bindings, making the dramatic performance improvements available through a simple API: build your graph as usual, call eliminate_to_dag() once, then call instantiate(theta) for each parameter vector. The resulting workflow integrates seamlessly with existing inference code while providing transformative speedups.</p>
<p>The practical impact of symbolic elimination extends far beyond raw speed. Inference problems that previously required days of computation complete in hours or minutes. Parameter sweeps that were impractical become routine. Sensitivity analyses and gradient computations that involved expensive numerical differentiation become cheap and precise. Real-time inference scenarios that required careful approximation or precomputation become feasible with exact computation. These capabilities fundamentally expand what kinds of phase-type distribution models we can use in practice and what kinds of inference questions we can answer economically.</p>
<div id="final-summary" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"SYMBOLIC GRAPH ELIMINATION - SUMMARY"</span>)</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">The Problem:"</span>)</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  Traditional evaluation: O(m × n³) for m parameter evaluations"</span>)</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  Bottleneck: Repeated graph elimination with O(n³) complexity"</span>)</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  Impact: Inference with 100+ particles becomes prohibitively expensive"</span>)</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">The Solution:"</span>)</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  Symbolic elimination: O(n³ + m × S) where S ≈ O(n) for sparse graphs"</span>)</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  Key insight: Elimination structure is parameter-independent"</span>)</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  Approach: Build expression trees once, evaluate quickly for each parameter"</span>)</span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Performance Gains:"</span>)</span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  ✓ </span><span class="sc">{</span>speedups[<span class="op">-</span><span class="dv">1</span>]<span class="sc">:.0f}</span><span class="ss">× speedup observed for coalescent model with 500 evaluations"</span>)</span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  ✓ Speedup grows with evaluation count (amortizes one-time elimination)"</span>)</span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  ✓ Larger graphs see greater speedups (O(n³) vs O(n) difference magnifies)"</span>)</span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  ✓ Real-world inference: 100-1000× speedup for SVGD and MCMC"</span>)</span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">API Usage:"</span>)</span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a>api_summary <span class="op">=</span> <span class="st">"""  # Build parameterized graph</span></span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a><span class="st">  graph = Graph(callback=model, parameterized=True)</span></span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a><span class="st">  graph.update_parameterized_weights(init_params)</span></span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a><span class="st">  </span></span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a><span class="st">  # One-time symbolic elimination (O(n³))</span></span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a><span class="st">  dag = graph.eliminate_to_dag()</span></span>
<span id="cb14-28"><a href="#cb14-28" aria-hidden="true" tabindex="-1"></a><span class="st">  </span></span>
<span id="cb14-29"><a href="#cb14-29" aria-hidden="true" tabindex="-1"></a><span class="st">  # Many fast evaluations (O(n) each)</span></span>
<span id="cb14-30"><a href="#cb14-30" aria-hidden="true" tabindex="-1"></a><span class="st">  for theta in parameters:</span></span>
<span id="cb14-31"><a href="#cb14-31" aria-hidden="true" tabindex="-1"></a><span class="st">      concrete = dag.instantiate(theta)</span></span>
<span id="cb14-32"><a href="#cb14-32" aria-hidden="true" tabindex="-1"></a><span class="st">      result = concrete.moments(1)</span></span>
<span id="cb14-33"><a href="#cb14-33" aria-hidden="true" tabindex="-1"></a><span class="st">"""</span></span>
<span id="cb14-34"><a href="#cb14-34" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(api_summary)</span>
<span id="cb14-35"><a href="#cb14-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-36"><a href="#cb14-36" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Best Use Cases:"</span>)</span>
<span id="cb14-37"><a href="#cb14-37" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  • Bayesian inference (SVGD, MCMC)"</span>)</span>
<span id="cb14-38"><a href="#cb14-38" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  • Parameter estimation and optimization"</span>)</span>
<span id="cb14-39"><a href="#cb14-39" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  • Sensitivity analysis and uncertainty quantification"</span>)</span>
<span id="cb14-40"><a href="#cb14-40" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  • Any scenario with 10+ evaluations at different parameters"</span>)</span>
<span id="cb14-41"><a href="#cb14-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-42"><a href="#cb14-42" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Implementation:"</span>)</span>
<span id="cb14-43"><a href="#cb14-43" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  • C implementation with expression tree evaluation"</span>)</span>
<span id="cb14-44"><a href="#cb14-44" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  • Python bindings via pybind11"</span>)</span>
<span id="cb14-45"><a href="#cb14-45" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  • Available in PtDAlgorithms v0.21.3+"</span>)</span>
<span id="cb14-46"><a href="#cb14-46" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  • Numerical results match traditional approach exactly"</span>)</span>
<span id="cb14-47"><a href="#cb14-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-48"><a href="#cb14-48" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Future Directions:"</span>)</span>
<span id="cb14-49"><a href="#cb14-49" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  • Expression simplification for smaller trees"</span>)</span>
<span id="cb14-50"><a href="#cb14-50" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  • Batched evaluation for SIMD/GPU acceleration"</span>)</span>
<span id="cb14-51"><a href="#cb14-51" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  • Automatic differentiation through symbolic DAGs"</span>)</span>
<span id="cb14-52"><a href="#cb14-52" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  • Hierarchical elimination for structured graphs"</span>)</span>
<span id="cb14-53"><a href="#cb14-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-54"><a href="#cb14-54" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb14-55"><a href="#cb14-55" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"For more details, see the paper:"</span>)</span>
<span id="cb14-56"><a href="#cb14-56" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Røikjer, Hobolth, &amp; Munch (2022). Graph-based algorithms for"</span>)</span>
<span id="cb14-57"><a href="#cb14-57" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"phase-type distributions. Statistics and Computing, 32, 91."</span>)</span>
<span id="cb14-58"><a href="#cb14-58" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">70</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/munch-group\.github\.io\/PtDAlgorithms\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>